<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>Hadoop2.x | Jermyn's blog</title><meta name="keywords" content="大数据集群服务,Hadoop2.7.2"><meta name="author" content="Jermyn,born_in2084@yeah.net"><meta name="copyright" content="Jermyn"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="第一章 Hadoop框架Hadoop1.x 和 Hadoop2.x 区别 Hadoop1.x组成MapReduce（计算+资源调度），HDFS（数据存储），Common（辅助工具） Hadoop2.x组成MapReduce（计算），Yarn（资源调度），HDFS（数据存储），Common（辅助工具） 在Hadoop1.x时代，Hadoop中的MapReduce同时处理业务逻辑运算和资源的调度，耦合"><meta property="og:type" content="article"><meta property="og:title" content="Hadoop2.x"><meta property="og:url" content="https://www.jermyn.cn/posts/facf.html"><meta property="og:site_name" content="Jermyn&#39;s blog"><meta property="og:description" content="第一章 Hadoop框架Hadoop1.x 和 Hadoop2.x 区别 Hadoop1.x组成MapReduce（计算+资源调度），HDFS（数据存储），Common（辅助工具） Hadoop2.x组成MapReduce（计算），Yarn（资源调度），HDFS（数据存储），Common（辅助工具） 在Hadoop1.x时代，Hadoop中的MapReduce同时处理业务逻辑运算和资源的调度，耦合"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/087b21e70b21ac643352602c8746d20.jpg"><meta property="article:published_time" content="2023-05-23T21:12:50.000Z"><meta property="article:modified_time" content="2023-05-28T15:04:33.103Z"><meta property="article:author" content="Jermyn"><meta property="article:tag" content="hadoop"><meta property="article:tag" content="大数据"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/087b21e70b21ac643352602c8746d20.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://www.jermyn.cn/posts/facf"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="manifest" href="/manifest.json"><meta name="msapplication-TileColor" content="#49b1f5"><link rel="apple-touch-icon" sizes="180x180" href="/img/siteicon/128.png"><link rel="icon" type="image/png" sizes="32x32" href="/img/siteicon/32.png"><link rel="icon" type="image/png" sizes="16x16" href="/img/siteicon/16.png"><link rel="mask-icon" href="/img/siteicon/128.png" color="#5bbad5"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"Hadoop2.x",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2023-05-28 15:04:33"}</script><noscript><style>#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.css"><link rel="stylesheet" href="/js/runtime/runtime.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload='this.media="screen"'><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload='this.media="all"'><script src="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="Jermyn's blog" type="application/atom+xml"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/9a8a/auther.jpg" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">15</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">22</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><span>留言</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><span>档案</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><span>音乐</span></a></div><div class="menus_item"><a class="site-page" href="/bangumis/index.html"><span>番剧</span></a></div><div class="menus_item"><a class="site-page" href="/books"><span>书籍</span></a></div><div class="menus_item"><a class="site-page" href="/movies/"><span>影视</span></a></div><div class="menus_item"><a class="site-page" href="/games/"><span>游戏</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/087b21e70b21ac643352602c8746d20.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Jermyn's blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i> <span>搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><span>留言</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><span>档案</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><span>音乐</span></a></div><div class="menus_item"><a class="site-page" href="/bangumis/index.html"><span>番剧</span></a></div><div class="menus_item"><a class="site-page" href="/books"><span>书籍</span></a></div><div class="menus_item"><a class="site-page" href="/movies/"><span>影视</span></a></div><div class="menus_item"><a class="site-page" href="/games/"><span>游戏</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Hadoop2.x</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-05-23T21:12:50.000Z" title="发表于 2023-05-23 21:12:50">2023-05-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-05-28T15:04:33.103Z" title="更新于 2023-05-28 15:04:33">2023-05-28</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">13k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>58分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="Hadoop2.x"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="第一章-Hadoop框架"><a href="#第一章-Hadoop框架" class="headerlink" title="第一章 Hadoop框架"></a>第一章 Hadoop框架</h1><h2 id="Hadoop1-x-和-Hadoop2-x-区别"><a href="#Hadoop1-x-和-Hadoop2-x-区别" class="headerlink" title="Hadoop1.x 和 Hadoop2.x 区别"></a>Hadoop1.x 和 Hadoop2.x 区别</h2><ul><li><strong>Hadoop1.x组成</strong><br>MapReduce（计算+资源调度），HDFS（数据存储），Common（辅助工具）</li><li><strong>Hadoop2.x组成</strong><br>MapReduce（计算），Yarn（资源调度），HDFS（数据存储），Common（辅助工具）<blockquote><p>在Hadoop1.x时代，Hadoop中的MapReduce同时处理业务逻辑运算和资源的调度，耦合性较大，在Hadoop2.x时代，增加了Yarn。Yarn只负责资源的调度，MapReduce只负责运算</p></blockquote></li></ul><h2 id="HDFS架构概述"><a href="#HDFS架构概述" class="headerlink" title="HDFS架构概述"></a>HDFS架构概述</h2><ol><li>NameNode（nn）：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等。</li><li>DataNode(dn)：在本地文件系统存储文件块数据，以及块数据的校验和。</li><li>Secondary NameNode(2nn)：辅助NameNode工作，用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。</li></ol><h2 id="Yarn架构"><a href="#Yarn架构" class="headerlink" title="Yarn架构"></a>Yarn架构</h2><p>ResourceManager（RM）：资源由RM管理（理解为部门经理）。<br>（1）处理客户端请求；<br>（2）监控NodeManager<br>（3）启动或监控ApplicationMaster<br>（4）资源的分配与调度</p><p>NodeManager（NM）：单个节点上的资源由NM管理，但是经过RM协调。（理解为小组长）<br>（1）管理单个节点上的资源<br>（2）处理来自ResourceManager的命令<br>（3）处理来自ApplicationMaster的命令</p><p>ApplicationMaster（AM）：集群上某一个任务的开启关闭，协调（理解为一个个项目）<br>（1）负责数据的切分<br>（2）为应用程序申请资源并分配给内部的任务<br>（3）任务的监控与容错</p><p>Container ：Container是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/f495/20230523213727.png" alt=""></p><h2 id="MapReduce架构概述"><a href="#MapReduce架构概述" class="headerlink" title="MapReduce架构概述"></a>MapReduce架构概述</h2><p>MapReduce将计算过程分为两个阶段：Map和Reduce</p><ol><li>Map阶段并行处理输入数据（分：一个大的任务分给多个节点，每个节点都做一部分）</li><li>Reduce阶段对Map结果进行汇总（和：将每个节点的计算结果汇总）</li></ol><h1 id="第二章-Hadoop运行环境搭建"><a href="#第二章-Hadoop运行环境搭建" class="headerlink" title="第二章 Hadoop运行环境搭建"></a>第二章 Hadoop运行环境搭建</h1><ul><li><strong>JAVA_HOME</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># JAVA_HOME</span></span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.<span class="number">8.0</span>_144</span><br><span class="line">export PATH=<span class="variable">$PATH:</span><span class="variable">$JAVA_HOME</span>/bin</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#HADOOP_HOME</span></span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span></span><br><span class="line">export PATH=<span class="variable">$PATH:</span><span class="variable">$HADOOP_HOME</span>/bin</span><br><span class="line">export PATH=<span class="variable">$PATH:</span><span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure></li></ul><h1 id="第三章-Hadoop运行模式"><a href="#第三章-Hadoop运行模式" class="headerlink" title="第三章 Hadoop运行模式"></a>第三章 Hadoop运行模式</h1><p>Hadoop运行模式包括：本地模式、伪分布式模式以及完全分布式模式。<br>Hadoop官方网站：<a target="_blank" rel="noopener" href="http://hadoop.apache.org/">http://hadoop.apache.org/</a></p><h2 id="本地运行模式"><a href="#本地运行模式" class="headerlink" title="本地运行模式"></a>本地运行模式</h2><h3 id="官方WordCount案例"><a href="#官方WordCount案例" class="headerlink" title="官方WordCount案例"></a><strong>官方WordCount案例</strong></h3><ol><li>创建在hadoop-2.7.2文件下面创建一个wcinput文件夹</li><li>在wcinput文件下创建一个wc.input文件</li><li>编辑wc.input文件(输入任意内容)</li><li>回到Hadoop目录/opt/module/hadoop-2.7.2</li><li>执行程序</li><li>查看结果<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> mkdir wcinput</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> <span class="built_in">cd</span> wcinput/</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">wcinput</span>]<span class="variable">$</span> vim wc.input</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">wcinput</span>]<span class="variable">$</span> <span class="built_in">ls</span></span><br><span class="line">wc.input</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">wcinput</span>]<span class="variable">$</span> <span class="built_in">cd</span> ..</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> <span class="built_in">ls</span></span><br><span class="line">bin  etc  include  input  lib  libexec  LICENSE.txt  NOTICE.txt  output  README.txt  sbin  share  wcinput</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hadoop jar share/hadoop/mapreduce/hadoop<span class="literal">-mapreduce-examples-2</span>.<span class="number">7.2</span>.jar wordcount wcinput/ wcouput</span><br><span class="line"><span class="number">23</span>/<span class="number">05</span>/<span class="number">24</span> <span class="number">09</span>:<span class="number">09</span>:<span class="number">19</span> INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session<span class="literal">-id</span></span><br><span class="line"><span class="number">23</span>/<span class="number">05</span>/<span class="number">24</span> <span class="number">09</span>:<span class="number">09</span>:<span class="number">19</span> INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=</span><br><span class="line">............</span><br><span class="line">............</span><br><span class="line">............</span><br><span class="line">        File Output Format Counters</span><br><span class="line">                Bytes Written=<span class="number">235</span></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> <span class="built_in">cd</span> wcouput/</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">wcouput</span>]<span class="variable">$</span> <span class="built_in">ls</span></span><br><span class="line">part<span class="literal">-r-00000</span>  _SUCCESS</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">wcouput</span>]<span class="variable">$</span> <span class="built_in">cat</span> part<span class="literal">-r-00000</span></span><br><span class="line">EJERMYN <span class="number">1</span></span><br><span class="line">HADOOP  <span class="number">6</span></span><br><span class="line">JAVA    <span class="number">5</span></span><br><span class="line">JAVAA   <span class="number">1</span></span><br><span class="line">JEERMYN <span class="number">1</span></span><br><span class="line">JERDMYN <span class="number">1</span></span><br><span class="line">JEREMYN <span class="number">1</span></span><br><span class="line">JERMYCN <span class="number">1</span></span><br><span class="line">JERMYN  <span class="number">1</span></span><br><span class="line">JERMYTN <span class="number">1</span></span><br><span class="line">JRECMYN <span class="number">1</span></span><br><span class="line">JREEMYN <span class="number">2</span></span><br><span class="line">JREMYDN <span class="number">1</span></span><br><span class="line">JREMYEN <span class="number">1</span></span><br><span class="line">Jefrmyn <span class="number">1</span></span><br><span class="line">Jermfdyn        <span class="number">1</span></span><br><span class="line">Jermyfn <span class="number">1</span></span><br><span class="line">Jermyn  <span class="number">3</span></span><br><span class="line">hadoop  <span class="number">6</span></span><br><span class="line">java    <span class="number">2</span></span><br><span class="line">javaC   <span class="number">1</span></span><br><span class="line">javaEE  <span class="number">1</span></span><br><span class="line">javaSE  <span class="number">1</span></span><br><span class="line">javac   <span class="number">1</span></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">wcouput</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="伪分布式运行模式"><a href="#伪分布式运行模式" class="headerlink" title="伪分布式运行模式"></a>伪分布式运行模式</h2><div class="tip fa-gamepad faa-horizontal animated"><p>启动HDFS并运行MapReduce程序</p></div><p><strong><em>点击图片查看文档</em></strong><br><a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/SingleCluster.html"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524100352.png" alt=""></a></p><ul><li><strong>配置：hadoop-env.sh</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>]<span class="variable">$</span> <span class="built_in">echo</span> <span class="variable">$JAVA_HOME</span></span><br><span class="line">/opt/module/jdk1.<span class="number">8.0</span>_144</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>]<span class="variable">$</span> vim hadoop<span class="literal">-env</span>.sh</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524100154.png" alt=""></li><li><strong>配置：core-site.xml</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop100:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><strong>配置：hdfs-site.xml</strong><br><strong><em>点击图片查看文档</em></strong><br><a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524100755.png" alt=""></a><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定HDFS副本的数量 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><strong>启动集群</strong></li><li>格式化NameNode（第一次启动时格式化，以后就不要总格式化）<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs namenode <span class="literal">-format</span></span><br></pre></td></tr></table></figure></li><li>启动NameNode<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop<span class="literal">-daemon</span>.sh <span class="built_in">start</span> namenode</span><br></pre></td></tr></table></figure></li><li>启动DataNode<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop<span class="literal">-daemon</span>.sh <span class="built_in">start</span> datanode</span><br></pre></td></tr></table></figure></li><li>查看进程<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> [<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> jps</span><br><span class="line"><span class="number">3826</span> DataNode</span><br><span class="line"><span class="number">3683</span> NameNode</span><br><span class="line"><span class="number">3902</span> Jps</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li>web端查看HDFS文件系统<br><a target="_blank" rel="noopener" href="http://hadoop100:50070/dfshealth.html#tab-overview">http://hadoop100:50070/dfshealth.html#tab-overview</a><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524103135.png" alt=""></li></ul><div class="note blue icon-padding modern"><i class="note-icon fas fa-bullhorn"></i><p>说明：在企业中遇到Bug时，经常根据日志提示信息去分析问题、解决Bug</p></div><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">logs</span>]<span class="variable">$</span> <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">logs</span>]<span class="variable">$</span> ll</span><br><span class="line">总用量 <span class="number">68</span></span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root <span class="number">24131</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">10</span>:<span class="number">31</span> hadoop<span class="literal">-Jermyn-datanode-hadoop100</span>.log</span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root   <span class="number">717</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">10</span>:<span class="number">23</span> hadoop<span class="literal">-Jermyn-datanode-hadoop100</span>.out</span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root <span class="number">29149</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">10</span>:<span class="number">29</span> hadoop<span class="literal">-Jermyn-namenode-hadoop100</span>.log</span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root  <span class="number">5007</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">10</span>:<span class="number">27</span> hadoop<span class="literal">-Jermyn-namenode-hadoop100</span>.out</span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root     <span class="number">0</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">10</span>:<span class="number">20</span> SecurityAuth<span class="literal">-Jermyn</span>.audit</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">logs</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><div class="note blue icon-padding modern"><i class="note-icon fas fa-bullhorn"></i><p>思考：为什么不能一直格式化NameNode，格式化NameNode，要注意什么？</p></div><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> <span class="built_in">cat</span> <span class="keyword">data</span>/tmp/dfs/<span class="keyword">data</span>/current/VERSION | grep <span class="string">&#x27;clusterID&#x27;</span></span><br><span class="line">clusterID=CID<span class="literal">-77af8246-5931-4a4f-bdbe-5fe9624458a3</span></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> <span class="built_in">cat</span> <span class="keyword">data</span>/tmp/dfs/name/current/VERSION | grep <span class="string">&#x27;clusterID&#x27;</span></span><br><span class="line">clusterID=CID<span class="literal">-77af8246-5931-4a4f-bdbe-5fe9624458a3</span></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><blockquote><p>注意：<span class="p red">可以看出data和name的集群ID是相同的</span>格式化NameNode，会产生新的集群id,导致NameNode和DataNode的集群id不一致，集群找不到已往数据。所以，格式NameNode时，一定要先删除data数据和log日志<span class="p red">（删除data和log时候，必须把NameNode和DataNode关闭，否则删除无效）</span>，然后再格式化NameNode。<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524115949.png" alt=""></p></blockquote><ul><li><p><strong>在HDFS文件系统上创建一个input文件夹</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs <span class="literal">-mkdir</span> <span class="literal">-p</span> /user/Jermyn/input</span><br></pre></td></tr></table></figure><p><a target="_blank" rel="noopener" href="http://hadoop100:50070/explorer.html#/user/Jermyn/input">http://hadoop100:50070/explorer.html#/user/Jermyn/input</a></p></li><li><p><strong>将本地的 wcinput/wc.input 上传到hdfs的/user/Jermyn/input</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs <span class="literal">-put</span> wcinput/wc.input /user/Jermyn/input</span><br></pre></td></tr></table></figure><p><strong><em>点击图片查看</em></strong><br><a target="_blank" rel="noopener" href="http://hadoop100:50070/explorer.html#/user/Jermyn/input"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524104943.png" alt=""></a></p></li><li><p><strong>执行官方WordCount案例</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop jar share/hadoop/mapreduce/hadoop<span class="literal">-mapreduce-examples-2</span>.<span class="number">7.2</span>.jar wordcount /user/Jermyn/input /user/Jermyn/output</span><br></pre></td></tr></table></figure><p><strong><em>点击图片查看</em></strong><br><a target="_blank" rel="noopener" href="http://hadoop100:50070/explorer.html#/user/Jermyn/output"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524110240.png" alt=""></a></p></li><li><p><strong>查看运行的结果</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop dfs <span class="literal">-cat</span> /user/Jermyn/output/p*</span><br></pre></td></tr></table></figure></li><li><p><strong>删除输出结果</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop dfs <span class="literal">-rm</span> <span class="literal">-r</span> /user/Jermyn/out</span><br></pre></td></tr></table></figure><div class="tip fa-gamepad faa-horizontal animated"><p>启动YARN并运行MapReduce程序</p></div></li><li><p><strong>配置yarn-env.sh</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.<span class="number">8.0</span>_144</span><br></pre></td></tr></table></figure></li><li><p><strong>配置yarn-site.xml</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Reducer获取数据的方式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> 	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> 	<span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop100<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>配置：mapred-env.sh</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure></li><li><p><strong>配置： (对mapred-site.xml.template重新命名为) mapred-site.xml</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mv</span> mapred<span class="literal">-site</span>.xml.template mapred<span class="literal">-site</span>.xml</span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定MR运行在YARN上 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><span class="p green">点击图片查看配置文件</span><p><a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r2.7.2/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524122131.png" alt=""></a></p></li></ul><h3 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a><strong>启动集群</strong></h3><span class="p red">注意：启动前必须保证NameNode和DataNode已经启动</span><ul><li><strong>启动ResourceManager</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/yarn<span class="literal">-daemon</span>.sh <span class="built_in">start</span> resourcemanager</span><br></pre></td></tr></table></figure></li><li><strong>启动NodeManager</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/yarn<span class="literal">-daemon</span>.sh <span class="built_in">start</span> nodemanager</span><br></pre></td></tr></table></figure></li><li><strong>查看进程</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> jps</span><br><span class="line"><span class="number">6016</span> Jps</span><br><span class="line"><span class="number">3826</span> DataNode</span><br><span class="line"><span class="number">3683</span> NameNode</span><br><span class="line"><span class="number">5637</span> ResourceManager</span><br><span class="line"><span class="number">5897</span> NodeManager</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><h3 id="集群操作"><a href="#集群操作" class="headerlink" title="集群操作"></a><strong>集群操作</strong></h3></li><li><p><strong>YARN的浏览器页面查看</strong><br><a target="_blank" rel="noopener" href="http://hadoop100:8088/cluster">http://hadoop100:8088/cluster</a><br><strong><em>点击图片跳转</em></strong><br><a target="_blank" rel="noopener" href="http://hadoop100:8088/cluster"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524123246.png" alt=""></a></p></li><li><p><strong>执行执行官方WordCount案例查看任务</strong></p><span class="p red">执行任务前必须把output删除</span><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs <span class="literal">-rm</span> <span class="literal">-r</span> /user/Jermyn/output</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop jar share/hadoop/mapreduce/hadoop<span class="literal">-mapreduce-examples-2</span>.<span class="number">7.2</span>.jar wordcount /user/Jermyn/input /user/Jermyn/output</span><br></pre></td></tr></table></figure><p><a target="_blank" rel="noopener" href="http://hadoop100:8088/cluster"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524124532.png" alt=""></a></p></li></ul><div class="tip fa-gamepad faa-horizontal animated"><p>配置历史服务器</p></div><p>为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下：</p><ul><li><strong>配置mapred-site.xml</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 历史服务器端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop100:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 历史服务器web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop100:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>启动历史服务器</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/mr<span class="literal">-jobhistory-daemon</span>.sh <span class="built_in">start</span> historyserver</span><br></pre></td></tr></table></figure></li><li><p><strong>查看历史服务器是否启动</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> jps</span><br><span class="line"><span class="number">3826</span> DataNode</span><br><span class="line"><span class="number">3683</span> NameNode</span><br><span class="line"><span class="number">6836</span> Jps</span><br><span class="line"><span class="number">5637</span> ResourceManager</span><br><span class="line"><span class="number">6758</span> JobHistoryServer</span><br><span class="line"><span class="number">5897</span> NodeManager</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li><strong>查看JobHistory</strong><br><a target="_blank" rel="noopener" href="http://hadoop100:19888/jobhistory">http://hadoop100:19888/jobhistory</a><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524125336.png" alt=""><br><a target="_blank" rel="noopener" href="http://hadoop100:19888/jobhistory/job/job_1684902467164_0001"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524125303.png" alt=""></a></li></ul><div class="tip fa-gamepad faa-horizontal animated"><p>配置日志的聚集</p></div><p>日志聚集概念：应用运行完成以后，将程序运行日志信息上传到HDFS系统上。<br>日志聚集功能好处：可以方便的查看到程序运行详情，方便开发调试。<br><span class="p red">注意：开启日志聚集功能，需要重新启动NodeManager 、ResourceManager和HistoryManager。</span></p><ul><li><p><strong>配置yarn-site.xml</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 日志聚集功能使能 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 日志保留时间设置7天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>关闭NodeManager 、ResourceManager和HistoryManage</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sbin/yarn<span class="literal">-daemon</span>.sh stop nodemanager</span><br><span class="line">sbin/yarn<span class="literal">-daemon</span>.sh stop resourcemanager</span><br><span class="line">sbin/mr<span class="literal">-jobhistory-daemon</span>.sh stop historyserver</span><br></pre></td></tr></table></figure></li><li><p><strong>启动NodeManager 、ResourceManager和HistoryManager</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sbin/yarn<span class="literal">-daemon</span>.sh <span class="built_in">start</span> nodemanager</span><br><span class="line">sbin/yarn<span class="literal">-daemon</span>.sh <span class="built_in">start</span> resourcemanager</span><br><span class="line">sbin/mr<span class="literal">-jobhistory-daemon</span>.sh <span class="built_in">start</span> historyserver</span><br></pre></td></tr></table></figure></li><li><p><strong>删除HDFS上已经存在的输出文件</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs <span class="literal">-rm</span> <span class="literal">-r</span> /user/Jermyn/output</span><br></pre></td></tr></table></figure></li><li><p><strong>执行WordCount程序</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop jar share/hadoop/mapreduce/hadoop<span class="literal">-mapreduce-examples-2</span>.<span class="number">7.2</span>.jar wordcount /user/Jermyn/input /user/Jermyn/output</span><br></pre></td></tr></table></figure></li><li><strong>查看日志</strong><br><a target="_blank" rel="noopener" href="http://hadoop100:19888/jobhistory">http://hadoop100:19888/jobhistory</a><br><a target="_blank" rel="noopener" href="http://hadoop100:19888/jobhistory/job/job_1684908681616_0001"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524142503.png" alt=""></a><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524142605.png" alt=""></li></ul><div class="tip fa-gamepad faa-horizontal animated"><p>配置文件说明</p></div><ol><li>Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。<br>core-default.xml 在 hadoop-common-2.7.2.jar/ core-default.xml<br>hdfs-default.xml 在 hadoop-hdfs-2.7.2.jar/ hdfs-default.xml<br>yarn-default.xml 在 hadoop-yarn-common-2.7.2.jar/ yarn-default.xml<br>mapred-default.xml 在 hadoop-mapreduce-client-core-2.7.2.jar/ mapred-default.xml</li><li>core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径上，用户可以根据项目需求重新进行修改配置</li></ol><h2 id="完全分布式运行模式"><a href="#完全分布式运行模式" class="headerlink" title="完全分布式运行模式"></a>完全分布式运行模式</h2><span class="p red">根据 hadoop100 进行拷贝出hadoop102，hadoop103，hadoop104，然后把在hadoop100上配置的/opt/module 分发到 hadoop102，hadoop103，hadoop104，还有配置文件 /etc/profile (使用 scp -r 命令)</span><h3 id="scp（secure-copy）安全拷贝"><a href="#scp（secure-copy）安全拷贝" class="headerlink" title="scp（secure copy）安全拷贝"></a><strong>scp（secure copy）安全拷贝</strong></h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp    <span class="literal">-r</span>          <span class="variable">$pdir</span>/<span class="variable">$fname</span>              <span class="variable">$user</span>@hadoop<span class="variable">$host:</span><span class="variable">$pdir</span>/<span class="variable">$fname</span></span><br><span class="line">命令   递归       要拷贝的文件路径/名称    目的用户<span class="selector-tag">@</span>主机:目的路径/名称</span><br></pre></td></tr></table></figure><h3 id="rsync-远程同步工具"><a href="#rsync-远程同步工具" class="headerlink" title="rsync 远程同步工具"></a><strong>rsync 远程同步工具</strong></h3><p>rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。<br>rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。<br></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rsync    <span class="literal">-rvl</span>       <span class="variable">$pdir</span>/<span class="variable">$fname</span>              <span class="variable">$user</span>@hadoop<span class="variable">$host:</span><span class="variable">$pdir</span>/<span class="variable">$fname</span></span><br><span class="line">命令   选项参数   要拷贝的文件路径/名称    目的用户<span class="selector-tag">@</span>主机:目的路径/名称</span><br></pre></td></tr></table></figure><p></p><blockquote><p>-r 递归<br>-v 显示复制过程<br>-l 拷贝符号连接</p></blockquote><h3 id="编写脚本，使用xsync实现文件在集群中传输"><a href="#编写脚本，使用xsync实现文件在集群中传输" class="headerlink" title="编写脚本，使用xsync实现文件在集群中传输"></a><strong>编写脚本，使用xsync实现文件在集群中传输</strong></h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment">############################################################################</span></span><br><span class="line"><span class="comment"># Desc    : xsync集群分发脚本</span></span><br><span class="line"><span class="comment"># Path    : /home/Jermyn/bin</span></span><br><span class="line"><span class="comment"># Auther  : Jermyn</span></span><br><span class="line"><span class="comment"># Date    : 2023-05-24</span></span><br><span class="line"><span class="comment"># Version : 1.0</span></span><br><span class="line"><span class="comment">############################################################################</span></span><br><span class="line"><span class="comment"># 前置需要一个ip.txt文件，注意：文件格式严按照“ipaddress空格hostname”格式如：“127.0.0.1 root”</span></span><br><span class="line">p1=<span class="variable">$1</span></span><br><span class="line">pcount=<span class="variable">$</span><span class="comment">#</span></span><br><span class="line">user=`whoami`</span><br><span class="line">HOSTNAME=`hostname`</span><br><span class="line">fname=`basename <span class="variable">$p1</span>`</span><br><span class="line"><span class="built_in">echo</span> fname=<span class="variable">$fname</span></span><br><span class="line"><span class="keyword">if</span>((pcount==<span class="number">0</span>)); then</span><br><span class="line">        <span class="built_in">echo</span> no args;</span><br><span class="line">        <span class="keyword">exit</span>;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">pdir=`cd <span class="literal">-P</span> <span class="variable">$</span>(dirname <span class="variable">$p1</span>); <span class="built_in">pwd</span>`</span><br><span class="line"><span class="built_in">echo</span> pdir=<span class="variable">$pdir</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> read ip hostname</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">[ <span class="string">&quot;<span class="variable">$hostname</span>&quot;</span> = <span class="string">&quot;<span class="variable">$HOSTNAME</span>&quot;</span> ] &amp;&amp; <span class="keyword">continue</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="literal">-e</span> <span class="string">&quot;-----------------------\033[5;34mSending a file to <span class="variable">$hostname</span>\033[0m-----------------------&quot;</span></span><br><span class="line">        rsync <span class="literal">-rvl</span> <span class="variable">$pdir</span>/<span class="variable">$fname</span> <span class="variable">$user</span><span class="selector-tag">@</span><span class="variable">$hostname:</span><span class="variable">$pdir</span></span><br><span class="line">        [ <span class="variable">$</span>? -<span class="type">eq</span> <span class="number">0</span> ]&amp;&amp; <span class="built_in">echo</span> <span class="literal">-e</span> <span class="string">&quot;           \033[5;32m已成功向<span class="variable">$hostname</span>传输文件\033[0m&quot;</span> || <span class="built_in">echo</span> <span class="literal">-e</span> <span class="string">&quot;           \033[5;31m文件传输失败，请检查主机<span class="variable">$hostname</span>\033[0m&quot;</span></span><br><span class="line">done &lt; ip.txt</span><br></pre></td></tr></table></figure><div class="tip fa-gamepad faa-horizontal animated"><p>集群配置</p></div><h3 id="集群部署规划"><a href="#集群部署规划" class="headerlink" title="集群部署规划"></a><strong>集群部署规划</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                HDFS                    YARN</span><br><span class="line">hadoop102       NameNode                NodeManager</span><br><span class="line">                DataNode</span><br><span class="line">hadoop103       DataNode                ResourceManager </span><br><span class="line">                                        NodeManager</span><br><span class="line">hadoop104       SecondaryNameNode</span><br><span class="line">                DataNode                NodeManager</span><br></pre></td></tr></table></figure><ul><li><strong>修改配置Core-site.xml</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop102:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><span class="p red">注：伪分布是NameNode是 hadoop100</span> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525100948.png" alt=""></li><li><strong>修改hadoop-env.sh</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.<span class="number">8.0</span>_144</span><br></pre></td></tr></table></figure><span class="p red">注：伪分布已添加，此处不做修改</span></li><li><strong>修改hdfs-site.xml</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定HDFS副本的数量 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><span class="p red">注：伪分布是dfs.replication是1，其实默认配置是3，伪分布式的时候不用改，因为只有一台节点的时候，不会产生3个副本，还是一个，如果节点多的话才会增加，snn的配置是新增加的</span> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525102138.png" alt=""></li><li><strong>配置yarn-env.sh</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.<span class="number">8.0</span>_144</span><br></pre></td></tr></table></figure><span class="p red">注：伪分布已添加，此处不做修改</span></li><li><strong>修改配置yarn-site.xml</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Reducer获取数据的方式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><span class="p red">注:伪分布式rm配置是hadoop100 在此改为hadoop103</span> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525103003.png" alt=""></li><li><p><strong>配置mapred-env.sh</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.<span class="number">8.0</span>_144</span><br></pre></td></tr></table></figure><ul><li><strong>配置mapred-site.xml</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> mapred<span class="literal">-site</span>.xml.template mapred<span class="literal">-site</span>.xml</span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定MR运行在Yarn上 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><span class="p red">注:伪分布式修改过，此处不用修改</span> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525103804.png" alt=""></li></ul></li><li><p><strong>在集群上分发配置好的Hadoop配置文件</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/</span><br></pre></td></tr></table></figure><h3 id="集群单点启动"><a href="#集群单点启动" class="headerlink" title="集群单点启动"></a><strong>集群单点启动</strong></h3><span class="p red">注意:此处如果是第一次启动，一定要注意需要格式化namenode，原因上面1.3.2思考已经注明，我这里是已经配置过伪分布，也格式化过，所以这里需要删除data/和log/文件夹</span><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop namenode <span class="literal">-format</span></span><br></pre></td></tr></table></figure></li><li><strong>在hadoop102、hadoop103以及hadoop104上分别启动DataNode</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop<span class="literal">-daemon</span>.sh <span class="built_in">start</span> datanode</span><br></pre></td></tr></table></figure></li><li><strong>jps 查看进程</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> jps</span><br><span class="line"><span class="number">3384</span> NameNode</span><br><span class="line"><span class="number">3516</span> Jps</span><br><span class="line"><span class="number">3308</span> DataNode</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop103</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> jps</span><br><span class="line"><span class="number">3227</span> Jps</span><br><span class="line"><span class="number">3117</span> DataNode</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop104</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> jps</span><br><span class="line"><span class="number">3200</span> Jps</span><br><span class="line"><span class="number">3082</span> DataNode</span><br></pre></td></tr></table></figure></li></ul><h3 id="SSH无密登录配置"><a href="#SSH无密登录配置" class="headerlink" title="SSH无密登录配置"></a><strong>SSH无密登录配置</strong></h3><ul><li><strong>免密登录原理</strong><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525110211.png" alt=""></li><li><strong>生成公钥和私钥：</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> ssh<span class="literal">-keygen</span> <span class="literal">-t</span> rsa</span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file <span class="keyword">in</span> which to save the key (/home/Jermyn/.ssh/id_rsa):</span><br><span class="line">Enter passphrase (empty <span class="keyword">for</span> no passphrase):</span><br><span class="line">Enter same passphrase again:</span><br><span class="line">Your identification has been saved <span class="keyword">in</span> /home/Jermyn/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved <span class="keyword">in</span> /home/Jermyn/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">SHA256:xAXniHrEhQ4pWD2L1xsyS8ixH5jv8Zsx9X8zghOE23o Jermyn@hadoop102</span><br><span class="line">The key<span class="string">&#x27;s randomart image is:</span></span><br><span class="line"><span class="string">+---[RSA 2048]----+</span></span><br><span class="line"><span class="string">| o.. . .o.o      |</span></span><br><span class="line"><span class="string">|. o =..+ =       |</span></span><br><span class="line"><span class="string">| . O *+ +..      |</span></span><br><span class="line"><span class="string">|  B Bo+.. .      |</span></span><br><span class="line"><span class="string">|   =.=.oS+       |</span></span><br><span class="line"><span class="string">|    =.....o      |</span></span><br><span class="line"><span class="string">|   . oo  ..o     |</span></span><br><span class="line"><span class="string">|    . .+. E.. +  |</span></span><br><span class="line"><span class="string">|      o. . ..o o |</span></span><br><span class="line"><span class="string">+----[SHA256]-----+</span></span><br><span class="line"><span class="string">[Jermyn@hadoop102 hadoop-2.7.2]$</span></span><br></pre></td></tr></table></figure></li><li><strong>将公钥拷贝到要免密登录的目标机器上</strong><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id hadoop102</span><br><span class="line">ssh-copy-id hadoop103</span><br><span class="line">ssh-copy-id hadoop104</span><br></pre></td></tr></table></figure></li><li><strong>.ssh文件夹下（~/.ssh）的文件功能解释</strong><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">known_hosts         记录ssh访问过计算机的公钥(public key)</span><br><span class="line">id_rsa              生成的私钥</span><br><span class="line">id_rsa.pub          生成的公钥</span><br><span class="line">authorized_keys	    存放授权过得无密登录服务器公钥</span><br></pre></td></tr></table></figure><span class="p red">注意： 还需要在hadoop102上采用root账号，配置一下无密登录到hadoop102、hadoop103、hadoop104； 还需要在hadoop103上采用Jermyn账号配置一下无密登录到hadoop102、hadoop103、hadoop104服务器上。(103上有一个resourcemanager在控制其他节点，所以也需要免密登录其他节点)</span></li></ul><div class="tip fa-gamepad faa-horizontal animated"><p>群起集群</p></div><ul><li><p><strong>配置/etc/hadoop/slaves</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/hadoop/slaves</span><br><span class="line"></span><br><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br></pre></td></tr></table></figure><span class="p red">注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。</span></li><li><p><strong>启动HDFS</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> sbin/<span class="built_in">start-dfs</span>.sh</span><br><span class="line">Starting namenodes on [<span class="type">hadoop102</span>]</span><br><span class="line">hadoop102: starting namenode, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-namenode-hadoop102</span>.out</span><br><span class="line">hadoop103: starting datanode, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-datanode-hadoop103</span>.out</span><br><span class="line">hadoop102: starting datanode, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-datanode-hadoop102</span>.out</span><br><span class="line">hadoop104: starting datanode, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-datanode-hadoop104</span>.out</span><br><span class="line">Starting secondary namenodes [<span class="type">hadoop104</span>]</span><br><span class="line">hadoop104: starting secondarynamenode, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-secondarynamenode-hadoop104</span>.out</span><br></pre></td></tr></table></figure><p>-<strong>启动YARN，在hadoop103</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> [<span class="type">Jermyn</span>@<span class="type">hadoop103</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> sbin/<span class="built_in">start-yarn</span>.sh</span><br><span class="line">starting yarn daemons</span><br><span class="line">starting resourcemanager, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/yarn<span class="literal">-Jermyn-resourcemanager-hadoop103</span>.out</span><br><span class="line">hadoop102: starting nodemanager, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/yarn<span class="literal">-Jermyn-nodemanager-hadoop102</span>.out</span><br><span class="line">hadoop104: starting nodemanager, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/yarn<span class="literal">-Jermyn-nodemanager-hadoop104</span>.out</span><br><span class="line">hadoop103: starting nodemanager, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/yarn<span class="literal">-Jermyn-nodemanager-hadoop103</span>.out</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop103</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> jps</span><br><span class="line"><span class="number">4871</span> NodeManager</span><br><span class="line"><span class="number">4711</span> ResourceManager</span><br><span class="line"><span class="number">5065</span> Jps</span><br><span class="line"><span class="number">4575</span> DataNode</span><br></pre></td></tr></table></figure></li><li><strong>Web端查看SecondaryNameNode</strong><br><a target="_blank" rel="noopener" href="http://hadoop104:50090/status.html">http://hadoop104:50090/status.html</a><br><a target="_blank" rel="noopener" href="http://hadoop104:50090/status.html"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525121828.png" alt=""></a></li></ul><h3 id="集群基本测试：上传小文件和大文件"><a href="#集群基本测试：上传小文件和大文件" class="headerlink" title="集群基本测试：上传小文件和大文件"></a><strong>集群基本测试：上传小文件和大文件</strong></h3><ul><li><strong>上传小文件</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hdfs dfs <span class="literal">-put</span> wcinput/ /user/Jermyn/input put: /user/Jermyn/input: No such file or directory</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hdfs dfs <span class="literal">-mkdir</span> <span class="literal">-p</span> /user/Jermyn/input</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hdfs dfs <span class="literal">-put</span> wcinput/ /user/Jermyn/input</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525152756.png" alt=""></li><li><strong>上传大文件</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs <span class="literal">-put</span> /opt/software/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>.tar.gz /user/Jermyn/input</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525152911.png" alt=""><span class="p red">可以直接点击下载在win下载，且两个块自动进行组合</span> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525153553.png" alt=""></li><li><strong>将两个文件下载（拼接）</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">subdir3</span>]<span class="variable">$</span> <span class="built_in">cat</span> blk_1073742741 &gt;&gt; tmp.txt</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">subdir3</span>]<span class="variable">$</span> <span class="built_in">cat</span> blk_1073742742 &gt;&gt; tmp.txt</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">subdir3</span>]<span class="variable">$</span> tar <span class="literal">-zxvf</span> tmp.txt</span><br><span class="line">hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/</span><br><span class="line">hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/NOTICE.txt</span><br><span class="line">hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/etc/</span><br><span class="line">hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/etc/hadoop/</span><br><span class="line">hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/etc/hadoop/kms<span class="literal">-log4j</span>.properties</span><br><span class="line">hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/etc/hadoop/mapred<span class="literal">-env</span>.sh</span><br><span class="line">hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/etc/hadoop/hdfs<span class="literal">-site</span>.xml</span><br><span class="line">hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/etc/hadoop/httpfs<span class="literal">-signature</span>.secret</span><br><span class="line">hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/etc/hadoop/mapred<span class="literal">-site</span>.xml.template</span><br><span class="line">...........................</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">subdir3</span>]<span class="variable">$</span> ll <span class="literal">-ah</span></span><br><span class="line">总用量 <span class="number">379</span>M</span><br><span class="line">drwxr<span class="literal">-xr-x</span>. <span class="number">3</span> Jermyn root  <span class="number">16</span>K <span class="number">5</span>月  <span class="number">25</span> <span class="number">15</span>:<span class="number">38</span> .</span><br><span class="line">drwxr<span class="literal">-xr-x</span>. <span class="number">6</span> Jermyn root <span class="number">4.0</span>K <span class="number">5</span>月  <span class="number">25</span> <span class="number">14</span>:<span class="number">28</span> ..</span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root  <span class="number">293</span> <span class="number">5</span>月  <span class="number">25</span> <span class="number">15</span>:<span class="number">19</span> blk_1073742740</span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root   <span class="number">11</span> <span class="number">5</span>月  <span class="number">25</span> <span class="number">15</span>:<span class="number">19</span> blk_1073742740_1916.meta</span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root <span class="number">128</span>M <span class="number">5</span>月  <span class="number">25</span> <span class="number">15</span>:<span class="number">22</span> blk_1073742741</span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root <span class="number">1.1</span>M <span class="number">5</span>月  <span class="number">25</span> <span class="number">15</span>:<span class="number">22</span> blk_1073742741_1917.meta</span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root  <span class="number">61</span>M <span class="number">5</span>月  <span class="number">25</span> <span class="number">15</span>:<span class="number">22</span> blk_1073742742</span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root <span class="number">485</span>K <span class="number">5</span>月  <span class="number">25</span> <span class="number">15</span>:<span class="number">22</span> blk_1073742742_1918.meta</span><br><span class="line">drwxr<span class="literal">-xr-x</span>. <span class="number">9</span> Jermyn root <span class="number">4.0</span>K <span class="number">5</span>月  <span class="number">22</span> <span class="number">2017</span> hadoop<span class="literal">-2</span>.<span class="number">7.2</span></span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root <span class="number">189</span>M <span class="number">5</span>月  <span class="number">25</span> <span class="number">15</span>:<span class="number">37</span> tmp.txt</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525153835.png" alt=""></li></ul><h3 id="hadoop相关执行命令"><a href="#hadoop相关执行命令" class="headerlink" title="hadoop相关执行命令"></a><strong>hadoop相关执行命令</strong></h3><ul><li>启动NameNode<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop<span class="literal">-daemon</span>.sh <span class="built_in">start</span> namenode</span><br></pre></td></tr></table></figure></li><li>启动DataNode<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop<span class="literal">-daemon</span>.sh <span class="built_in">start</span> datanode</span><br></pre></td></tr></table></figure></li><li><strong>在HDFS文件系统上创建一个input文件夹</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs <span class="literal">-mkdir</span> <span class="literal">-p</span> /user/Jermyn/input</span><br></pre></td></tr></table></figure></li><li><strong>将本地的 wcinput/wc.input 上传到hdfs的/user/Jermyn/input</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs <span class="literal">-put</span> wcinput/wc.input /user/Jermyn/input</span><br></pre></td></tr></table></figure></li><li><strong>执行官方WordCount案例</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop jar share/hadoop/mapreduce/hadoop<span class="literal">-mapreduce-examples-2</span>.<span class="number">7.2</span>.jar wordcount /user/Jermyn/input /user/Jermyn/output</span><br></pre></td></tr></table></figure></li><li><strong>查看运行的结果</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop dfs <span class="literal">-cat</span> /user/Jermyn/output/p*</span><br></pre></td></tr></table></figure></li><li><strong>删除输出结果</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop dfs <span class="literal">-rm</span> <span class="literal">-r</span> /user/Jermyn/out</span><br></pre></td></tr></table></figure></li><li><p><strong>关闭NodeManager 、ResourceManager和HistoryManage</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sbin/yarn<span class="literal">-daemon</span>.sh stop nodemanager</span><br><span class="line">sbin/yarn<span class="literal">-daemon</span>.sh stop resourcemanager</span><br><span class="line">sbin/mr<span class="literal">-jobhistory-daemon</span>.sh stop historyserver</span><br></pre></td></tr></table></figure></li><li><p><strong>启动NodeManager 、ResourceManager和HistoryManager</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sbin/yarn<span class="literal">-daemon</span>.sh <span class="built_in">start</span> nodemanager</span><br><span class="line">sbin/yarn<span class="literal">-daemon</span>.sh <span class="built_in">start</span> resourcemanager</span><br><span class="line">sbin/mr<span class="literal">-jobhistory-daemon</span>.sh <span class="built_in">start</span> historyserver</span><br></pre></td></tr></table></figure></li><li><strong>启动HDFS</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/<span class="built_in">start-dfs</span>.sh</span><br></pre></td></tr></table></figure>-<strong>启动YARN，在hadoop103</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/<span class="built_in">start-yarn</span>.sh</span><br></pre></td></tr></table></figure></li></ul><h3 id="集群时间同步"><a href="#集群时间同步" class="headerlink" title="集群时间同步"></a>集群时间同步</h3><p>时间同步的方式：找一个机器，作为时间服务器，所有的机器与这台集群时间进行定时的同步，比如，每隔十分钟，同步一次时间。<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525161707.png" alt=""></p><ul><li><strong>时间服务器配置（必须root用户）</strong><ul><li><strong>检查ntp是否安装</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm <span class="literal">-qa</span>|grep ntp</span><br></pre></td></tr></table></figure></li><li><strong>修改ntp配置文件/ etc/ntp.conf</strong><br>修改内容如下:<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">修改1（授权192.168.1.0-192.168.1.255网段上的所有机器可以从这台机器上查询和同步时间）</span><br><span class="line">#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap为</span><br><span class="line">restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</span><br><span class="line"></span><br><span class="line">修改2（集群在局域网中，不使用其他互联网上的时间）</span><br><span class="line">server 0.centos.pool.ntp.org iburst</span><br><span class="line">server 1.centos.pool.ntp.org iburst</span><br><span class="line">server 2.centos.pool.ntp.org iburst</span><br><span class="line">server 3.centos.pool.ntp.org iburst为</span><br><span class="line">#server 0.centos.pool.ntp.org iburst</span><br><span class="line">#server 1.centos.pool.ntp.org iburst</span><br><span class="line">#server 2.centos.pool.ntp.org iburst</span><br><span class="line">#server 3.centos.pool.ntp.org iburst</span><br><span class="line"></span><br><span class="line">添加3（当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步）</span><br><span class="line">server 127.127.1.0</span><br><span class="line">fudge 127.127.1.0 stratum 10</span><br></pre></td></tr></table></figure></li><li><strong>修改/etc/sysconfig/ntpd 文件</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">增加内容如下（让硬件时间与系统时间一起同步）</span><br><span class="line"></span><br><span class="line">SYNC_HWCLOCK=yes</span><br></pre></td></tr></table></figure></li><li><strong>查看ntpd状态</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service ntpd status</span><br></pre></td></tr></table></figure></li><li><strong>启动ntpd</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service ntpd <span class="built_in">start</span></span><br></pre></td></tr></table></figure></li><li><strong>查看ntpd状态</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">hadoop102</span> ~]<span class="comment"># service ntpd status</span></span><br><span class="line">Redirecting to /bin/systemctl status ntpd.service</span><br><span class="line">● ntpd.service - Network Time Service</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/ntpd.service; disabled; vendor preset: disabled)</span><br><span class="line">   Active: inactive (dead)</span><br><span class="line">[<span class="type">root</span>@<span class="type">hadoop102</span> ~]<span class="comment"># service ntpd start</span></span><br><span class="line">Redirecting to /bin/systemctl <span class="built_in">start</span> ntpd.service</span><br><span class="line">[<span class="type">root</span>@<span class="type">hadoop102</span> ~]<span class="comment"># service ntpd status</span></span><br><span class="line">Redirecting to /bin/systemctl status ntpd.service</span><br><span class="line">● ntpd.service - Network Time Service</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/ntpd.service; disabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since 四 <span class="number">2023</span><span class="literal">-05-25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">05</span> CST; <span class="number">2</span>s ago</span><br><span class="line">  <span class="keyword">Process</span>: <span class="number">12860</span> ExecStart=/usr/sbin/ntpd <span class="literal">-u</span> ntp:ntp <span class="variable">$OPTIONS</span> (code=exited, status=<span class="number">0</span>/SUCCESS)</span><br><span class="line"> Main PID: <span class="number">12863</span> (ntpd)</span><br><span class="line">    Tasks: <span class="number">1</span></span><br><span class="line">   CGroup: /system.slice/ntpd.service</span><br><span class="line">           └─<span class="number">12863</span> /usr/sbin/ntpd <span class="literal">-u</span> ntp:ntp <span class="literal">-g</span></span><br><span class="line"></span><br><span class="line"><span class="number">5</span>月 <span class="number">25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">05</span> hadoop102 ntpd[<span class="number">12863</span>]: Listen normally on <span class="number">2</span> lo <span class="number">127.0</span>.<span class="number">0.1</span> UDP <span class="number">123</span></span><br><span class="line"><span class="number">5</span>月 <span class="number">25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">05</span> hadoop102 ntpd[<span class="number">12863</span>]: Listen normally on <span class="number">3</span> ens33 <span class="number">192.168</span>.<span class="number">10.102</span> UDP <span class="number">123</span></span><br><span class="line"><span class="number">5</span>月 <span class="number">25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">05</span> hadoop102 ntpd[<span class="number">12863</span>]: Listen normally on <span class="number">4</span> virbr0 <span class="number">192.168</span>.<span class="number">122.1</span> UDP <span class="number">123</span></span><br><span class="line"><span class="number">5</span>月 <span class="number">25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">05</span> hadoop102 ntpd[<span class="number">12863</span>]: Listen normally on <span class="number">5</span> lo ::<span class="number">1</span> UDP <span class="number">123</span></span><br><span class="line"><span class="number">5</span>月 <span class="number">25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">05</span> hadoop102 ntpd[<span class="number">12863</span>]: Listen normally on <span class="number">6</span> ens33 fe80::<span class="number">4</span>e60:<span class="number">766</span>f:adbc:<span class="number">1548</span> UDP <span class="number">123</span></span><br><span class="line"><span class="number">5</span>月 <span class="number">25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">05</span> hadoop102 ntpd[<span class="number">12863</span>]: Listening on routing socket on fd <span class="comment">#23 for interface updates</span></span><br><span class="line"><span class="number">5</span>月 <span class="number">25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">05</span> hadoop102 ntpd[<span class="number">12863</span>]: <span class="number">0.0</span>.<span class="number">0.0</span> c016 <span class="number">06</span> restart</span><br><span class="line"><span class="number">5</span>月 <span class="number">25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">05</span> hadoop102 ntpd[<span class="number">12863</span>]: <span class="number">0.0</span>.<span class="number">0.0</span> c012 <span class="number">02</span> freq_set kernel <span class="number">0.000</span> PPM</span><br><span class="line"><span class="number">5</span>月 <span class="number">25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">05</span> hadoop102 ntpd[<span class="number">12863</span>]: <span class="number">0.0</span>.<span class="number">0.0</span> c011 <span class="number">01</span> freq_not_set</span><br><span class="line"><span class="number">5</span>月 <span class="number">25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">06</span> hadoop102 ntpd[<span class="number">12863</span>]: <span class="number">0.0</span>.<span class="number">0.0</span> c514 <span class="number">04</span> freq_mode</span><br><span class="line">[<span class="type">root</span>@<span class="type">hadoop102</span> ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure></li><li><strong>设置ntpd服务开机启动</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">hadoop102</span> ~]<span class="comment"># chkconfig ntpd on</span></span><br><span class="line">注意：正在将请求转发到“systemctl enable ntpd.service”。</span><br><span class="line">Created symlink from /etc/systemd/system/multi<span class="literal">-user</span>.target.wants/ntpd.service to /usr/lib/systemd/system/ntpd.service.</span><br></pre></td></tr></table></figure></li><li><strong>其他机器配置（必须root用户）</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">（<span class="number">1</span>）在其他机器配置<span class="number">10</span>分钟与时间服务器同步一次</span><br><span class="line">[<span class="type">root</span>@<span class="type">hadoop103</span>桌面]<span class="comment"># crontab -e</span></span><br><span class="line">编写定时任务如下：</span><br><span class="line">*/<span class="number">10</span> * * * * /usr/sbin/ntpdate hadoop102</span><br><span class="line">（<span class="number">2</span>）修改任意机器时间</span><br><span class="line">[<span class="type">root</span>@<span class="type">hadoop103</span>桌面]<span class="comment"># date -s &quot;2017-9-11 11:11:11&quot;</span></span><br><span class="line">（<span class="number">3</span>）十分钟后查看机器是否与时间服务器同步</span><br><span class="line">[<span class="type">root</span>@<span class="type">hadoop103</span>桌面]<span class="comment"># date</span></span><br><span class="line">说明：测试的时候可以将<span class="number">10</span>分钟调整为<span class="number">1</span>分钟，节省时间。</span><br></pre></td></tr></table></figure></li></ul></li></ul><h1 id="第四章-HDFS-概述"><a href="#第四章-HDFS-概述" class="headerlink" title="第四章 HDFS 概述"></a>第四章 HDFS 概述</h1><h2 id="HDFS优缺点"><a href="#HDFS优缺点" class="headerlink" title="HDFS优缺点"></a>HDFS优缺点</h2><ul><li><p><strong>优点</strong></p><ul><li>高容错性：<br>（1）数据自动保存多个副本。它通过增加副本的形式，提高容错性；<br>（2）某一个副本丢失以后，它可以自动恢复。</li><li>适合处理大数据：<br>（1）数据规模：能够处理数据规模达到GB、TB、甚至PB级别的数据；<br>（2）文件规模：能够处理百万规模以上的文件数量，数量相当之大。</li><li>可构建在廉价机器上，通过多副本机制，提高可靠性。</li></ul></li><li><p><strong>缺点</strong></p><ul><li>不适合低延时数据访问，比如毫秒级的存储数据，是做不到的。</li><li>无法高效的对大量小文件进行存储。<br>（1）存储大量小文件的话，它会占用NameNode大量的内存来存储文件目录和块信息。这样是不可取的，因为NameNode的内存总是有限的；<br>（2）小文件存储的寻址时间会超过读取时间，它违反了HDFS的设计目标。</li><li>不支持并发写入、文件随机修改。<br>（1）一个文件只能有一个写，不允许多个线程同时写；<br>（2）仅支持数据append（追加），不支持文件的随机修改。</li></ul></li></ul><h2 id="HDFS组成架构"><a href="#HDFS组成架构" class="headerlink" title="HDFS组成架构"></a>HDFS组成架构</h2><ol><li>NameNode（nn）：就是Master，它是一个主管、管理者。<br>（1）管理HDFS的名称空间；<br>（2）配置副本策略；<br>（3）管理数据块（Block）映射信息；<br>（4）处理客户端读写请求。</li><li>DataNode：就是Slave。NameNode下达命令，DataNode执行实际的操作。<br>（1）存储实际的数据块；<br>（2）执行数据块的读/写操作。</li><li>Client：就是客户端。<br>（1）文件切分。文件上传HDFS的时候，Client将文件切分成一个一个的Block，然后进行上传；<br>（2）与NameNode交互，获取文件的位置信息；<br>（3）与DataNode交互，读取或者写入数据；<br>（4）Client提供一些命令来管理HDFS，比如NameNode格式化；<br>（5）Client可以通过一些命令来访问HDFS，比如对HDFS增删查改操作；</li><li>Secondary NameNode：并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。<br>（1）辅助NameNode，分担其工作量，比如定期合并Fsimage和Edits，并推送给NameNode ；<br>（2）在紧急情况下，可辅助恢复NameNode。</li></ol><h2 id="HDFS文件块大小"><a href="#HDFS文件块大小" class="headerlink" title="HDFS文件块大小"></a>HDFS文件块大小</h2><p>HDFS中的文件在物理上是分块存储（Block），块的大小可以通过配置参数( dfs.blocksize)来规定，默认大小在Hadoop2.x版本中是128M，老版本中是64M。<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525195408.png" alt=""></p><h1 id="第五章-HDFS的Shell操作"><a href="#第五章-HDFS的Shell操作" class="headerlink" title="第五章 HDFS的Shell操作"></a>第五章 HDFS的Shell操作</h1><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop fs 具体命令</span><br><span class="line">bin/hdfs dfs 具体命令</span><br></pre></td></tr></table></figure><h2 id="常用命令实操"><a href="#常用命令实操" class="headerlink" title="常用命令实操"></a>常用命令实操</h2><ol><li>启动Hadoop集群<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> ~]<span class="variable">$</span> <span class="built_in">start-dfs</span>.sh</span><br><span class="line">Starting namenodes on [<span class="type">hadoop102</span>]</span><br><span class="line">hadoop102: starting namenode, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-namenode-hadoop102</span>.out</span><br><span class="line">hadoop103: starting datanode, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-datanode-hadoop103</span>.out</span><br><span class="line">hadoop104: starting datanode, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-datanode-hadoop104</span>.out</span><br><span class="line">hadoop102: starting datanode, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-datanode-hadoop102</span>.out</span><br><span class="line">Starting secondary namenodes [<span class="type">hadoop104</span>]</span><br><span class="line">hadoop104: starting secondarynamenode, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-secondarynamenode-hadoop104</span>.out</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> ~]<span class="variable">$</span> jps</span><br><span class="line"><span class="number">2305</span> DataNode</span><br><span class="line"><span class="number">2409</span> NodeManager</span><br><span class="line"><span class="number">2729</span> Jps</span><br><span class="line"><span class="number">2190</span> NameNode</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop103</span> ~]<span class="variable">$</span> <span class="built_in">start-yarn</span>.sh</span><br><span class="line">starting yarn daemons</span><br><span class="line">starting resourcemanager, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/yarn<span class="literal">-Jermyn-resourcemanager-hadoop103</span>.out</span><br><span class="line">hadoop104: starting nodemanager, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/yarn<span class="literal">-Jermyn-nodemanager-hadoop104</span>.out</span><br><span class="line">hadoop103: starting nodemanager, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/yarn<span class="literal">-Jermyn-nodemanager-hadoop103</span>.out</span><br><span class="line">hadoop102: starting nodemanager, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/yarn<span class="literal">-Jermyn-nodemanager-hadoop102</span>.out</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop103</span> ~]<span class="variable">$</span> jps</span><br><span class="line"><span class="number">2561</span> Jps</span><br><span class="line"><span class="number">2066</span> ResourceManager</span><br><span class="line"><span class="number">2005</span> DataNode</span><br><span class="line"><span class="number">2191</span> NodeManager</span><br></pre></td></tr></table></figure></li><li>-help：输出这个命令参数(查某个命令的使用)<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> ~]<span class="variable">$</span> hadoop fs <span class="literal">-help</span> mkdir</span><br><span class="line"><span class="literal">-mkdir</span> [-<span class="type">p</span>] &lt;path&gt; ... :</span><br><span class="line">  Create a directory <span class="keyword">in</span> specified location.</span><br><span class="line"></span><br><span class="line">  <span class="literal">-p</span>  <span class="keyword">Do</span> not fail <span class="keyword">if</span> the directory already exists</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> ~]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li>-ls: 显示目录信息　<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> ~]<span class="variable">$</span> hadoop fs <span class="literal">-ls</span> /</span><br><span class="line">Found <span class="number">1</span> items</span><br><span class="line">drwxr<span class="literal">-xr-x</span>   - Jermyn supergroup          <span class="number">0</span> <span class="number">2023</span><span class="literal">-05-25</span> <span class="number">14</span>:<span class="number">24</span> /user</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> ~]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li>-mkdir：在HDFS上创建目录<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> ~]<span class="variable">$</span> hadoop fs <span class="literal">-mkdir</span> <span class="literal">-p</span> /folder1/folder2/folder3</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230526103718.png" alt=""></li><li>-moveFromLocal：从本地剪切粘贴到HDFS<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> ll</span><br><span class="line">总用量 <span class="number">8</span></span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">38</span> demo.txt</span><br><span class="line">drwxr<span class="literal">-xr-x</span>. <span class="number">15</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">25</span> <span class="number">10</span>:<span class="number">52</span> hadoop<span class="literal">-2</span>.<span class="number">7.2</span></span><br><span class="line">drwxr<span class="literal">-xr-x</span>.  <span class="number">8</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">18</span>:<span class="number">55</span> jdk1.<span class="number">8.0</span>_144</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-moveFromLocal</span> ./demo.txt /folder1/folder2/folder3</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> ll</span><br><span class="line">总用量 <span class="number">8</span></span><br><span class="line">drwxr<span class="literal">-xr-x</span>. <span class="number">15</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">25</span> <span class="number">10</span>:<span class="number">52</span> hadoop<span class="literal">-2</span>.<span class="number">7.2</span></span><br><span class="line">drwxr<span class="literal">-xr-x</span>.  <span class="number">8</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">18</span>:<span class="number">55</span> jdk1.<span class="number">8.0</span>_144</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230526104029.png" alt=""></li><li>-appendToFile：追加一个文件到已经存在的文件末尾<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> vim demo2.txt</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> <span class="built_in">cat</span> demo2.txt</span><br><span class="line">hello hadoop2.<span class="number">7.2</span></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-appendToFile</span> ./demo2.txt /folder1/folder2/folder3/demo.txt</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230526104628.png" alt=""></li><li>-cat：显示文件内容<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> <span class="built_in">cat</span> demo2.txt</span><br><span class="line">hello hadoop2.<span class="number">7.2</span></span><br></pre></td></tr></table></figure></li><li>-chgrp 、-chmod、-chown：Linux文件系统中的用法一样，修改文件所属权限<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-chgrp</span> Jermyn /folder1/folder2/folder3/demo.txt</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230526105125.png" alt=""></li><li>-copyFromLocal：从本地文件系统中拷贝文件到HDFS路径去<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-copyFromLocal</span> ./DEMO.txt /folder1/folder2/folder3</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230526105506.png" alt=""></li><li>-copyToLocal：从HDFS拷贝到本地<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> ll</span><br><span class="line">总用量 <span class="number">12</span></span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root     <span class="number">18</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">43</span> demo2.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">52</span> DEMO.txt</span><br><span class="line">drwxr<span class="literal">-xr-x</span>. <span class="number">15</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">25</span> <span class="number">10</span>:<span class="number">52</span> hadoop<span class="literal">-2</span>.<span class="number">7.2</span></span><br><span class="line">drwxr<span class="literal">-xr-x</span>.  <span class="number">8</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">18</span>:<span class="number">55</span> jdk1.<span class="number">8.0</span>_144</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-copyToLocal</span> /folder1/folder2/folder3/demo.txt ./</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> ll</span><br><span class="line">总用量 <span class="number">16</span></span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root     <span class="number">18</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">43</span> demo2.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root     <span class="number">18</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">57</span> demo.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">52</span> DEMO.txt</span><br><span class="line">drwxr<span class="literal">-xr-x</span>. <span class="number">15</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">25</span> <span class="number">10</span>:<span class="number">52</span> hadoop<span class="literal">-2</span>.<span class="number">7.2</span></span><br><span class="line">drwxr<span class="literal">-xr-x</span>.  <span class="number">8</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">18</span>:<span class="number">55</span> jdk1.<span class="number">8.0</span>_144</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li>-cp ：从HDFS的一个路径拷贝到HDFS的另一个路径<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-cp</span> /user/Jermyn/input/wcinput /folder1/folder2/folder3</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-ls</span> /folder1/folder2/folder3</span><br><span class="line">Found <span class="number">3</span> items</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">3</span> Jermyn supergroup          <span class="number">0</span> <span class="number">2023</span><span class="literal">-05-26</span> <span class="number">10</span>:<span class="number">54</span> /folder1/folder2/folder3/DEMO.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">3</span> Jermyn Jermyn             <span class="number">18</span> <span class="number">2023</span><span class="literal">-05-26</span> <span class="number">10</span>:<span class="number">44</span> /folder1/folder2/folder3/demo.txt</span><br><span class="line">drwxr<span class="literal">-xr-x</span>   - Jermyn supergroup          <span class="number">0</span> <span class="number">2023</span><span class="literal">-05-26</span> <span class="number">10</span>:<span class="number">59</span> /folder1/folder2/folder3/wcinput</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230526110030.png" alt=""></li><li>-mv：在HDFS目录中移动文件<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-mv</span> /folder1/folder2/folder3/demo.txt /user/Jermyn/input</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-ls</span> /user/Jermyn/input</span><br><span class="line">Found <span class="number">3</span> items</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">3</span> Jermyn Jermyn             <span class="number">18</span> <span class="number">2023</span><span class="literal">-05-26</span> <span class="number">10</span>:<span class="number">44</span> /user/Jermyn/input/demo.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">3</span> Jermyn supergroup  <span class="number">197657687</span> <span class="number">2023</span><span class="literal">-05-25</span> <span class="number">15</span>:<span class="number">22</span> /user/Jermyn/input/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>.tar.gz</span><br><span class="line">drwxr<span class="literal">-xr-x</span>   - Jermyn supergroup          <span class="number">0</span> <span class="number">2023</span><span class="literal">-05-25</span> <span class="number">15</span>:<span class="number">19</span> /user/Jermyn/input/wcinput</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230526110313.png" alt=""></li><li>-get：等同于copyToLocal，就是从HDFS下载文件到本地<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-get</span> /folder1/folder2/folder3/wcinput /opt/module/</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> ll</span><br><span class="line">总用量 <span class="number">20</span></span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root     <span class="number">18</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">43</span> demo2.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root     <span class="number">18</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">57</span> demo.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">52</span> DEMO.txt</span><br><span class="line">drwxr<span class="literal">-xr-x</span>. <span class="number">15</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">25</span> <span class="number">10</span>:<span class="number">52</span> hadoop<span class="literal">-2</span>.<span class="number">7.2</span></span><br><span class="line">drwxr<span class="literal">-xr-x</span>.  <span class="number">8</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">18</span>:<span class="number">55</span> jdk1.<span class="number">8.0</span>_144</span><br><span class="line">drwxr<span class="literal">-xr-x</span>.  <span class="number">2</span> Jermyn root   <span class="number">4096</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">11</span>:<span class="number">09</span> wcinput</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> </span><br></pre></td></tr></table></figure></li><li>-put：等同于copyFromLocal<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> ll</span><br><span class="line">总用量 <span class="number">20</span></span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root     <span class="number">18</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">43</span> demo2.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root     <span class="number">18</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">57</span> demo.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">52</span> DEMO.txt</span><br><span class="line">drwxr<span class="literal">-xr-x</span>. <span class="number">15</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">25</span> <span class="number">10</span>:<span class="number">52</span> hadoop<span class="literal">-2</span>.<span class="number">7.2</span></span><br><span class="line">drwxr<span class="literal">-xr-x</span>.  <span class="number">8</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">18</span>:<span class="number">55</span> jdk1.<span class="number">8.0</span>_144</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">11</span>:<span class="number">12</span> log1.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">11</span>:<span class="number">12</span> log2.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">11</span>:<span class="number">12</span> log3.txt</span><br><span class="line">drwxr<span class="literal">-xr-x</span>.  <span class="number">2</span> Jermyn root   <span class="number">4096</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">11</span>:<span class="number">09</span> wcinput</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-put</span> log* /log</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230526111445.png" alt=""></li><li>-getmerge：合并下载多个文件，比如HDFS的目录 /user/Jermyn/test下有多个文件:log.1, log.2,log.3,…<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-getmerge</span> /log/log* /opt/module/log_mege.txt</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> ll</span><br><span class="line">总用量 <span class="number">20</span></span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root     <span class="number">18</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">43</span> demo2.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root     <span class="number">18</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">57</span> demo.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">52</span> DEMO.txt</span><br><span class="line">drwxr<span class="literal">-xr-x</span>. <span class="number">15</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">25</span> <span class="number">10</span>:<span class="number">52</span> hadoop<span class="literal">-2</span>.<span class="number">7.2</span></span><br><span class="line">drwxr<span class="literal">-xr-x</span>.  <span class="number">8</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">18</span>:<span class="number">55</span> jdk1.<span class="number">8.0</span>_144</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">11</span>:<span class="number">12</span> log1.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">11</span>:<span class="number">12</span> log2.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">11</span>:<span class="number">12</span> log3.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">11</span>:<span class="number">16</span> log_mege.txt</span><br><span class="line">drwxr<span class="literal">-xr-x</span>.  <span class="number">2</span> Jermyn root   <span class="number">4096</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">11</span>:<span class="number">09</span> wcinput</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li>-tail：显示一个文件的末尾<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-tail</span> /user/Jermyn/input/wcinput/wc.input</span><br><span class="line">JERMYN JREMYEN Jermfdyn java JAVA hadoop HADOOP</span><br><span class="line">JERMYTN JREMYDN Jefrmyn java JAVA hadoop HADOOP</span><br><span class="line">JERMYCN JRECMYN Jermyfn javaC JAVAA hadoop HADOOP</span><br><span class="line">EJERMYN JREEMYN Jermyn javac JAVA hadoop HADOOP</span><br><span class="line">JEERMYN JREEMYN Jermyn javaSE JAVA hadoop HADOOP</span><br><span class="line">JERDMYN JEREMYN Jermyn javaEE JAVA hadoop HADOOP</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li>-rm：删除文件或文件夹<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-rm</span> <span class="literal">-R</span> /folder1</span><br><span class="line"><span class="number">23</span>/<span class="number">05</span>/<span class="number">26</span> <span class="number">11</span>:<span class="number">21</span>:<span class="number">44</span> INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = <span class="number">0</span> minutes, Emptier interval = <span class="number">0</span> minutes.</span><br><span class="line">Deleted /folder1</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230526112207.png" alt=""></li><li>-rmdir：删除空目录<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-mkdir</span> /FolderEmpt</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-rmdir</span> /FolderEmpt</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li>-du统计文件夹的大小信息<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-du</span> /</span><br><span class="line"><span class="number">0</span>          /log</span><br><span class="line"><span class="number">197657998</span>  /user</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li>-setrep：设置HDFS中文件的副本数量<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-setrep</span> <span class="number">7</span> /user/Jermyn/input/wcinput/wc.input</span><br><span class="line">Replication <span class="number">7</span> <span class="built_in">set</span>: /user/Jermyn/input/wcinput/wc.input</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230526112849.png" alt=""><span class="p red">这里设置的副本数只是记录在NameNode的元数据中，是否真的会有这么多副本，还得看DataNode的数量，因为目前只有3台设备，最多也就3个副本，只有节点数的增加到7台时，副本数才能达到7</span></li></ol><h1 id="第六章-HDFS客户端操作"><a href="#第六章-HDFS客户端操作" class="headerlink" title="第六章 HDFS客户端操作"></a>第六章 HDFS客户端操作</h1><h2 id="HDFS客户端环境准备"><a href="#HDFS客户端环境准备" class="headerlink" title="HDFS客户端环境准备"></a>HDFS客户端环境准备</h2><ol><li><strong>Win下面配置高级环境变量</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">HADOOP_HOME=D:\PATH_EN\hadoop<span class="literal">-2</span>.<span class="number">7.2</span></span><br><span class="line"></span><br><span class="line">path添加：</span><br><span class="line">PATH=%HADOOP_HOME%\bin</span><br></pre></td></tr></table></figure></li><li><strong>创建一个Maven工程HdfsClient</strong><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230527195758.png" alt=""></li><li><strong>导入相应的依赖坐标+日志添加</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span> <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.example<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>HdfsClient<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">packaging</span>&gt;</span>jar<span class="tag">&lt;/<span class="name">packaging</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>HdfsClient<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.apache.org<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.8.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><strong>注意：如果Eclipse/Idea打印不出日志，需要在项目的src/main/resources目录下，新建一个文件，命名为“log4j.properties”，在文件中填入</strong><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">log4j.rootLogger</span>=<span class="string">INFO, stdout</span></span><br><span class="line"><span class="attr">log4j.appender.stdout</span>=<span class="string">org.apache.log4j.ConsoleAppender</span></span><br><span class="line"><span class="attr">log4j.appender.stdout.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="attr">log4j.appender.stdout.layout.ConversionPattern</span>=<span class="string">%d %p [%c] - %m%n</span></span><br><span class="line"><span class="attr">log4j.appender.logfile</span>=<span class="string">org.apache.log4j.FileAppender</span></span><br><span class="line"><span class="attr">log4j.appender.logfile.File</span>=<span class="string">target/spring.log</span></span><br><span class="line"><span class="attr">log4j.appender.logfile.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="attr">log4j.appender.logfile.layout.ConversionPattern</span>=<span class="string">%d %p [%c] - %m%n</span></span><br></pre></td></tr></table></figure></li><li><strong>创建HdfsClient类测试</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.hdfs;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"><span class="keyword">import</span> java.net.URISyntaxException;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HDFSClient</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, URISyntaxException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * hadoop在访问hdfs的时候会进行权限认证，取用户名的过程是这样的：</span></span><br><span class="line"><span class="comment">         * 读取HADOOP_USER_NAME系统环境变量，如果不为空，那么拿它作username，如果为空</span></span><br><span class="line"><span class="comment">         * 读取HADOOP_USER_NAME这个java环境变量，如果为空</span></span><br><span class="line"><span class="comment">         * 从com.sun.security.auth.NTUserPrincipal或者com.sun.security.auth.UnixPrincipal的实例获取username。</span></span><br><span class="line"><span class="comment">         * 如果以上尝试都失败，那么抛出异常LoginException(&quot;Can’t find user name&quot;)</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"><span class="comment">//        Properties properties = System.getProperties();</span></span><br><span class="line"><span class="comment">//        properties.setProperty(&quot;HADOOP_USER_NAME&quot;, &quot;Jermyn&quot;);</span></span><br><span class="line"></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>, <span class="string">&quot;hdfs://hadoop102:9000&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1.获取hdfs客户端对象</span></span><br><span class="line"><span class="comment">//        FileSystem fileSystem = FileSystem.get(conf);</span></span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fileSystem</span> <span class="operator">=</span> FileSystem.get(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>), conf, <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 2.在hdfs上创建路径</span></span><br><span class="line">        fileSystem.mkdirs(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/hdfsClient/demo/test&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3.关闭资源</span></span><br><span class="line">        fileSystem.close();</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;OVER&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230527200459.png" alt=""></li></ol><h2 id="HDFS的API操作"><a href="#HDFS的API操作" class="headerlink" title="HDFS的API操作"></a>HDFS的API操作</h2><h3 id="HDFS文件上传（测试参数优先级）"><a href="#HDFS文件上传（测试参数优先级）" class="headerlink" title="HDFS文件上传（测试参数优先级）"></a>HDFS文件上传（测试参数优先级）</h3><ol><li><strong>编写源代码</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testCopyFromLocalFile</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1.获取fs对象</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fileSystem</span> <span class="operator">=</span> FileSystem.get(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>), conf, <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2.执行上传API</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">src</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:/TestData.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 第一次客户端代码中设置的值默认副本为3</span></span><br><span class="line"><span class="comment">//        Path dst = new Path(&quot;/hdfsClient/demo/test&quot;);</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 第二次配置xml，副本设为1</span></span><br><span class="line"><span class="comment">//        Path dst = new Path(&quot;/hdfsClient/demo/test/TestData2.txt&quot;);</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 第三次设置副本数</span></span><br><span class="line">    conf.set(<span class="string">&quot;dfs.replication&quot;</span>,<span class="string">&quot;2&quot;</span>);</span><br><span class="line">    <span class="type">Path</span> <span class="variable">dst</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/hdfsClient/demo/test/TestData3.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">    fileSystem.copyFromLocalFile(src, dst);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3.关闭对象</span></span><br><span class="line">    fileSystem.close();</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">&quot;over&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230527202444.png" alt=""></li><li><strong>将hdfs-site.xml拷贝到项目的根目录下</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230527203019.png" alt=""></li><li><strong>参数优先级</strong><br>参数优先级排序：<span class="p red">（1）客户端代码中设置的值 >（2）ClassPath下的用户自定义配置文件 >（3）然后是服务器的默认配置</span><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230527203244.png" alt=""></li></ol><h3 id="HDFS文件下载"><a href="#HDFS文件下载" class="headerlink" title="HDFS文件下载"></a>HDFS文件下载</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testCopyToLocalFile</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1.获取文件系统</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fileSystem</span> <span class="operator">=</span> FileSystem.get(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>), configuration, <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2.执行下载操作</span></span><br><span class="line">    <span class="comment">// boolean delSrc 指是否将原文件删除</span></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">delSrc</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Path src 指要下载的文件路径</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">src</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/hdfsClient/demo/test/TestData.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Path dst 指将文件下载到的路径</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">dst</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;C:\\Users\\Administrator\\Desktop&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// boolean useRawLocalFileSystem 是否开启文件校验</span></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">useRawLocalFileSystem</span> <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line">    fileSystem.copyToLocalFile(delSrc, src, dst, useRawLocalFileSystem);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3.关闭资源</span></span><br><span class="line">    fileSystem.close();</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">&quot;OVER&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528104839.png" alt=""></p><h3 id="HDFS文件的删除"><a href="#HDFS文件的删除" class="headerlink" title="HDFS文件的删除"></a>HDFS文件的删除</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testDelete</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1 获取文件系统</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fileSystem</span> <span class="operator">=</span> FileSystem.get(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>), conf, <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2 执行删除</span></span><br><span class="line">    <span class="comment">// 要删除的路径</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">f</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/hdfsClient/demo/test/TestData3.txt&quot;</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 如果path是一个目录并设置为true，则删除该目录，否则抛出异常。在文件的情况下，递归可以设置为true或false。</span></span><br><span class="line">    <span class="type">boolean</span> recursive= <span class="literal">true</span>;</span><br><span class="line">    fileSystem.delete(f, recursive);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3 关闭资源</span></span><br><span class="line">    fileSystem.close();</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">&quot;OVER&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="HDFS文件名更改"><a href="#HDFS文件名更改" class="headerlink" title="HDFS文件名更改"></a>HDFS文件名更改</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testRename</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1 获取文件系统</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>), configuration, <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// src -要重命名的路径</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">src</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/hdfsClient/demo/test/TestData2.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// dst -重命名后的新路径</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">dst</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/hdfsClient/demo/test/TestData3.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2 修改文件名称</span></span><br><span class="line">    fs.rename(src,dst);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3 关闭资源</span></span><br><span class="line">    fs.close();</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">&quot;OVER&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="HDFS文件详情查看"><a href="#HDFS文件详情查看" class="headerlink" title="HDFS文件详情查看"></a>HDFS文件详情查看</h3><p><strong>查看文件名称、权限、长度、块信息</strong><br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testListFiles</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException &#123;</span><br><span class="line">    <span class="comment">// 1 获取文件系统</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>), configuration, <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2 获取文件详情</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// f 是递归路径</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">f</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/&quot;</span>);</span><br><span class="line">    <span class="comment">// 递归地遍历</span></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">recursive</span> <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="comment">// 返回遍历文件状态的迭代器</span></span><br><span class="line">    RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fs.listFiles(f, recursive);</span><br><span class="line">    <span class="keyword">while</span> (listFiles.hasNext()) &#123;</span><br><span class="line">        <span class="type">LocatedFileStatus</span> <span class="variable">status</span> <span class="operator">=</span> listFiles.next();</span><br><span class="line">        <span class="comment">// 输出详情</span></span><br><span class="line">        <span class="comment">// 文件名称</span></span><br><span class="line">        System.out.println(<span class="string">&quot;文件名称：&quot;</span>+status.getPath().getName());</span><br><span class="line">        <span class="comment">// 长度</span></span><br><span class="line">        System.out.println(<span class="string">&quot;文件的大小（长度）：&quot;</span>+status.getLen());</span><br><span class="line">        <span class="comment">// 权限</span></span><br><span class="line">        System.out.println(<span class="string">&quot;文件的权限：&quot;</span>+status.getPermission());</span><br><span class="line">        <span class="comment">// 分组</span></span><br><span class="line">        System.out.println(<span class="string">&quot;文件的所属组：&quot;</span>+status.getGroup());</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;----------------------------------&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 文件的块位置</span></span><br><span class="line">        BlockLocation[] blockLocations = status.getBlockLocations();</span><br><span class="line">        <span class="keyword">for</span> (BlockLocation blockLocation : blockLocations) &#123;</span><br><span class="line">            <span class="keyword">for</span> (String host : blockLocation.getHosts()) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;承载此文件的主机名：&quot;</span>+host);</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;--------------------------------------&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    fs.close();</span><br><span class="line">    System.out.println(<span class="string">&quot;OVER&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><details class="folding-tag" green><summary>点击查看运行结果</summary><div class="content"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">D:\PATH_EN\JDK17\bin\java.exe...</span><br><span class="line">文件名称：TestData.txt</span><br><span class="line">文件的大小（长度）：<span class="number">0</span></span><br><span class="line">文件的权限：rw-r--r--</span><br><span class="line">文件的所属组：supergroup</span><br><span class="line">----------------------------------</span><br><span class="line">文件名称：TestData3.txt</span><br><span class="line">文件的大小（长度）：<span class="number">0</span></span><br><span class="line">文件的权限：rw-r--r--</span><br><span class="line">文件的所属组：supergroup</span><br><span class="line">----------------------------------</span><br><span class="line">文件名称：log1.txt</span><br><span class="line">文件的大小（长度）：<span class="number">0</span></span><br><span class="line">文件的权限：rw-r--r--</span><br><span class="line">文件的所属组：supergroup</span><br><span class="line">----------------------------------</span><br><span class="line">文件名称：log2.txt</span><br><span class="line">文件的大小（长度）：<span class="number">0</span></span><br><span class="line">文件的权限：rw-r--r--</span><br><span class="line">文件的所属组：supergroup</span><br><span class="line">----------------------------------</span><br><span class="line">文件名称：log3.txt</span><br><span class="line">文件的大小（长度）：<span class="number">0</span></span><br><span class="line">文件的权限：rw-r--r--</span><br><span class="line">文件的所属组：supergroup</span><br><span class="line">----------------------------------</span><br><span class="line">文件名称：demo.txt</span><br><span class="line">文件的大小（长度）：<span class="number">18</span></span><br><span class="line">文件的权限：rw-r--r--</span><br><span class="line">文件的所属组：Jermyn</span><br><span class="line">----------------------------------</span><br><span class="line">承载此文件的主机名：hadoop104</span><br><span class="line">承载此文件的主机名：hadoop102</span><br><span class="line">承载此文件的主机名：hadoop103</span><br><span class="line">--------------------------------------</span><br><span class="line">文件名称：hadoop-<span class="number">2.7</span><span class="number">.2</span>.tar.gz</span><br><span class="line">文件的大小（长度）：<span class="number">197657687</span></span><br><span class="line">文件的权限：rw-r--r--</span><br><span class="line">文件的所属组：supergroup</span><br><span class="line">----------------------------------</span><br><span class="line">承载此文件的主机名：hadoop104</span><br><span class="line">承载此文件的主机名：hadoop102</span><br><span class="line">承载此文件的主机名：hadoop103</span><br><span class="line">--------------------------------------</span><br><span class="line">承载此文件的主机名：hadoop104</span><br><span class="line">承载此文件的主机名：hadoop102</span><br><span class="line">承载此文件的主机名：hadoop103</span><br><span class="line">--------------------------------------</span><br><span class="line">文件名称：wc.input</span><br><span class="line">文件的大小（长度）：<span class="number">293</span></span><br><span class="line">文件的权限：rw-r--r--</span><br><span class="line">文件的所属组：supergroup</span><br><span class="line">----------------------------------</span><br><span class="line">承载此文件的主机名：hadoop104</span><br><span class="line">承载此文件的主机名：hadoop102</span><br><span class="line">承载此文件的主机名：hadoop103</span><br><span class="line">--------------------------------------</span><br><span class="line">OVER</span><br><span class="line"></span><br><span class="line">Process finished with exit code <span class="number">0</span></span><br></pre></td></tr></table></figure></div></details><p></p><h3 id="HDFS文件和文件夹判断"><a href="#HDFS文件和文件夹判断" class="headerlink" title="HDFS文件和文件夹判断"></a>HDFS文件和文件夹判断</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testListStatus</span><span class="params">()</span> <span class="keyword">throws</span> IOException, URISyntaxException, InterruptedException &#123;</span><br><span class="line">    <span class="comment">// 1 获取文件系统</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>), configuration, <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="type">Path</span> <span class="variable">path</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/&quot;</span>);</span><br><span class="line">    FileStatus[] fileStatuses = fs.listStatus(path);</span><br><span class="line">    <span class="keyword">for</span> (FileStatus fileStatus : fileStatuses) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 判断是文件还是文件夹</span></span><br><span class="line">        <span class="keyword">if</span> (fileStatus.isFile()) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;f：&quot;</span> + fileStatus.getPath().getName());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;d：&quot;</span> + fileStatus.getPath().getName());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="HDFS的I-O流操作"><a href="#HDFS的I-O流操作" class="headerlink" title="HDFS的I/O流操作"></a>HDFS的I/O流操作</h2><h3 id="HDFS文件上传"><a href="#HDFS文件上传" class="headerlink" title="HDFS文件上传"></a>HDFS文件上传</h3><ol><li><strong>需求：把本机桌面(C:\Users\Administrator\Desktop)上的文件Test.txt上传到HDFS(/hdfsClient/demo/test/Test.txt)目录</strong></li><li><strong>编写代码</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">getFileFromHDFS</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1 获取文件系统</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>),</span><br><span class="line">            configuration,</span><br><span class="line">            <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2 获取输入流</span></span><br><span class="line">    <span class="type">FileInputStream</span> <span class="variable">fis</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileInputStream</span>(</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\Test.txt&quot;</span>));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3 获取输出流</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">f</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/hdfsClient/demo/test/Test.txt&quot;</span>);</span><br><span class="line">    <span class="type">FSDataOutputStream</span> <span class="variable">fos</span> <span class="operator">=</span> fs.create(f);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4 流的对拷</span></span><br><span class="line">    IOUtils.copyBytes(fis, fos, configuration);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5 关闭资源</span></span><br><span class="line">    IOUtils.closeStream(fos);</span><br><span class="line">    IOUtils.closeStream(fis);</span><br><span class="line">    fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528165150.png" alt=""></li></ol><h3 id="HDFS文件下载-1"><a href="#HDFS文件下载-1" class="headerlink" title="HDFS文件下载"></a>HDFS文件下载</h3><ol><li><strong>需求：从HDFS(/log)上下载log1.txt文件到本地桌面（C:\Users\Administrator\Desktop）上</strong></li><li><strong>编写代码</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">getFileFromHDFS</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException &#123;</span><br><span class="line">    <span class="comment">// 1 获取文件系统</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>),</span><br><span class="line">            configuration,</span><br><span class="line">            <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2 获取输入流</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">f</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/log/log1.txt&quot;</span>);</span><br><span class="line">    <span class="type">FSDataInputStream</span> <span class="variable">fis</span> <span class="operator">=</span> fs.open(f);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3 获取输出流</span></span><br><span class="line">    <span class="type">FileOutputStream</span> <span class="variable">fos</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileOutputStream</span>(<span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\log.txt&quot;</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4 流的对拷</span></span><br><span class="line">    IOUtils.copyBytes(fis, fos, configuration);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5 关闭资源</span></span><br><span class="line">    IOUtils.closeStream(fis);</span><br><span class="line">    IOUtils.closeStream(fos);</span><br><span class="line">    fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528170500.png" alt=""></li></ol><h3 id="定位文件读取"><a href="#定位文件读取" class="headerlink" title="定位文件读取"></a>定位文件读取</h3><ol><li><strong>需求：分块读取HDFS上的大文件，比如根目录下的/user/Jermyn/input/hadoop-2.7.2.tar.gz</strong></li><li><strong>编写代码</strong></li></ol><ul><li><strong>下载第一块</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFileSeek1</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException &#123;</span><br><span class="line">    <span class="comment">// 1 获取文件系统</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>),</span><br><span class="line">            configuration,</span><br><span class="line">            <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2 获取输入流</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">f</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/user/Jermyn/input/hadoop-2.7.2.tar.gz&quot;</span>);</span><br><span class="line">    <span class="type">FSDataInputStream</span> <span class="variable">fis</span> <span class="operator">=</span> fs.open(f);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3 获取输出流</span></span><br><span class="line">    <span class="type">FileOutputStream</span> <span class="variable">fos</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileOutputStream</span>(</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\hadoop-2.7.2.tar.gz.block1&quot;</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4 流的对拷(只拷贝128)</span></span><br><span class="line">    <span class="type">byte</span>[] bytes = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">1024</span> * <span class="number">128</span>; i++) &#123;</span><br><span class="line">        fis.read(bytes);</span><br><span class="line">        fos.write(bytes);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5 关闭资源</span></span><br><span class="line">    IOUtils.closeStream(fis);</span><br><span class="line">    IOUtils.closeStream(fos);</span><br><span class="line">    fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528171624.png" alt=""></li><li><strong>下载第二块</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFileSeek2</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException &#123;</span><br><span class="line">    <span class="comment">// 1 获取文件系统</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>),</span><br><span class="line">            configuration,</span><br><span class="line">            <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2 获取输入流</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">f</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/user/Jermyn/input/hadoop-2.7.2.tar.gz&quot;</span>);</span><br><span class="line">    <span class="type">FSDataInputStream</span> <span class="variable">fis</span> <span class="operator">=</span> fs.open(f);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3 设置指定的读取节点</span></span><br><span class="line">    fis.seek(<span class="number">1024</span> * <span class="number">1024</span> * <span class="number">128</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4 获取输出流</span></span><br><span class="line">    <span class="type">FileOutputStream</span> <span class="variable">fos</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileOutputStream</span>(</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\hadoop-2.7.2.tar.gz.block2&quot;</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5 流的对拷</span></span><br><span class="line">    IOUtils.copyBytes(fis, fos, configuration);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 6 关闭资源</span></span><br><span class="line">    IOUtils.closeStream(fis);</span><br><span class="line">    IOUtils.closeStream(fos);</span><br><span class="line">    fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528172455.png" alt=""></li><li><strong>合并文件</strong><br>在Window命令窗口中进入到目录E:\，然后执行如下命令，对数据进行合并 type hadoop-2.7.2.tar.gz.part2 &gt;&gt; hadoop-2.7.2.tar.gz.part1<br>合并完成后，将hadoop-2.7.2.tar.gz.part1重新命名为hadoop-2.7.2.tar.gz。解压发现该tar包非常完整。</li></ul><h1 id="第七章-HDFS的数据流"><a href="#第七章-HDFS的数据流" class="headerlink" title="第七章 HDFS的数据流"></a>第七章 HDFS的数据流</h1><h2 id="HDFS写数据流程"><a href="#HDFS写数据流程" class="headerlink" title="HDFS写数据流程"></a>HDFS写数据流程</h2><h3 id="剖析文件写入"><a href="#剖析文件写入" class="headerlink" title="剖析文件写入"></a>剖析文件写入</h3><span class="p center logo large">HDFS写数据流程</span> <span class="p center small green">点击下图可放大查看</span><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528175922.png" alt=""><br></p><div class="timeline green"><div class="timeline-item headline"><div class="timeline-item-title"><div class="item-circle"><p>HDFS写数据流程</p></div></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第一步</p></div></div><div class="timeline-item-content"><p>客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第二步</p></div></div><div class="timeline-item-content"><p>NameNode返回是否可以上传。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第三步</p></div></div><div class="timeline-item-content"><p>客户端请求第一个 Block上传到哪几个DataNode服务器上。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第四步</p></div></div><div class="timeline-item-content"><p>NameNode返回3个DataNode节点，分别为dn1、dn2、dn3（如何返回合适的datanode详细可见7.1.2）。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第五步</p></div></div><div class="timeline-item-content"><p>客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第六步</p></div></div><div class="timeline-item-content"><p>dn1、dn2、dn3逐级应答客户端。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第七步</p></div></div><div class="timeline-item-content"><p>客户端开始往dn1上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet为单位，dn1收到一个Packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第八步</p></div></div><div class="timeline-item-content"><p>当一个Block传输完成之后，客户端再次请求NameNode上传第二个Block的服务器。（重复执行3-7步）。</p></div></div></div><p></p><h3 id="网络拓扑-节点距离计算"><a href="#网络拓扑-节点距离计算" class="headerlink" title="网络拓扑-节点距离计算"></a>网络拓扑-节点距离计算</h3><p>在HDFS写数据的过程中，NameNode会选择距离待上传数据最近距离的DataNode接收数据。<br>节点距离：<span class="p red">两个节点到达最近的共同祖先的距离总和。</span><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528184907.png" alt=""></p><h3 id="机架感知（副本存储节点选择）"><a href="#机架感知（副本存储节点选择）" class="headerlink" title="机架感知（副本存储节点选择）"></a>机架感知（副本存储节点选择）</h3><ol><li><strong>官方ip地址</strong><br><strong><em>点击图片跳转链接</em></strong><br><a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#Data_Replication"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528185714.png" alt=""></a></li><li><strong>Hadoop2.7.2副本节点选择</strong><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528185910.png" alt=""></li></ol><h2 id="HDFS读数据流程"><a href="#HDFS读数据流程" class="headerlink" title="HDFS读数据流程"></a>HDFS读数据流程</h2><span class="p center logo large">HDFS的读数据流程</span> <span class="p center logo small green">点击下图可放大查看</span><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528190740.png" alt=""><br></p><div class="timeline green"><div class="timeline-item headline"><div class="timeline-item-title"><div class="item-circle"><p>HDFS读数据流程</p></div></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第一步</p></div></div><div class="timeline-item-content"><p>客户端通过Distributed FileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第二步</p></div></div><div class="timeline-item-content"><p>挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第三步</p></div></div><div class="timeline-item-content"><p>DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以Packet为单位来做校验）。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第四步</p></div></div><div class="timeline-item-content"><p>客户端以Packet为单位接收，先在本地缓存，然后写入目标文件。</p></div></div></div><p></p><h1 id="第八章-NameNode和SecondaryNameNode"><a href="#第八章-NameNode和SecondaryNameNode" class="headerlink" title="第八章 NameNode和SecondaryNameNode"></a>第八章 NameNode和SecondaryNameNode</h1><h2 id="NN和2NN工作机制"><a href="#NN和2NN工作机制" class="headerlink" title="NN和2NN工作机制"></a>NN和2NN工作机制</h2><span class="p red">思考：NameNode中的元数据是存储在哪里的？</span><p>首先，我们做个假设，如果存储在NameNode节点的磁盘中，因为经常需要进行随机访问，还有响应客户请求，必然是效率过低。因此，元数据需要存放在内存中。但如果只存在内存中，一旦断电，元数据丢失，整个集群就无法工作了。因此产生在磁盘中备份元数据的FsImage。这样又会带来新的问题，当在内存中的元数据更新时，如果同时更新FsImage，就会导致效率过低，但如果不更新，就会发生一致性问题，一旦NameNode节点断电，就会产生数据丢失。因此，引入Edits文件(只进行追加操作，效率很高)。每当元数据有更新或者添加元数据时，修改内存中的元数据并追加到Edits中。这样，一旦NameNode节点断电，可以通过FsImage和Edits的合并，合成元数据。但是，如果长时间添加数据到Edits中，会导致该文件数据过大，效率降低，而且一旦断电，恢复元数据需要的时间过长。因此，需要定期进行FsImage和Edits的合并，如果这个操作由NameNode节点完成，又会效率过低。因此，引入一个新的节点SecondaryNamenode，专门用于FsImage和Edits的合并。<br><span class="p center logo large">NN和2NN工作机制</span><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528193202.png" alt=""><br></p><div class="timeline green"><div class="timeline-item headline"><div class="timeline-item-title"><div class="item-circle"><p>NN和2NN工作机制</p></div></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>NN第1步</p></div></div><div class="timeline-item-content"><p>第一次启动NameNode格式化后，创建Fsimage和Edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>NN第2步</p></div></div><div class="timeline-item-content"><p>客户端对元数据进行增删改的请求。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>NN第3步</p></div></div><div class="timeline-item-content"><p>NameNode记录操作日志，更新滚动日志（即：nd向将操作写到edits在进行相应操作）。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>NN第4步</p></div></div><div class="timeline-item-content"><p>NameNode在内存中对数据进行增删改。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>2NN第1步</p></div></div><div class="timeline-item-content"><p>Secondary NameNode询问NameNode是否需要CheckPoint。直接带回NameNode是否检查结果。<br>CheckPoint：将edits和fsimage进行合并成为最新的元数据，序列化到fsimage中</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>2NN第2步</p></div></div><div class="timeline-item-content"><p>Secondary NameNode请求执行CheckPoint。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>2NN第3步</p></div></div><div class="timeline-item-content"><p>NameNode滚动正在写的Edits日志。正在写入的edits叫edits_inprogress_001,滚动生成edits_001，同时生成edits_inprogress_002（空的内容），此后在进行的操作写入到edits_inprogress_002中，</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>2NN第4步</p></div></div><div class="timeline-item-content"><p>将滚动前的编辑日志（edits_001）和镜像文件（fsimage）拷贝到Secondary NameNode</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>2NN第5步</p></div></div><div class="timeline-item-content"><p>Secondary NameNode加载编辑日志和镜像文件到内存，并合并。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>2NN第6步</p></div></div><div class="timeline-item-content"><p>生成新的镜像文件fsimage.chkpoint。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>2NN第7步</p></div></div><div class="timeline-item-content"><p>拷贝fsimage.chkpoint到NameNode。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>2NN第8步</p></div></div><div class="timeline-item-content"><p>NameNode将fsimage.chkpoint重新命名成fsimage。</p></div></div></div><p></p><h2 id="NN和2NN工作机制详解："><a href="#NN和2NN工作机制详解：" class="headerlink" title="NN和2NN工作机制详解："></a>NN和2NN工作机制详解：</h2><p>Fsimage：NameNode内存中元数据序列化后形成的文件。<br>Edits：记录客户端更新元数据信息的每一步操作（可通过Edits运算出元数据）。<br>NameNode启动时，先滚动Edits并生成一个空的edits.inprogress，然后加载Edits和Fsimage到内存中，此时NameNode内存就持有最新的元数据信息。Client开始对NameNode发送元数据的增删改的请求，这些请求的操作首先会被记录到edits.inprogress中（查询元数据的操作不会被记录在Edits中，因为查询操作不会更改元数据信息），如果此时NameNode挂掉，重启后会从Edits中读取元数据的信息。然后，NameNode会在内存中执行元数据的增删改的操作。<br>由于Edits中记录的操作会越来越多，Edits文件会越来越大，导致NameNode在启动加载Edits时会很慢，所以需要对Edits和Fsimage进行合并（所谓合并，就是将Edits和Fsimage加载到内存中，照着Edits中的操作一步步执行，最终形成新的Fsimage）。SecondaryNameNode的作用就是帮助NameNode进行Edits和Fsimage的合并工作。<br>SecondaryNameNode首先会询问NameNode是否需要CheckPoint（触发CheckPoint需要满足两个条件中的任意一个，定时时间到和Edits中数据写满了）。直接带回NameNode是否检查结果。SecondaryNameNode执行CheckPoint操作，首先会让NameNode滚动Edits并生成一个空的edits.inprogress，滚动Edits的目的是给Edits打个标记，以后所有新的操作都写入edits.inprogress，其他未合并的Edits和Fsimage会拷贝到SecondaryNameNode的本地，然后将拷贝的Edits和Fsimage加载到内存中进行合并，生成fsimage.chkpoint，然后将fsimage.chkpoint拷贝给NameNode，重命名为Fsimage后替换掉原来的Fsimage。NameNode在启动时就只需要加载之前未合并的Edits和Fsimage即可，因为合并过的Edits中的元数据信息已经被记录在Fsimage中。</p><h2 id="Fsimage和Edits解析"><a href="#Fsimage和Edits解析" class="headerlink" title="Fsimage和Edits解析"></a>Fsimage和Edits解析</h2><span class="p center logo large">Fsimage和Edits概念</span><p>NameNode被格式化之后，将在/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current目录中产生如下文件<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528202634.png" alt=""></p><ol><li>Fsimage文件：HDFS文件系统元数据的一个永久性的检查点，其中包含HDFS文件系统的所有目录和文件inode的序列化信息。</li><li>Edits文件：存放HDFS文件系统的所有更新操作的路径，文件系统客户端执行的所有写操作首先会被记录到Edits文件中。</li><li>seen<em>txid文件保存的是一个数字，就是最后一个edits</em>的数字(即最新的操作的edits的文件id)</li><li>每次NameNode启动的时候都会将Fsimage文件读入内存，加载Edits里面的更新操作，保证内存中的元数据信息是最新的、同步的，可以看成NameNode启动的时候就将Fsimage和Edits文件进行了合并。</li></ol><h3 id="oiv查看Fsimage文件"><a href="#oiv查看Fsimage文件" class="headerlink" title="oiv查看Fsimage文件"></a>oiv查看Fsimage文件</h3><ol><li><strong>查看oiv和oev命令</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hdfs | grep <span class="literal">-E</span>  <span class="string">&#x27;oiv|oev&#x27;</span></span><br><span class="line">  oiv                  apply the offline fsimage viewer to an fsimage</span><br><span class="line">  oiv_legacy           apply the offline fsimage viewer to an legacy fsimage</span><br><span class="line">  oev                  apply the offline edits viewer to an edits file</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li><strong>基本语法</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs oiv <span class="literal">-p</span> 文件类型 <span class="literal">-i</span>镜像文件 <span class="literal">-o</span> 转换后文件输出路径</span><br></pre></td></tr></table></figure></li><li><strong>案例实操</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">current</span>]<span class="variable">$</span> <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/<span class="keyword">data</span>/tmp/dfs/name/current</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">current</span>]<span class="variable">$</span> hdfs oiv <span class="literal">-p</span> XML <span class="literal">-i</span> fsimage_0000000000000000025 <span class="literal">-o</span> /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/fsimage.xml</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">current</span>]<span class="variable">$</span> <span class="built_in">cat</span> /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/fsimage.xml</span><br></pre></td></tr></table></figure></li></ol><ul><li><strong>思考：可以看出，Fsimage中没有记录块所对应DataNode，为什么？</strong><br>在集群启动后，要求DataNode上报数据块信息，并间隔一段时间后再次上报。</li></ul><h3 id="oev查看Edits文件"><a href="#oev查看Edits文件" class="headerlink" title="oev查看Edits文件"></a>oev查看Edits文件</h3><ol><li><strong>基本语法</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs oev <span class="literal">-p</span> 文件类型 <span class="literal">-i</span>编辑日志 <span class="literal">-o</span> 转换后文件输出路径</span><br></pre></td></tr></table></figure></li><li><strong>实例实操</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">current</span>]<span class="variable">$</span> hdfs oev <span class="literal">-p</span> XML <span class="literal">-i</span> edits_0000000000000000012<span class="literal">-0000000000000000013</span> <span class="literal">-o</span> /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/edits.xml</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">current</span>]<span class="variable">$</span> <span class="built_in">cat</span> /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/edits.xml</span><br></pre></td></tr></table></figure></li></ol><h2 id="CheckPoint时间设置"><a href="#CheckPoint时间设置" class="headerlink" title="CheckPoint时间设置"></a>CheckPoint时间设置</h2><p><a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528222032.png" alt=""></a></p><ol><li><strong>通常情况下，SecondaryNameNode每隔一小时执行一次。</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim hdfs<span class="literal">-default</span>.xml</span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>3600<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><strong>一分钟检查一次操作次数，3当操作次数达到1百万时，SecondaryNameNode执行一次。</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.txns<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>1000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>操作动作次数<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.check.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>60<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span> 1分钟检查一次操作次数<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">&lt;/property &gt;</span><br></pre></td></tr></table></figure><h2 id="NameNode故障处理"><a href="#NameNode故障处理" class="headerlink" title="NameNode故障处理"></a>NameNode故障处理</h2>NameNode故障后，可以采用如下两种方法恢复数据。</li></ol><ul><li><strong>方法一：将SecondaryNameNode中数据拷贝到NameNode存储数据的目录(我们发现2NN和NN相比NN多个seentxid文件，其他都一样，所以此方法是将2NN的所有文件拷贝到NN所在的相应目录下)</strong></li></ul><ol><li>kill -9 NameNode进程</li><li>删除NameNode存储的数据（/opt/module/hadoop-2.7.2/data/tmp/dfs/name）<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> <span class="literal">-rf</span> /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/<span class="keyword">data</span>/tmp/dfs/name/*</span><br></pre></td></tr></table></figure></li><li>拷贝SecondaryNameNode中数据到原NameNode存储数据目录<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp <span class="literal">-r</span> Jermyn@hadoop104:/opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/<span class="keyword">data</span>/tmp/dfs/namesecondary/* ./name/</span><br></pre></td></tr></table></figure></li><li>重新启动NameNode<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop<span class="literal">-daemon</span>.sh <span class="built_in">start</span> namenode</span><br></pre></td></tr></table></figure></li></ol><ul><li><strong>方法二：使用-importCheckpoint选项启动NameNode守护进程，从而将SecondaryNameNode中数据拷贝到NameNode目录中。（CheckPoint触发条件是①定时时间到②edits中数据满，显然数据满不了了，所以我们修改定时任务，时间缩短，让他尽快触发进行Checkpoint，把内存的数据导出）</strong></li></ul><ol><li>修改hdfs-site.xml中的<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>120<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li>kill -9 NameNode进程</li><li>删除NameNode存储的数据（/opt/module/hadoop-2.7.2/data/tmp/dfs/name）<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> <span class="literal">-rf</span> /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/<span class="keyword">data</span>/tmp/dfs/name/*</span><br></pre></td></tr></table></figure></li><li>如果SecondaryNameNode不和NameNode在一个主机节点上，需要将SecondaryNameNode存储数据的目录拷贝到NameNode存储数据的平级目录，并删除in_use.lock文件<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">dfs</span>]<span class="variable">$</span> scp <span class="literal">-r</span> Jermyn@hadoop104:/opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/<span class="keyword">data</span>/tmp/dfs/namesecondary ./</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">namesecondary</span>]<span class="variable">$</span> <span class="built_in">rm</span> <span class="literal">-rf</span> in_use.lock</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">dfs</span>]<span class="variable">$</span> <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/<span class="keyword">data</span>/tmp/dfs</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">dfs</span>]<span class="variable">$</span> <span class="built_in">ls</span></span><br><span class="line"><span class="keyword">data</span>  name  namesecondary</span><br></pre></td></tr></table></figure></li><li>导入检查点数据（等待一会ctrl+c结束掉）<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs namenode <span class="literal">-importCheckpoint</span></span><br></pre></td></tr></table></figure></li><li>启动NameNode<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop<span class="literal">-daemon</span>.sh <span class="built_in">start</span> namenode</span><br></pre></td></tr></table></figure></li></ol><h2 id="集群安全模式"><a href="#集群安全模式" class="headerlink" title="集群安全模式"></a>集群安全模式</h2></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者:</span> <span class="post-copyright-info"><a href="https://www.jermyn.cn">Jermyn</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接:</span> <span class="post-copyright-info"><a href="https://www.jermyn.cn/posts/facf.html">https://www.jermyn.cn/posts/facf.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明:</span> <span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.jermyn.cn" target="_blank">Jermyn's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/hadoop/">hadoop</a><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></div><div class="post_share"><div class="social-share" data-image="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/087b21e70b21ac643352602c8746d20.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/77ed.html"><img class="prev-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/7c668fc4863f9534bfc36f9b42fd723.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Hadoop2.x源码编译</div></div></a></div><div class="next-post pull-right"><a href="/posts/eb1d.html"><img class="next-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/f495/2.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Linux基础命令</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/77ed.html" title="Hadoop2.x源码编译"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/7c668fc4863f9534bfc36f9b42fd723.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-25</div><div class="title">Hadoop2.x源码编译</div></div></a></div><div><a href="/posts/e6c9.html" title="Jave基础编程"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/2.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-02</div><div class="title">Jave基础编程</div></div></a></div><div><a href="/posts/9a8a.html" title="Java高级编程"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/1.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-02</div><div class="title">Java高级编程</div></div></a></div></div></div><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i> <span>评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/9a8a/auther.jpg" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">Jermyn</div><div class="author-info__description">个人学习笔记</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">15</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">22</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Jermyn-code"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/Jermyn-code" target="_blank" title="Github"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-github-fill"></use></svg></a><a class="social-icon faa-parent animated-hover" href="https://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=1773046949@qq.com" target="_blank" title="Email"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-mail"></use></svg></a><a class="social-icon faa-parent animated-hover" href="tencent://Message/?Uin=1773046949&amp;amp;websiteName=local.edu.com:8888=&amp;amp;Menu=yes" target="_blank" title="QQ"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-QQ1"></use></svg></a><a class="social-icon faa-parent animated-hover" href="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/qrcode.jpg" target="_blank" title="WeChat"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-weixin"></use></svg></a><a class="social-icon faa-parent animated-hover" href="https://www.instagram.com/born_in2084/" target="_blank" title="Instagram"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-instagram-fill"></use></svg></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">在读学习，联系我请+VX：AYOBRUH</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E7%AB%A0-Hadoop%E6%A1%86%E6%9E%B6"><span class="toc-number">1.</span> <span class="toc-text">第一章 Hadoop框架</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop1-x-%E5%92%8C-Hadoop2-x-%E5%8C%BA%E5%88%AB"><span class="toc-number">1.1.</span> <span class="toc-text">Hadoop1.x 和 Hadoop2.x 区别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0"><span class="toc-number">1.2.</span> <span class="toc-text">HDFS架构概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Yarn%E6%9E%B6%E6%9E%84"><span class="toc-number">1.3.</span> <span class="toc-text">Yarn架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0"><span class="toc-number">1.4.</span> <span class="toc-text">MapReduce架构概述</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E7%AB%A0-Hadoop%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA"><span class="toc-number">2.</span> <span class="toc-text">第二章 Hadoop运行环境搭建</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E7%AB%A0-Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="toc-number">3.</span> <span class="toc-text">第三章 Hadoop运行模式</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%AC%E5%9C%B0%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="toc-number">3.1.</span> <span class="toc-text">本地运行模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%98%E6%96%B9WordCount%E6%A1%88%E4%BE%8B"><span class="toc-number">3.1.1.</span> <span class="toc-text">官方WordCount案例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="toc-number">3.2.</span> <span class="toc-text">伪分布式运行模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4"><span class="toc-number">3.2.1.</span> <span class="toc-text">启动集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E6%93%8D%E4%BD%9C"><span class="toc-number">3.2.2.</span> <span class="toc-text">集群操作</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="toc-number">3.3.</span> <span class="toc-text">完全分布式运行模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#scp%EF%BC%88secure-copy%EF%BC%89%E5%AE%89%E5%85%A8%E6%8B%B7%E8%B4%9D"><span class="toc-number">3.3.1.</span> <span class="toc-text">scp（secure copy）安全拷贝</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rsync-%E8%BF%9C%E7%A8%8B%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7"><span class="toc-number">3.3.2.</span> <span class="toc-text">rsync 远程同步工具</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E5%86%99%E8%84%9A%E6%9C%AC%EF%BC%8C%E4%BD%BF%E7%94%A8xsync%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E5%9C%A8%E9%9B%86%E7%BE%A4%E4%B8%AD%E4%BC%A0%E8%BE%93"><span class="toc-number">3.3.3.</span> <span class="toc-text">编写脚本，使用xsync实现文件在集群中传输</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E8%A7%84%E5%88%92"><span class="toc-number">3.3.4.</span> <span class="toc-text">集群部署规划</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E5%8D%95%E7%82%B9%E5%90%AF%E5%8A%A8"><span class="toc-number">3.3.5.</span> <span class="toc-text">集群单点启动</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SSH%E6%97%A0%E5%AF%86%E7%99%BB%E5%BD%95%E9%85%8D%E7%BD%AE"><span class="toc-number">3.3.6.</span> <span class="toc-text">SSH无密登录配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E6%B5%8B%E8%AF%95%EF%BC%9A%E4%B8%8A%E4%BC%A0%E5%B0%8F%E6%96%87%E4%BB%B6%E5%92%8C%E5%A4%A7%E6%96%87%E4%BB%B6"><span class="toc-number">3.3.7.</span> <span class="toc-text">集群基本测试：上传小文件和大文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hadoop%E7%9B%B8%E5%85%B3%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4"><span class="toc-number">3.3.8.</span> <span class="toc-text">hadoop相关执行命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5"><span class="toc-number">3.3.9.</span> <span class="toc-text">集群时间同步</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E7%AB%A0-HDFS-%E6%A6%82%E8%BF%B0"><span class="toc-number">4.</span> <span class="toc-text">第四章 HDFS 概述</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">4.1.</span> <span class="toc-text">HDFS优缺点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E7%BB%84%E6%88%90%E6%9E%B6%E6%9E%84"><span class="toc-number">4.2.</span> <span class="toc-text">HDFS组成架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E5%9D%97%E5%A4%A7%E5%B0%8F"><span class="toc-number">4.3.</span> <span class="toc-text">HDFS文件块大小</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%94%E7%AB%A0-HDFS%E7%9A%84Shell%E6%93%8D%E4%BD%9C"><span class="toc-number">5.</span> <span class="toc-text">第五章 HDFS的Shell操作</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%AE%9E%E6%93%8D"><span class="toc-number">5.1.</span> <span class="toc-text">常用命令实操</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%85%AD%E7%AB%A0-HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C"><span class="toc-number">6.</span> <span class="toc-text">第六章 HDFS客户端操作</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="toc-number">6.1.</span> <span class="toc-text">HDFS客户端环境准备</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E7%9A%84API%E6%93%8D%E4%BD%9C"><span class="toc-number">6.2.</span> <span class="toc-text">HDFS的API操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%EF%BC%88%E6%B5%8B%E8%AF%95%E5%8F%82%E6%95%B0%E4%BC%98%E5%85%88%E7%BA%A7%EF%BC%89"><span class="toc-number">6.2.1.</span> <span class="toc-text">HDFS文件上传（测试参数优先级）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD"><span class="toc-number">6.2.2.</span> <span class="toc-text">HDFS文件下载</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E7%9A%84%E5%88%A0%E9%99%A4"><span class="toc-number">6.2.3.</span> <span class="toc-text">HDFS文件的删除</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E5%90%8D%E6%9B%B4%E6%94%B9"><span class="toc-number">6.2.4.</span> <span class="toc-text">HDFS文件名更改</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E8%AF%A6%E6%83%85%E6%9F%A5%E7%9C%8B"><span class="toc-number">6.2.5.</span> <span class="toc-text">HDFS文件详情查看</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E5%92%8C%E6%96%87%E4%BB%B6%E5%A4%B9%E5%88%A4%E6%96%AD"><span class="toc-number">6.2.6.</span> <span class="toc-text">HDFS文件和文件夹判断</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E7%9A%84I-O%E6%B5%81%E6%93%8D%E4%BD%9C"><span class="toc-number">6.3.</span> <span class="toc-text">HDFS的I&#x2F;O流操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0"><span class="toc-number">6.3.1.</span> <span class="toc-text">HDFS文件上传</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD-1"><span class="toc-number">6.3.2.</span> <span class="toc-text">HDFS文件下载</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%BD%8D%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96"><span class="toc-number">6.3.3.</span> <span class="toc-text">定位文件读取</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%83%E7%AB%A0-HDFS%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81"><span class="toc-number">7.</span> <span class="toc-text">第七章 HDFS的数据流</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B"><span class="toc-number">7.1.</span> <span class="toc-text">HDFS写数据流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%96%E6%9E%90%E6%96%87%E4%BB%B6%E5%86%99%E5%85%A5"><span class="toc-number">7.1.1.</span> <span class="toc-text">剖析文件写入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E6%8B%93%E6%89%91-%E8%8A%82%E7%82%B9%E8%B7%9D%E7%A6%BB%E8%AE%A1%E7%AE%97"><span class="toc-number">7.1.2.</span> <span class="toc-text">网络拓扑-节点距离计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5%EF%BC%88%E5%89%AF%E6%9C%AC%E5%AD%98%E5%82%A8%E8%8A%82%E7%82%B9%E9%80%89%E6%8B%A9%EF%BC%89"><span class="toc-number">7.1.3.</span> <span class="toc-text">机架感知（副本存储节点选择）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E8%AF%BB%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B"><span class="toc-number">7.2.</span> <span class="toc-text">HDFS读数据流程</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%85%AB%E7%AB%A0-NameNode%E5%92%8CSecondaryNameNode"><span class="toc-number">8.</span> <span class="toc-text">第八章 NameNode和SecondaryNameNode</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#NN%E5%92%8C2NN%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="toc-number">8.1.</span> <span class="toc-text">NN和2NN工作机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NN%E5%92%8C2NN%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%EF%BC%9A"><span class="toc-number">8.2.</span> <span class="toc-text">NN和2NN工作机制详解：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Fsimage%E5%92%8CEdits%E8%A7%A3%E6%9E%90"><span class="toc-number">8.3.</span> <span class="toc-text">Fsimage和Edits解析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#oiv%E6%9F%A5%E7%9C%8BFsimage%E6%96%87%E4%BB%B6"><span class="toc-number">8.3.1.</span> <span class="toc-text">oiv查看Fsimage文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#oev%E6%9F%A5%E7%9C%8BEdits%E6%96%87%E4%BB%B6"><span class="toc-number">8.3.2.</span> <span class="toc-text">oev查看Edits文件</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CheckPoint%E6%97%B6%E9%97%B4%E8%AE%BE%E7%BD%AE"><span class="toc-number">8.4.</span> <span class="toc-text">CheckPoint时间设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NameNode%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86"><span class="toc-number">8.5.</span> <span class="toc-text">NameNode故障处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E5%AE%89%E5%85%A8%E6%A8%A1%E5%BC%8F"><span class="toc-number">8.6.</span> <span class="toc-text">集群安全模式</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/77ed.html" title="Hadoop2.x源码编译"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/7c668fc4863f9534bfc36f9b42fd723.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Hadoop2.x源码编译"></a><div class="content"><a class="title" href="/posts/77ed.html" title="Hadoop2.x源码编译">Hadoop2.x源码编译</a><time datetime="2023-05-25T18:12:54.000Z" title="发表于 2023-05-25 18:12:54">2023-05-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/facf.html" title="Hadoop2.x"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/087b21e70b21ac643352602c8746d20.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Hadoop2.x"></a><div class="content"><a class="title" href="/posts/facf.html" title="Hadoop2.x">Hadoop2.x</a><time datetime="2023-05-23T21:12:50.000Z" title="发表于 2023-05-23 21:12:50">2023-05-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/eb1d.html" title="Linux基础命令"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/f495/2.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Linux基础命令"></a><div class="content"><a class="title" href="/posts/eb1d.html" title="Linux基础命令">Linux基础命令</a><time datetime="2023-05-22T22:17:56.000Z" title="发表于 2023-05-22 22:17:56">2023-05-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/f495.html" title="Linux磁盘的挂载和卸载"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/f495/1.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Linux磁盘的挂载和卸载"></a><div class="content"><a class="title" href="/posts/f495.html" title="Linux磁盘的挂载和卸载">Linux磁盘的挂载和卸载</a><time datetime="2023-05-22T14:41:20.000Z" title="发表于 2023-05-22 14:41:20">2023-05-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/2053.html" title="JavaCodeDemo"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/other/2053head.jpeg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="JavaCodeDemo"></a><div class="content"><a class="title" href="/posts/2053.html" title="JavaCodeDemo">JavaCodeDemo</a><time datetime="2023-05-07T18:21:42.000Z" title="发表于 2023-05-07 18:21:42">2023-05-07</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2023 By Jermyn</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i> <span>数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo.jermyn.cn/',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo.jermyn.cn/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><div class="aplayer no-destroy" data-id="8670693070" data-server="tencent" data-type="playlist" data-order="list" data-fixed="true" data-preload="auto" data-autoplay="false" data-mutex="true"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><div class="app-refresh" id="app-refresh" style="position:fixed;top:-2.2rem;left:0;right:0;z-index:99999;padding:0 1rem;font-size:15px;height:2.2rem;transition:all .3s ease"><div class="app-refresh-wrap" style="display:flex;color:#fff;height:100%;align-items:center;justify-content:center"><label>✨ 有新文章啦！ 👉</label><a href="javascript:void(0)" onclick="location.reload()"><span style="color:#fff;text-decoration:underline;cursor:pointer">🍗点击食用🍔</span></a></div></div><script>if ('serviceWorker' in navigator) {
if (navigator.serviceWorker.controller) {
navigator.serviceWorker.addEventListener('controllerchange', function() {
showNotification()
})
}
window.addEventListener('load', function() {
navigator.serviceWorker.register('/sw.js')
})
}
function showNotification() {
if (GLOBAL_CONFIG.Snackbar) {
var snackbarBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
GLOBAL_CONFIG.Snackbar.bgLight :
GLOBAL_CONFIG.Snackbar.bgDark
var snackbarPos = GLOBAL_CONFIG.Snackbar.position
Snackbar.show({
text: '✨ 有新文章啦！ 👉',
backgroundColor: snackbarBg,
duration: 500000,
pos: snackbarPos,
actionText: '🍗点击食用🍔',
actionTextColor: '#fff',
onActionClick: function(e) {
location.reload()
},
})
} else {
var showBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
'#49b1f5' :
'#1f1f1f'
var cssText = `top: 0; background: ${showBg};`
document.getElementById('app-refresh').style.cssText = cssText
}
}</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script data-pjax>function butterfly_clock_anzhiyu_injector_config(){var e=document.getElementsByClassName("sticky_layout")[0];console.log("已挂载butterfly_clock_anzhiyu"),e&&e.insertAdjacentHTML("afterbegin",'<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>')}for(var elist="null".split(","),cpage=location.pathname,epage="all",qweather_key="0f5e430e0ec2485a8e175000f1ca33eb",gaud_map_key="163f0b807c26d68365ae5f029f76cf19",baidu_ak_key="undefined",flag=0,clock_rectangle="111.62,33.79",clock_default_rectangle_enable="false",i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;"all"===epage&&0==flag?butterfly_clock_anzhiyu_injector_config():epage===cpage&&butterfly_clock_anzhiyu_injector_config()</script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.js"></script><script data-pjax>function butterfly_footer_beautify_injector_config(){var A=document.getElementById("footer-wrap");console.log("已挂载butterfly_footer_beautify"),A.insertAdjacentHTML("beforeend",'<div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v5.4.0" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" data-title="主题版本Butterfly_v4.2.2" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://cloud.tencent.com/" style="margin-inline:5px" data-title="本站使用JsDelivr为静态资源提供CDN加速" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/CDN-Tencent-blue?style=flat&amp;logo=iCloud" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/Jermyn-code" style="margin-inline:5px" data-title="本站项目由Github托管" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></p>')}for(var elist="null".split(","),cpage=location.pathname,epage="all",flag=0,i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;"all"===epage&&0==flag?butterfly_footer_beautify_injector_config():epage===cpage&&butterfly_footer_beautify_injector_config()</script><script async src="/js/runtime/runtime.min.js"></script><script data-pjax>function butterfly_swiper_injector_config(){var a=document.getElementById("recent-posts");console.log("已挂载butterfly_swiper"),a.insertAdjacentHTML("afterbegin",'<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/9a8a.html" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/1.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-10-02</span><a class="blog-slider__title" href="posts/9a8a.html" alt="">Java高级编程</a><div class="blog-slider__text">Java学习笔记，Java基础阶段的高级编程，包含多线程，Java常用类，枚举类&amp;注解，Java集合，泛型，IO流，网络编程，Java反射机制，Java8的其他新特性，Java9&amp;10&amp;11新特性，文档资源来自尚硅谷，整理为博主，在此感谢尚硅谷无私分享大量的学习资源。</div><a class="blog-slider__button" href="posts/9a8a.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/ba42.html" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/3.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-08-26</span><a class="blog-slider__title" href="posts/ba42.html" alt="">Hadoop集群脚本部署</a><div class="blog-slider__text">Hadoop脚本部署，包含7个shell脚本，以及一个ip.txt文件，建议运行顺序为00-06</div><a class="blog-slider__button" href="posts/ba42.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/ef13.html" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/6.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-08-27</span><a class="blog-slider__title" href="posts/ef13.html" alt="">大数据集群服务部署</a><div class="blog-slider__text">本文为大数据集群服务的部署文档,包括zookeeper服务部署,Hadoop服务部署,Spark服务部署,Kafka服务部署,Hbase服务部署,Hive服务部署</div><a class="blog-slider__button" href="posts/ef13.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/d746.html" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/9a8a/8.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-08-26</span><a class="blog-slider__title" href="posts/d746.html" alt="">shell 学习笔记</a><div class="blog-slider__text">shell脚本学习笔记，学完可自行编写shell脚本</div><a class="blog-slider__button" href="posts/d746.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/e6c9.html" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/2.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-09-02</span><a class="blog-slider__title" href="posts/e6c9.html" alt="">Jave基础编程</a><div class="blog-slider__text">Java学习笔记，Java基础阶段的基础编程，包含Java语言概述，基本语法，数组，面向对象编程，异常处理。文档资源来自尚硅谷，整理为博主，在此感谢尚硅谷无私分享大量的学习资源。</div><a class="blog-slider__button" href="posts/e6c9.html" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>')}for(var elist="undefined".split(","),cpage=location.pathname,epage="all",flag=0,i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;"all"===epage&&0==flag?butterfly_swiper_injector_config():epage===cpage&&butterfly_swiper_injector_config()</script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><div class="js-pjax"><script async>for(var arr=document.getElementsByClassName("recent-post-item"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__zoomIn"),arr[i].setAttribute("data-wow-duration","1.5s"),arr[i].setAttribute("data-wow-delay","200ms"),arr[i].setAttribute("data-wow-offset","30"),arr[i].setAttribute("data-wow-iteration","1")</script><script async>for(var arr=document.getElementsByClassName("card-widget"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__zoomIn"),arr[i].setAttribute("data-wow-duration",""),arr[i].setAttribute("data-wow-delay","200ms"),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("flink-list-card"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__flipInY"),arr[i].setAttribute("data-wow-duration","3s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("flink-list-card"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__animated"),arr[i].setAttribute("data-wow-duration","3s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("article-sort-item"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__slideInRight"),arr[i].setAttribute("data-wow-duration","1.5s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("site-card"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__flipInY"),arr[i].setAttribute("data-wow-duration","3s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("site-card"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__animated"),arr[i].setAttribute("data-wow-duration","3s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script></div><script defer src="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/wow_init.js"></script><script async src="//at.alicdn.com/t/c/font_3617685_a7gpo3nfht.js"></script></body></html>