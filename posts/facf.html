<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>Hadoop2.x | Jermyn's blog</title><meta name="keywords" content="大数据集群服务,Hadoop2.7.2"><meta name="author" content="Jermyn,born_in2084@yeah.net"><meta name="copyright" content="Jermyn"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="第一章 Hadoop框架Hadoop1.x 和 Hadoop2.x 区别 Hadoop1.x组成MapReduce（计算+资源调度），HDFS（数据存储），Common（辅助工具） Hadoop2.x组成MapReduce（计算），Yarn（资源调度），HDFS（数据存储），Common（辅助工具） 在Hadoop1.x时代，Hadoop中的MapReduce同时处理业务逻辑运算和资源的调度，耦合"><meta property="og:type" content="article"><meta property="og:title" content="Hadoop2.x"><meta property="og:url" content="https://www.jermyn.cn/posts/facf.html"><meta property="og:site_name" content="Jermyn&#39;s blog"><meta property="og:description" content="第一章 Hadoop框架Hadoop1.x 和 Hadoop2.x 区别 Hadoop1.x组成MapReduce（计算+资源调度），HDFS（数据存储），Common（辅助工具） Hadoop2.x组成MapReduce（计算），Yarn（资源调度），HDFS（数据存储），Common（辅助工具） 在Hadoop1.x时代，Hadoop中的MapReduce同时处理业务逻辑运算和资源的调度，耦合"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/006bf826d4ef7fff55821708a9726a2.jpg"><meta property="article:published_time" content="2023-05-23T21:12:50.000Z"><meta property="article:modified_time" content="2023-07-12T16:15:03.792Z"><meta property="article:author" content="Jermyn"><meta property="article:tag" content="hadoop"><meta property="article:tag" content="大数据"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/006bf826d4ef7fff55821708a9726a2.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://www.jermyn.cn/posts/facf"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="manifest" href="/manifest.json"><meta name="msapplication-TileColor" content="#49b1f5"><link rel="apple-touch-icon" sizes="180x180" href="/img/siteicon/128.png"><link rel="icon" type="image/png" sizes="32x32" href="/img/siteicon/32.png"><link rel="icon" type="image/png" sizes="16x16" href="/img/siteicon/16.png"><link rel="mask-icon" href="/img/siteicon/128.png" color="#5bbad5"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"Hadoop2.x",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2023-07-12 16:15:03"}</script><noscript><style>#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.css"><link rel="stylesheet" href="/js/runtime/runtime.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload='this.media="screen"'><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload='this.media="all"'><script src="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="Jermyn's blog" type="application/atom+xml"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/9a8a/auther.jpg" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">23</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><span>留言</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><span>档案</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><span>音乐</span></a></div><div class="menus_item"><a class="site-page" href="/bangumis/index.html"><span>番剧</span></a></div><div class="menus_item"><a class="site-page" href="/books"><span>书籍</span></a></div><div class="menus_item"><a class="site-page" href="/movies/"><span>影视</span></a></div><div class="menus_item"><a class="site-page" href="/games/"><span>游戏</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/006bf826d4ef7fff55821708a9726a2.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Jermyn's blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i> <span>搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><span>留言</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><span>档案</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><span>音乐</span></a></div><div class="menus_item"><a class="site-page" href="/bangumis/index.html"><span>番剧</span></a></div><div class="menus_item"><a class="site-page" href="/books"><span>书籍</span></a></div><div class="menus_item"><a class="site-page" href="/movies/"><span>影视</span></a></div><div class="menus_item"><a class="site-page" href="/games/"><span>游戏</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Hadoop2.x</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-05-23T21:12:50.000Z" title="发表于 2023-05-23 21:12:50">2023-05-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-07-12T16:15:03.792Z" title="更新于 2023-07-12 16:15:03">2023-07-12</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">42k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>185分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="Hadoop2.x"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="第一章-Hadoop框架"><a href="#第一章-Hadoop框架" class="headerlink" title="第一章 Hadoop框架"></a>第一章 Hadoop框架</h1><h2 id="Hadoop1-x-和-Hadoop2-x-区别"><a href="#Hadoop1-x-和-Hadoop2-x-区别" class="headerlink" title="Hadoop1.x 和 Hadoop2.x 区别"></a>Hadoop1.x 和 Hadoop2.x 区别</h2><ul><li><strong>Hadoop1.x组成</strong><br>MapReduce（计算+资源调度），HDFS（数据存储），Common（辅助工具）</li><li><strong>Hadoop2.x组成</strong><br>MapReduce（计算），Yarn（资源调度），HDFS（数据存储），Common（辅助工具）<blockquote><p>在Hadoop1.x时代，Hadoop中的MapReduce同时处理业务逻辑运算和资源的调度，耦合性较大，在Hadoop2.x时代，增加了Yarn。Yarn只负责资源的调度，MapReduce只负责运算</p></blockquote></li></ul><h2 id="HDFS架构概述"><a href="#HDFS架构概述" class="headerlink" title="HDFS架构概述"></a>HDFS架构概述</h2><ol><li>NameNode（nn）：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等。</li><li>DataNode(dn)：在本地文件系统存储文件块数据，以及块数据的校验和。</li><li>Secondary NameNode(2nn)：辅助NameNode工作，用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。</li></ol><h2 id="Yarn架构"><a href="#Yarn架构" class="headerlink" title="Yarn架构"></a>Yarn架构</h2><p>ResourceManager（RM）：资源由RM管理（理解为部门经理）。<br>（1）处理客户端请求；<br>（2）监控NodeManager<br>（3）启动或监控ApplicationMaster<br>（4）资源的分配与调度</p><p>NodeManager（NM）：单个节点上的资源由NM管理，但是经过RM协调。（理解为小组长）<br>（1）管理单个节点上的资源<br>（2）处理来自ResourceManager的命令<br>（3）处理来自ApplicationMaster的命令</p><p>ApplicationMaster（AM）：集群上某一个任务的开启关闭，协调（理解为一个个项目）<br>（1）负责数据的切分<br>（2）为应用程序申请资源并分配给内部的任务<br>（3）任务的监控与容错</p><p>Container ：Container是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/f495/20230523213727.png" alt=""></p><h2 id="MapReduce架构概述"><a href="#MapReduce架构概述" class="headerlink" title="MapReduce架构概述"></a>MapReduce架构概述</h2><p>MapReduce将计算过程分为两个阶段：Map和Reduce</p><ol><li>Map阶段并行处理输入数据（分：一个大的任务分给多个节点，每个节点都做一部分）</li><li>Reduce阶段对Map结果进行汇总（和：将每个节点的计算结果汇总）</li></ol><h1 id="第二章-Hadoop运行环境搭建"><a href="#第二章-Hadoop运行环境搭建" class="headerlink" title="第二章 Hadoop运行环境搭建"></a>第二章 Hadoop运行环境搭建</h1><ul><li><strong>JAVA_HOME</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># JAVA_HOME</span></span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.<span class="number">8.0</span>_144</span><br><span class="line">export PATH=<span class="variable">$PATH:</span><span class="variable">$JAVA_HOME</span>/bin</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#HADOOP_HOME</span></span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span></span><br><span class="line">export PATH=<span class="variable">$PATH:</span><span class="variable">$HADOOP_HOME</span>/bin</span><br><span class="line">export PATH=<span class="variable">$PATH:</span><span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure></li></ul><h1 id="第三章-Hadoop运行模式"><a href="#第三章-Hadoop运行模式" class="headerlink" title="第三章 Hadoop运行模式"></a>第三章 Hadoop运行模式</h1><p>Hadoop运行模式包括：本地模式、伪分布式模式以及完全分布式模式。<br>Hadoop官方网站：<a target="_blank" rel="noopener" href="http://hadoop.apache.org/">http://hadoop.apache.org/</a></p><h2 id="本地运行模式"><a href="#本地运行模式" class="headerlink" title="本地运行模式"></a>本地运行模式</h2><h3 id="官方WordCount案例"><a href="#官方WordCount案例" class="headerlink" title="官方WordCount案例"></a><strong>官方WordCount案例</strong></h3><ol><li>创建在hadoop-2.7.2文件下面创建一个wcinput文件夹</li><li>在wcinput文件下创建一个wc.input文件</li><li>编辑wc.input文件(输入任意内容)</li><li>回到Hadoop目录/opt/module/hadoop-2.7.2</li><li>执行程序</li><li>查看结果<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> mkdir wcinput</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> <span class="built_in">cd</span> wcinput/</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">wcinput</span>]<span class="variable">$</span> vim wc.input</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">wcinput</span>]<span class="variable">$</span> <span class="built_in">ls</span></span><br><span class="line">wc.input</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">wcinput</span>]<span class="variable">$</span> <span class="built_in">cd</span> ..</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> <span class="built_in">ls</span></span><br><span class="line">bin  etc  include  input  lib  libexec  LICENSE.txt  NOTICE.txt  output  README.txt  sbin  share  wcinput</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hadoop jar share/hadoop/mapreduce/hadoop<span class="literal">-mapreduce-examples-2</span>.<span class="number">7.2</span>.jar wordcount wcinput/ wcouput</span><br><span class="line"><span class="number">23</span>/<span class="number">05</span>/<span class="number">24</span> <span class="number">09</span>:<span class="number">09</span>:<span class="number">19</span> INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session<span class="literal">-id</span></span><br><span class="line"><span class="number">23</span>/<span class="number">05</span>/<span class="number">24</span> <span class="number">09</span>:<span class="number">09</span>:<span class="number">19</span> INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=</span><br><span class="line">............</span><br><span class="line">............</span><br><span class="line">............</span><br><span class="line">        File Output Format Counters</span><br><span class="line">                Bytes Written=<span class="number">235</span></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> <span class="built_in">cd</span> wcouput/</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">wcouput</span>]<span class="variable">$</span> <span class="built_in">ls</span></span><br><span class="line">part<span class="literal">-r-00000</span>  _SUCCESS</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">wcouput</span>]<span class="variable">$</span> <span class="built_in">cat</span> part<span class="literal">-r-00000</span></span><br><span class="line">EJERMYN <span class="number">1</span></span><br><span class="line">HADOOP  <span class="number">6</span></span><br><span class="line">JAVA    <span class="number">5</span></span><br><span class="line">JAVAA   <span class="number">1</span></span><br><span class="line">JEERMYN <span class="number">1</span></span><br><span class="line">JERDMYN <span class="number">1</span></span><br><span class="line">JEREMYN <span class="number">1</span></span><br><span class="line">JERMYCN <span class="number">1</span></span><br><span class="line">JERMYN  <span class="number">1</span></span><br><span class="line">JERMYTN <span class="number">1</span></span><br><span class="line">JRECMYN <span class="number">1</span></span><br><span class="line">JREEMYN <span class="number">2</span></span><br><span class="line">JREMYDN <span class="number">1</span></span><br><span class="line">JREMYEN <span class="number">1</span></span><br><span class="line">Jefrmyn <span class="number">1</span></span><br><span class="line">Jermfdyn        <span class="number">1</span></span><br><span class="line">Jermyfn <span class="number">1</span></span><br><span class="line">Jermyn  <span class="number">3</span></span><br><span class="line">hadoop  <span class="number">6</span></span><br><span class="line">java    <span class="number">2</span></span><br><span class="line">javaC   <span class="number">1</span></span><br><span class="line">javaEE  <span class="number">1</span></span><br><span class="line">javaSE  <span class="number">1</span></span><br><span class="line">javac   <span class="number">1</span></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">wcouput</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="伪分布式运行模式"><a href="#伪分布式运行模式" class="headerlink" title="伪分布式运行模式"></a>伪分布式运行模式</h2><div class="tip fa-gamepad faa-horizontal animated"><p>启动HDFS并运行MapReduce程序</p></div><p><strong><em>点击图片查看文档</em></strong><br><a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/SingleCluster.html"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524100352.png" alt=""></a></p><ul><li><strong>配置：hadoop-env.sh</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>]<span class="variable">$</span> <span class="built_in">echo</span> <span class="variable">$JAVA_HOME</span></span><br><span class="line">/opt/module/jdk1.<span class="number">8.0</span>_144</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>]<span class="variable">$</span> vim hadoop<span class="literal">-env</span>.sh</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524100154.png" alt=""></li><li><strong>配置：core-site.xml</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop100:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><strong>配置：hdfs-site.xml</strong><br><strong><em>点击图片查看文档</em></strong><br><a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524100755.png" alt=""></a><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定HDFS副本的数量 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><strong>启动集群</strong></li><li>格式化NameNode（第一次启动时格式化，以后就不要总格式化）<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs namenode <span class="literal">-format</span></span><br></pre></td></tr></table></figure></li><li>启动NameNode<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop<span class="literal">-daemon</span>.sh <span class="built_in">start</span> namenode</span><br></pre></td></tr></table></figure></li><li>启动DataNode<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop<span class="literal">-daemon</span>.sh <span class="built_in">start</span> datanode</span><br></pre></td></tr></table></figure></li><li>查看进程<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> [<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> jps</span><br><span class="line"><span class="number">3826</span> DataNode</span><br><span class="line"><span class="number">3683</span> NameNode</span><br><span class="line"><span class="number">3902</span> Jps</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li>web端查看HDFS文件系统<br><a target="_blank" rel="noopener" href="http://hadoop100:50070/dfshealth.html#tab-overview">http://hadoop100:50070/dfshealth.html#tab-overview</a><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524103135.png" alt=""></li></ul><div class="note blue icon-padding modern"><i class="note-icon fas fa-bullhorn"></i><p>说明：在企业中遇到Bug时，经常根据日志提示信息去分析问题、解决Bug</p></div><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">logs</span>]<span class="variable">$</span> <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">logs</span>]<span class="variable">$</span> ll</span><br><span class="line">总用量 <span class="number">68</span></span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root <span class="number">24131</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">10</span>:<span class="number">31</span> hadoop<span class="literal">-Jermyn-datanode-hadoop100</span>.log</span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root   <span class="number">717</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">10</span>:<span class="number">23</span> hadoop<span class="literal">-Jermyn-datanode-hadoop100</span>.out</span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root <span class="number">29149</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">10</span>:<span class="number">29</span> hadoop<span class="literal">-Jermyn-namenode-hadoop100</span>.log</span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root  <span class="number">5007</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">10</span>:<span class="number">27</span> hadoop<span class="literal">-Jermyn-namenode-hadoop100</span>.out</span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root     <span class="number">0</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">10</span>:<span class="number">20</span> SecurityAuth<span class="literal">-Jermyn</span>.audit</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">logs</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><div class="note blue icon-padding modern"><i class="note-icon fas fa-bullhorn"></i><p>思考：为什么不能一直格式化NameNode，格式化NameNode，要注意什么？</p></div><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> <span class="built_in">cat</span> <span class="keyword">data</span>/tmp/dfs/<span class="keyword">data</span>/current/VERSION | grep <span class="string">&#x27;clusterID&#x27;</span></span><br><span class="line">clusterID=CID<span class="literal">-77af8246-5931-4a4f-bdbe-5fe9624458a3</span></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> <span class="built_in">cat</span> <span class="keyword">data</span>/tmp/dfs/name/current/VERSION | grep <span class="string">&#x27;clusterID&#x27;</span></span><br><span class="line">clusterID=CID<span class="literal">-77af8246-5931-4a4f-bdbe-5fe9624458a3</span></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><blockquote><p>注意：<span class="p red">可以看出data和name的集群ID是相同的</span>格式化NameNode，会产生新的集群id,导致NameNode和DataNode的集群id不一致，集群找不到已往数据。所以，格式NameNode时，一定要先删除data数据和log日志<span class="p red">（删除data和log时候，必须把NameNode和DataNode关闭，否则删除无效）</span>，然后再格式化NameNode。<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524115949.png" alt=""></p></blockquote><ul><li><p><strong>在HDFS文件系统上创建一个input文件夹</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs <span class="literal">-mkdir</span> <span class="literal">-p</span> /user/Jermyn/input</span><br></pre></td></tr></table></figure><p><a target="_blank" rel="noopener" href="http://hadoop100:50070/explorer.html#/user/Jermyn/input">http://hadoop100:50070/explorer.html#/user/Jermyn/input</a></p></li><li><p><strong>将本地的 wcinput/wc.input 上传到hdfs的/user/Jermyn/input</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs <span class="literal">-put</span> wcinput/wc.input /user/Jermyn/input</span><br></pre></td></tr></table></figure><p><strong><em>点击图片查看</em></strong><br><a target="_blank" rel="noopener" href="http://hadoop100:50070/explorer.html#/user/Jermyn/input"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524104943.png" alt=""></a></p></li><li><p><strong>执行官方WordCount案例</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop jar share/hadoop/mapreduce/hadoop<span class="literal">-mapreduce-examples-2</span>.<span class="number">7.2</span>.jar wordcount /user/Jermyn/input /user/Jermyn/output</span><br></pre></td></tr></table></figure><p><strong><em>点击图片查看</em></strong><br><a target="_blank" rel="noopener" href="http://hadoop100:50070/explorer.html#/user/Jermyn/output"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524110240.png" alt=""></a></p></li><li><p><strong>查看运行的结果</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop dfs <span class="literal">-cat</span> /user/Jermyn/output/p*</span><br></pre></td></tr></table></figure></li><li><p><strong>删除输出结果</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop dfs <span class="literal">-rm</span> <span class="literal">-r</span> /user/Jermyn/out</span><br></pre></td></tr></table></figure><div class="tip fa-gamepad faa-horizontal animated"><p>启动YARN并运行MapReduce程序</p></div></li><li><p><strong>配置yarn-env.sh</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.<span class="number">8.0</span>_144</span><br></pre></td></tr></table></figure></li><li><p><strong>配置yarn-site.xml</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Reducer获取数据的方式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> 	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> 	<span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop100<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>配置：mapred-env.sh</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure></li><li><p><strong>配置： (对mapred-site.xml.template重新命名为) mapred-site.xml</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mv</span> mapred<span class="literal">-site</span>.xml.template mapred<span class="literal">-site</span>.xml</span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定MR运行在YARN上 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><span class="p green">点击图片查看配置文件</span><p><a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r2.7.2/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524122131.png" alt=""></a></p></li></ul><h3 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a><strong>启动集群</strong></h3><span class="p red">注意：启动前必须保证NameNode和DataNode已经启动</span><ul><li><strong>启动ResourceManager</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/yarn<span class="literal">-daemon</span>.sh <span class="built_in">start</span> resourcemanager</span><br></pre></td></tr></table></figure></li><li><strong>启动NodeManager</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/yarn<span class="literal">-daemon</span>.sh <span class="built_in">start</span> nodemanager</span><br></pre></td></tr></table></figure></li><li><strong>查看进程</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> jps</span><br><span class="line"><span class="number">6016</span> Jps</span><br><span class="line"><span class="number">3826</span> DataNode</span><br><span class="line"><span class="number">3683</span> NameNode</span><br><span class="line"><span class="number">5637</span> ResourceManager</span><br><span class="line"><span class="number">5897</span> NodeManager</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><h3 id="集群操作"><a href="#集群操作" class="headerlink" title="集群操作"></a><strong>集群操作</strong></h3></li><li><p><strong>YARN的浏览器页面查看</strong><br><a target="_blank" rel="noopener" href="http://hadoop100:8088/cluster">http://hadoop100:8088/cluster</a><br><strong><em>点击图片跳转</em></strong><br><a target="_blank" rel="noopener" href="http://hadoop100:8088/cluster"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524123246.png" alt=""></a></p></li><li><p><strong>执行执行官方WordCount案例查看任务</strong></p><span class="p red">执行任务前必须把output删除</span><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs <span class="literal">-rm</span> <span class="literal">-r</span> /user/Jermyn/output</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop jar share/hadoop/mapreduce/hadoop<span class="literal">-mapreduce-examples-2</span>.<span class="number">7.2</span>.jar wordcount /user/Jermyn/input /user/Jermyn/output</span><br></pre></td></tr></table></figure><p><a target="_blank" rel="noopener" href="http://hadoop100:8088/cluster"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524124532.png" alt=""></a></p></li></ul><div class="tip fa-gamepad faa-horizontal animated"><p>配置历史服务器</p></div><p>为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下：</p><ul><li><strong>配置mapred-site.xml</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 历史服务器端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop100:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 历史服务器web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop100:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>启动历史服务器</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/mr<span class="literal">-jobhistory-daemon</span>.sh <span class="built_in">start</span> historyserver</span><br></pre></td></tr></table></figure></li><li><p><strong>查看历史服务器是否启动</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> jps</span><br><span class="line"><span class="number">3826</span> DataNode</span><br><span class="line"><span class="number">3683</span> NameNode</span><br><span class="line"><span class="number">6836</span> Jps</span><br><span class="line"><span class="number">5637</span> ResourceManager</span><br><span class="line"><span class="number">6758</span> JobHistoryServer</span><br><span class="line"><span class="number">5897</span> NodeManager</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop100</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li><strong>查看JobHistory</strong><br><a target="_blank" rel="noopener" href="http://hadoop100:19888/jobhistory">http://hadoop100:19888/jobhistory</a><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524125336.png" alt=""><br><a target="_blank" rel="noopener" href="http://hadoop100:19888/jobhistory/job/job_1684902467164_0001"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524125303.png" alt=""></a></li></ul><div class="tip fa-gamepad faa-horizontal animated"><p>配置日志的聚集</p></div><p>日志聚集概念：应用运行完成以后，将程序运行日志信息上传到HDFS系统上。<br>日志聚集功能好处：可以方便的查看到程序运行详情，方便开发调试。<br><span class="p red">注意：开启日志聚集功能，需要重新启动NodeManager 、ResourceManager和HistoryManager。</span></p><ul><li><p><strong>配置yarn-site.xml</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 日志聚集功能使能 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 日志保留时间设置7天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>关闭NodeManager 、ResourceManager和HistoryManage</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sbin/yarn<span class="literal">-daemon</span>.sh stop nodemanager</span><br><span class="line">sbin/yarn<span class="literal">-daemon</span>.sh stop resourcemanager</span><br><span class="line">sbin/mr<span class="literal">-jobhistory-daemon</span>.sh stop historyserver</span><br></pre></td></tr></table></figure></li><li><p><strong>启动NodeManager 、ResourceManager和HistoryManager</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sbin/yarn<span class="literal">-daemon</span>.sh <span class="built_in">start</span> nodemanager</span><br><span class="line">sbin/yarn<span class="literal">-daemon</span>.sh <span class="built_in">start</span> resourcemanager</span><br><span class="line">sbin/mr<span class="literal">-jobhistory-daemon</span>.sh <span class="built_in">start</span> historyserver</span><br></pre></td></tr></table></figure></li><li><p><strong>删除HDFS上已经存在的输出文件</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs <span class="literal">-rm</span> <span class="literal">-r</span> /user/Jermyn/output</span><br></pre></td></tr></table></figure></li><li><p><strong>执行WordCount程序</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop jar share/hadoop/mapreduce/hadoop<span class="literal">-mapreduce-examples-2</span>.<span class="number">7.2</span>.jar wordcount /user/Jermyn/input /user/Jermyn/output</span><br></pre></td></tr></table></figure></li><li><strong>查看日志</strong><br><a target="_blank" rel="noopener" href="http://hadoop100:19888/jobhistory">http://hadoop100:19888/jobhistory</a><br><a target="_blank" rel="noopener" href="http://hadoop100:19888/jobhistory/job/job_1684908681616_0001"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524142503.png" alt=""></a><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230524142605.png" alt=""></li></ul><div class="tip fa-gamepad faa-horizontal animated"><p>配置文件说明</p></div><ol><li>Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。<br>core-default.xml 在 hadoop-common-2.7.2.jar/ core-default.xml<br>hdfs-default.xml 在 hadoop-hdfs-2.7.2.jar/ hdfs-default.xml<br>yarn-default.xml 在 hadoop-yarn-common-2.7.2.jar/ yarn-default.xml<br>mapred-default.xml 在 hadoop-mapreduce-client-core-2.7.2.jar/ mapred-default.xml</li><li>core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径上，用户可以根据项目需求重新进行修改配置</li></ol><h2 id="完全分布式运行模式"><a href="#完全分布式运行模式" class="headerlink" title="完全分布式运行模式"></a>完全分布式运行模式</h2><span class="p red">根据 hadoop100 进行拷贝出hadoop102，hadoop103，hadoop104，然后把在hadoop100上配置的/opt/module 分发到 hadoop102，hadoop103，hadoop104，还有配置文件 /etc/profile (使用 scp -r 命令)</span><h3 id="scp（secure-copy）安全拷贝"><a href="#scp（secure-copy）安全拷贝" class="headerlink" title="scp（secure copy）安全拷贝"></a><strong>scp（secure copy）安全拷贝</strong></h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp    <span class="literal">-r</span>          <span class="variable">$pdir</span>/<span class="variable">$fname</span>              <span class="variable">$user</span>@hadoop<span class="variable">$host:</span><span class="variable">$pdir</span>/<span class="variable">$fname</span></span><br><span class="line">命令   递归       要拷贝的文件路径/名称    目的用户<span class="selector-tag">@</span>主机:目的路径/名称</span><br></pre></td></tr></table></figure><h3 id="rsync-远程同步工具"><a href="#rsync-远程同步工具" class="headerlink" title="rsync 远程同步工具"></a><strong>rsync 远程同步工具</strong></h3><p>rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。<br>rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。<br></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rsync    <span class="literal">-rvl</span>       <span class="variable">$pdir</span>/<span class="variable">$fname</span>              <span class="variable">$user</span>@hadoop<span class="variable">$host:</span><span class="variable">$pdir</span>/<span class="variable">$fname</span></span><br><span class="line">命令   选项参数   要拷贝的文件路径/名称    目的用户<span class="selector-tag">@</span>主机:目的路径/名称</span><br></pre></td></tr></table></figure><p></p><blockquote><p>-r 递归<br>-v 显示复制过程<br>-l 拷贝符号连接</p></blockquote><h3 id="编写脚本，使用xsync实现文件在集群中传输"><a href="#编写脚本，使用xsync实现文件在集群中传输" class="headerlink" title="编写脚本，使用xsync实现文件在集群中传输"></a><strong>编写脚本，使用xsync实现文件在集群中传输</strong></h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment">############################################################################</span></span><br><span class="line"><span class="comment"># Desc    : xsync集群分发脚本</span></span><br><span class="line"><span class="comment"># Path    : /home/Jermyn/bin</span></span><br><span class="line"><span class="comment"># Auther  : Jermyn</span></span><br><span class="line"><span class="comment"># Date    : 2023-05-24</span></span><br><span class="line"><span class="comment"># Version : 1.0</span></span><br><span class="line"><span class="comment">############################################################################</span></span><br><span class="line"><span class="comment"># 前置需要一个ip.txt文件，注意：文件格式严按照“ipaddress空格hostname”格式如：“127.0.0.1 root”</span></span><br><span class="line">p1=<span class="variable">$1</span></span><br><span class="line">pcount=<span class="variable">$</span><span class="comment">#</span></span><br><span class="line">user=`whoami`</span><br><span class="line">HOSTNAME=`hostname`</span><br><span class="line">fname=`basename <span class="variable">$p1</span>`</span><br><span class="line"><span class="built_in">echo</span> fname=<span class="variable">$fname</span></span><br><span class="line"><span class="keyword">if</span>((pcount==<span class="number">0</span>)); then</span><br><span class="line">        <span class="built_in">echo</span> no args;</span><br><span class="line">        <span class="keyword">exit</span>;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">pdir=`cd <span class="literal">-P</span> <span class="variable">$</span>(dirname <span class="variable">$p1</span>); <span class="built_in">pwd</span>`</span><br><span class="line"><span class="built_in">echo</span> pdir=<span class="variable">$pdir</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> read ip hostname</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">[ <span class="string">&quot;<span class="variable">$hostname</span>&quot;</span> = <span class="string">&quot;<span class="variable">$HOSTNAME</span>&quot;</span> ] &amp;&amp; <span class="keyword">continue</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="literal">-e</span> <span class="string">&quot;-----------------------\033[5;34mSending a file to <span class="variable">$hostname</span>\033[0m-----------------------&quot;</span></span><br><span class="line">        rsync <span class="literal">-rvl</span> <span class="variable">$pdir</span>/<span class="variable">$fname</span> <span class="variable">$user</span><span class="selector-tag">@</span><span class="variable">$hostname:</span><span class="variable">$pdir</span></span><br><span class="line">        [ <span class="variable">$</span>? -<span class="type">eq</span> <span class="number">0</span> ]&amp;&amp; <span class="built_in">echo</span> <span class="literal">-e</span> <span class="string">&quot;           \033[5;32m已成功向<span class="variable">$hostname</span>传输文件\033[0m&quot;</span> || <span class="built_in">echo</span> <span class="literal">-e</span> <span class="string">&quot;           \033[5;31m文件传输失败，请检查主机<span class="variable">$hostname</span>\033[0m&quot;</span></span><br><span class="line">done &lt; ip.txt</span><br></pre></td></tr></table></figure><div class="tip fa-gamepad faa-horizontal animated"><p>集群配置</p></div><h3 id="集群部署规划"><a href="#集群部署规划" class="headerlink" title="集群部署规划"></a><strong>集群部署规划</strong></h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                HDFS                    YARN</span><br><span class="line">hadoop102       NameNode                NodeManager</span><br><span class="line">                DataNode</span><br><span class="line">hadoop103       DataNode                ResourceManager </span><br><span class="line">                                        NodeManager</span><br><span class="line">hadoop104       SecondaryNameNode</span><br><span class="line">                DataNode                NodeManager</span><br></pre></td></tr></table></figure><ul><li><strong>修改配置Core-site.xml</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop102:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><span class="p red">注：伪分布是NameNode是 hadoop100</span> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525100948.png" alt=""></li><li><strong>修改hadoop-env.sh</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.<span class="number">8.0</span>_144</span><br></pre></td></tr></table></figure><span class="p red">注：伪分布已添加，此处不做修改</span></li><li><strong>修改hdfs-site.xml</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定HDFS副本的数量 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><span class="p red">注：伪分布是dfs.replication是1，其实默认配置是3，伪分布式的时候不用改，因为只有一台节点的时候，不会产生3个副本，还是一个，如果节点多的话才会增加，snn的配置是新增加的</span> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525102138.png" alt=""></li><li><strong>配置yarn-env.sh</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.<span class="number">8.0</span>_144</span><br></pre></td></tr></table></figure><span class="p red">注：伪分布已添加，此处不做修改</span></li><li><strong>修改配置yarn-site.xml</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Reducer获取数据的方式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><span class="p red">注:伪分布式rm配置是hadoop100 在此改为hadoop103</span> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525103003.png" alt=""></li><li><p><strong>配置mapred-env.sh</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.<span class="number">8.0</span>_144</span><br></pre></td></tr></table></figure><ul><li><strong>配置mapred-site.xml</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> mapred<span class="literal">-site</span>.xml.template mapred<span class="literal">-site</span>.xml</span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定MR运行在Yarn上 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><span class="p red">注:伪分布式修改过，此处不用修改</span> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525103804.png" alt=""></li></ul></li><li><p><strong>在集群上分发配置好的Hadoop配置文件</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/</span><br></pre></td></tr></table></figure><h3 id="集群单点启动"><a href="#集群单点启动" class="headerlink" title="集群单点启动"></a><strong>集群单点启动</strong></h3><span class="p red">注意:此处如果是第一次启动，一定要注意需要格式化namenode，原因上面1.3.2思考已经注明，我这里是已经配置过伪分布，也格式化过，所以这里需要删除data/和log/文件夹</span><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop namenode <span class="literal">-format</span></span><br></pre></td></tr></table></figure></li><li><strong>在hadoop102、hadoop103以及hadoop104上分别启动DataNode</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop<span class="literal">-daemon</span>.sh <span class="built_in">start</span> datanode</span><br></pre></td></tr></table></figure></li><li><strong>jps 查看进程</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> jps</span><br><span class="line"><span class="number">3384</span> NameNode</span><br><span class="line"><span class="number">3516</span> Jps</span><br><span class="line"><span class="number">3308</span> DataNode</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop103</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> jps</span><br><span class="line"><span class="number">3227</span> Jps</span><br><span class="line"><span class="number">3117</span> DataNode</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop104</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> jps</span><br><span class="line"><span class="number">3200</span> Jps</span><br><span class="line"><span class="number">3082</span> DataNode</span><br></pre></td></tr></table></figure></li></ul><h3 id="SSH无密登录配置"><a href="#SSH无密登录配置" class="headerlink" title="SSH无密登录配置"></a><strong>SSH无密登录配置</strong></h3><ul><li><strong>免密登录原理</strong><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525110211.png" alt=""></li><li><strong>生成公钥和私钥：</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> ssh<span class="literal">-keygen</span> <span class="literal">-t</span> rsa</span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file <span class="keyword">in</span> which to save the key (/home/Jermyn/.ssh/id_rsa):</span><br><span class="line">Enter passphrase (empty <span class="keyword">for</span> no passphrase):</span><br><span class="line">Enter same passphrase again:</span><br><span class="line">Your identification has been saved <span class="keyword">in</span> /home/Jermyn/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved <span class="keyword">in</span> /home/Jermyn/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">SHA256:xAXniHrEhQ4pWD2L1xsyS8ixH5jv8Zsx9X8zghOE23o Jermyn@hadoop102</span><br><span class="line">The key<span class="string">&#x27;s randomart image is:</span></span><br><span class="line"><span class="string">+---[RSA 2048]----+</span></span><br><span class="line"><span class="string">| o.. . .o.o      |</span></span><br><span class="line"><span class="string">|. o =..+ =       |</span></span><br><span class="line"><span class="string">| . O *+ +..      |</span></span><br><span class="line"><span class="string">|  B Bo+.. .      |</span></span><br><span class="line"><span class="string">|   =.=.oS+       |</span></span><br><span class="line"><span class="string">|    =.....o      |</span></span><br><span class="line"><span class="string">|   . oo  ..o     |</span></span><br><span class="line"><span class="string">|    . .+. E.. +  |</span></span><br><span class="line"><span class="string">|      o. . ..o o |</span></span><br><span class="line"><span class="string">+----[SHA256]-----+</span></span><br><span class="line"><span class="string">[Jermyn@hadoop102 hadoop-2.7.2]$</span></span><br></pre></td></tr></table></figure></li><li><strong>将公钥拷贝到要免密登录的目标机器上</strong><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id hadoop102</span><br><span class="line">ssh-copy-id hadoop103</span><br><span class="line">ssh-copy-id hadoop104</span><br></pre></td></tr></table></figure></li><li><strong>.ssh文件夹下（~/.ssh）的文件功能解释</strong><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">known_hosts         记录ssh访问过计算机的公钥(public key)</span><br><span class="line">id_rsa              生成的私钥</span><br><span class="line">id_rsa.pub          生成的公钥</span><br><span class="line">authorized_keys	    存放授权过得无密登录服务器公钥</span><br></pre></td></tr></table></figure><span class="p red">注意： 还需要在hadoop102上采用root账号，配置一下无密登录到hadoop102、hadoop103、hadoop104； 还需要在hadoop103上采用Jermyn账号配置一下无密登录到hadoop102、hadoop103、hadoop104服务器上。(103上有一个resourcemanager在控制其他节点，所以也需要免密登录其他节点)</span></li></ul><div class="tip fa-gamepad faa-horizontal animated"><p>群起集群</p></div><ul><li><p><strong>配置/etc/hadoop/slaves</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/hadoop/slaves</span><br><span class="line"></span><br><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br></pre></td></tr></table></figure><span class="p red">注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。</span></li><li><p><strong>启动HDFS</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> sbin/<span class="built_in">start-dfs</span>.sh</span><br><span class="line">Starting namenodes on [<span class="type">hadoop102</span>]</span><br><span class="line">hadoop102: starting namenode, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-namenode-hadoop102</span>.out</span><br><span class="line">hadoop103: starting datanode, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-datanode-hadoop103</span>.out</span><br><span class="line">hadoop102: starting datanode, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-datanode-hadoop102</span>.out</span><br><span class="line">hadoop104: starting datanode, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-datanode-hadoop104</span>.out</span><br><span class="line">Starting secondary namenodes [<span class="type">hadoop104</span>]</span><br><span class="line">hadoop104: starting secondarynamenode, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-secondarynamenode-hadoop104</span>.out</span><br></pre></td></tr></table></figure><p>-<strong>启动YARN，在hadoop103</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> [<span class="type">Jermyn</span>@<span class="type">hadoop103</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> sbin/<span class="built_in">start-yarn</span>.sh</span><br><span class="line">starting yarn daemons</span><br><span class="line">starting resourcemanager, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/yarn<span class="literal">-Jermyn-resourcemanager-hadoop103</span>.out</span><br><span class="line">hadoop102: starting nodemanager, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/yarn<span class="literal">-Jermyn-nodemanager-hadoop102</span>.out</span><br><span class="line">hadoop104: starting nodemanager, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/yarn<span class="literal">-Jermyn-nodemanager-hadoop104</span>.out</span><br><span class="line">hadoop103: starting nodemanager, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/yarn<span class="literal">-Jermyn-nodemanager-hadoop103</span>.out</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop103</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> jps</span><br><span class="line"><span class="number">4871</span> NodeManager</span><br><span class="line"><span class="number">4711</span> ResourceManager</span><br><span class="line"><span class="number">5065</span> Jps</span><br><span class="line"><span class="number">4575</span> DataNode</span><br></pre></td></tr></table></figure></li><li><strong>Web端查看SecondaryNameNode</strong><br><a target="_blank" rel="noopener" href="http://hadoop104:50090/status.html">http://hadoop104:50090/status.html</a><br><a target="_blank" rel="noopener" href="http://hadoop104:50090/status.html"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525121828.png" alt=""></a></li></ul><h3 id="集群基本测试：上传小文件和大文件"><a href="#集群基本测试：上传小文件和大文件" class="headerlink" title="集群基本测试：上传小文件和大文件"></a><strong>集群基本测试：上传小文件和大文件</strong></h3><ul><li><strong>上传小文件</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hdfs dfs <span class="literal">-put</span> wcinput/ /user/Jermyn/input put: /user/Jermyn/input: No such file or directory</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hdfs dfs <span class="literal">-mkdir</span> <span class="literal">-p</span> /user/Jermyn/input</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hdfs dfs <span class="literal">-put</span> wcinput/ /user/Jermyn/input</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525152756.png" alt=""></li><li><strong>上传大文件</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs <span class="literal">-put</span> /opt/software/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>.tar.gz /user/Jermyn/input</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525152911.png" alt=""><span class="p red">可以直接点击下载在win下载，且两个块自动进行组合</span> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525153553.png" alt=""></li><li><strong>将两个文件下载（拼接）</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">subdir3</span>]<span class="variable">$</span> <span class="built_in">cat</span> blk_1073742741 &gt;&gt; tmp.txt</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">subdir3</span>]<span class="variable">$</span> <span class="built_in">cat</span> blk_1073742742 &gt;&gt; tmp.txt</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">subdir3</span>]<span class="variable">$</span> tar <span class="literal">-zxvf</span> tmp.txt</span><br><span class="line">hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/</span><br><span class="line">hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/NOTICE.txt</span><br><span class="line">hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/etc/</span><br><span class="line">hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/etc/hadoop/</span><br><span class="line">hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/etc/hadoop/kms<span class="literal">-log4j</span>.properties</span><br><span class="line">hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/etc/hadoop/mapred<span class="literal">-env</span>.sh</span><br><span class="line">hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/etc/hadoop/hdfs<span class="literal">-site</span>.xml</span><br><span class="line">hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/etc/hadoop/httpfs<span class="literal">-signature</span>.secret</span><br><span class="line">hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/etc/hadoop/mapred<span class="literal">-site</span>.xml.template</span><br><span class="line">...........................</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">subdir3</span>]<span class="variable">$</span> ll <span class="literal">-ah</span></span><br><span class="line">总用量 <span class="number">379</span>M</span><br><span class="line">drwxr<span class="literal">-xr-x</span>. <span class="number">3</span> Jermyn root  <span class="number">16</span>K <span class="number">5</span>月  <span class="number">25</span> <span class="number">15</span>:<span class="number">38</span> .</span><br><span class="line">drwxr<span class="literal">-xr-x</span>. <span class="number">6</span> Jermyn root <span class="number">4.0</span>K <span class="number">5</span>月  <span class="number">25</span> <span class="number">14</span>:<span class="number">28</span> ..</span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root  <span class="number">293</span> <span class="number">5</span>月  <span class="number">25</span> <span class="number">15</span>:<span class="number">19</span> blk_1073742740</span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root   <span class="number">11</span> <span class="number">5</span>月  <span class="number">25</span> <span class="number">15</span>:<span class="number">19</span> blk_1073742740_1916.meta</span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root <span class="number">128</span>M <span class="number">5</span>月  <span class="number">25</span> <span class="number">15</span>:<span class="number">22</span> blk_1073742741</span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root <span class="number">1.1</span>M <span class="number">5</span>月  <span class="number">25</span> <span class="number">15</span>:<span class="number">22</span> blk_1073742741_1917.meta</span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root  <span class="number">61</span>M <span class="number">5</span>月  <span class="number">25</span> <span class="number">15</span>:<span class="number">22</span> blk_1073742742</span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root <span class="number">485</span>K <span class="number">5</span>月  <span class="number">25</span> <span class="number">15</span>:<span class="number">22</span> blk_1073742742_1918.meta</span><br><span class="line">drwxr<span class="literal">-xr-x</span>. <span class="number">9</span> Jermyn root <span class="number">4.0</span>K <span class="number">5</span>月  <span class="number">22</span> <span class="number">2017</span> hadoop<span class="literal">-2</span>.<span class="number">7.2</span></span><br><span class="line"><span class="literal">-rw-r--r--</span>. <span class="number">1</span> Jermyn root <span class="number">189</span>M <span class="number">5</span>月  <span class="number">25</span> <span class="number">15</span>:<span class="number">37</span> tmp.txt</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525153835.png" alt=""></li></ul><h3 id="hadoop相关执行命令"><a href="#hadoop相关执行命令" class="headerlink" title="hadoop相关执行命令"></a><strong>hadoop相关执行命令</strong></h3><ul><li>启动NameNode<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop<span class="literal">-daemon</span>.sh <span class="built_in">start</span> namenode</span><br></pre></td></tr></table></figure></li><li>启动DataNode<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop<span class="literal">-daemon</span>.sh <span class="built_in">start</span> datanode</span><br></pre></td></tr></table></figure></li><li><strong>在HDFS文件系统上创建一个input文件夹</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs <span class="literal">-mkdir</span> <span class="literal">-p</span> /user/Jermyn/input</span><br></pre></td></tr></table></figure></li><li><strong>将本地的 wcinput/wc.input 上传到hdfs的/user/Jermyn/input</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs <span class="literal">-put</span> wcinput/wc.input /user/Jermyn/input</span><br></pre></td></tr></table></figure></li><li><strong>执行官方WordCount案例</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop jar share/hadoop/mapreduce/hadoop<span class="literal">-mapreduce-examples-2</span>.<span class="number">7.2</span>.jar wordcount /user/Jermyn/input /user/Jermyn/output</span><br></pre></td></tr></table></figure></li><li><strong>查看运行的结果</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop dfs <span class="literal">-cat</span> /user/Jermyn/output/p*</span><br></pre></td></tr></table></figure></li><li><strong>删除输出结果</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop dfs <span class="literal">-rm</span> <span class="literal">-r</span> /user/Jermyn/out</span><br></pre></td></tr></table></figure></li><li><p><strong>关闭NodeManager 、ResourceManager和HistoryManage</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sbin/yarn<span class="literal">-daemon</span>.sh stop nodemanager</span><br><span class="line">sbin/yarn<span class="literal">-daemon</span>.sh stop resourcemanager</span><br><span class="line">sbin/mr<span class="literal">-jobhistory-daemon</span>.sh stop historyserver</span><br></pre></td></tr></table></figure></li><li><p><strong>启动NodeManager 、ResourceManager和HistoryManager</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sbin/yarn<span class="literal">-daemon</span>.sh <span class="built_in">start</span> nodemanager</span><br><span class="line">sbin/yarn<span class="literal">-daemon</span>.sh <span class="built_in">start</span> resourcemanager</span><br><span class="line">sbin/mr<span class="literal">-jobhistory-daemon</span>.sh <span class="built_in">start</span> historyserver</span><br></pre></td></tr></table></figure></li><li><strong>启动HDFS</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/<span class="built_in">start-dfs</span>.sh</span><br></pre></td></tr></table></figure>-<strong>启动YARN，在hadoop103</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/<span class="built_in">start-yarn</span>.sh</span><br></pre></td></tr></table></figure></li></ul><h3 id="集群时间同步"><a href="#集群时间同步" class="headerlink" title="集群时间同步"></a>集群时间同步</h3><p>时间同步的方式：找一个机器，作为时间服务器，所有的机器与这台集群时间进行定时的同步，比如，每隔十分钟，同步一次时间。<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525161707.png" alt=""></p><ul><li><strong>时间服务器配置（必须root用户）</strong><ul><li><strong>检查ntp是否安装</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm <span class="literal">-qa</span>|grep ntp</span><br></pre></td></tr></table></figure></li><li><strong>修改ntp配置文件/ etc/ntp.conf</strong><br>修改内容如下:<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">修改1（授权192.168.1.0-192.168.1.255网段上的所有机器可以从这台机器上查询和同步时间）</span><br><span class="line">#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap为</span><br><span class="line">restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</span><br><span class="line"></span><br><span class="line">修改2（集群在局域网中，不使用其他互联网上的时间）</span><br><span class="line">server 0.centos.pool.ntp.org iburst</span><br><span class="line">server 1.centos.pool.ntp.org iburst</span><br><span class="line">server 2.centos.pool.ntp.org iburst</span><br><span class="line">server 3.centos.pool.ntp.org iburst为</span><br><span class="line">#server 0.centos.pool.ntp.org iburst</span><br><span class="line">#server 1.centos.pool.ntp.org iburst</span><br><span class="line">#server 2.centos.pool.ntp.org iburst</span><br><span class="line">#server 3.centos.pool.ntp.org iburst</span><br><span class="line"></span><br><span class="line">添加3（当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步）</span><br><span class="line">server 127.127.1.0</span><br><span class="line">fudge 127.127.1.0 stratum 10</span><br></pre></td></tr></table></figure></li><li><strong>修改/etc/sysconfig/ntpd 文件</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">增加内容如下（让硬件时间与系统时间一起同步）</span><br><span class="line"></span><br><span class="line">SYNC_HWCLOCK=yes</span><br></pre></td></tr></table></figure></li><li><strong>查看ntpd状态</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service ntpd status</span><br></pre></td></tr></table></figure></li><li><strong>启动ntpd</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service ntpd <span class="built_in">start</span></span><br></pre></td></tr></table></figure></li><li><strong>查看ntpd状态</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">hadoop102</span> ~]<span class="comment"># service ntpd status</span></span><br><span class="line">Redirecting to /bin/systemctl status ntpd.service</span><br><span class="line">● ntpd.service - Network Time Service</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/ntpd.service; disabled; vendor preset: disabled)</span><br><span class="line">   Active: inactive (dead)</span><br><span class="line">[<span class="type">root</span>@<span class="type">hadoop102</span> ~]<span class="comment"># service ntpd start</span></span><br><span class="line">Redirecting to /bin/systemctl <span class="built_in">start</span> ntpd.service</span><br><span class="line">[<span class="type">root</span>@<span class="type">hadoop102</span> ~]<span class="comment"># service ntpd status</span></span><br><span class="line">Redirecting to /bin/systemctl status ntpd.service</span><br><span class="line">● ntpd.service - Network Time Service</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/ntpd.service; disabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since 四 <span class="number">2023</span><span class="literal">-05-25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">05</span> CST; <span class="number">2</span>s ago</span><br><span class="line">  <span class="keyword">Process</span>: <span class="number">12860</span> ExecStart=/usr/sbin/ntpd <span class="literal">-u</span> ntp:ntp <span class="variable">$OPTIONS</span> (code=exited, status=<span class="number">0</span>/SUCCESS)</span><br><span class="line"> Main PID: <span class="number">12863</span> (ntpd)</span><br><span class="line">    Tasks: <span class="number">1</span></span><br><span class="line">   CGroup: /system.slice/ntpd.service</span><br><span class="line">           └─<span class="number">12863</span> /usr/sbin/ntpd <span class="literal">-u</span> ntp:ntp <span class="literal">-g</span></span><br><span class="line"></span><br><span class="line"><span class="number">5</span>月 <span class="number">25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">05</span> hadoop102 ntpd[<span class="number">12863</span>]: Listen normally on <span class="number">2</span> lo <span class="number">127.0</span>.<span class="number">0.1</span> UDP <span class="number">123</span></span><br><span class="line"><span class="number">5</span>月 <span class="number">25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">05</span> hadoop102 ntpd[<span class="number">12863</span>]: Listen normally on <span class="number">3</span> ens33 <span class="number">192.168</span>.<span class="number">10.102</span> UDP <span class="number">123</span></span><br><span class="line"><span class="number">5</span>月 <span class="number">25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">05</span> hadoop102 ntpd[<span class="number">12863</span>]: Listen normally on <span class="number">4</span> virbr0 <span class="number">192.168</span>.<span class="number">122.1</span> UDP <span class="number">123</span></span><br><span class="line"><span class="number">5</span>月 <span class="number">25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">05</span> hadoop102 ntpd[<span class="number">12863</span>]: Listen normally on <span class="number">5</span> lo ::<span class="number">1</span> UDP <span class="number">123</span></span><br><span class="line"><span class="number">5</span>月 <span class="number">25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">05</span> hadoop102 ntpd[<span class="number">12863</span>]: Listen normally on <span class="number">6</span> ens33 fe80::<span class="number">4</span>e60:<span class="number">766</span>f:adbc:<span class="number">1548</span> UDP <span class="number">123</span></span><br><span class="line"><span class="number">5</span>月 <span class="number">25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">05</span> hadoop102 ntpd[<span class="number">12863</span>]: Listening on routing socket on fd <span class="comment">#23 for interface updates</span></span><br><span class="line"><span class="number">5</span>月 <span class="number">25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">05</span> hadoop102 ntpd[<span class="number">12863</span>]: <span class="number">0.0</span>.<span class="number">0.0</span> c016 <span class="number">06</span> restart</span><br><span class="line"><span class="number">5</span>月 <span class="number">25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">05</span> hadoop102 ntpd[<span class="number">12863</span>]: <span class="number">0.0</span>.<span class="number">0.0</span> c012 <span class="number">02</span> freq_set kernel <span class="number">0.000</span> PPM</span><br><span class="line"><span class="number">5</span>月 <span class="number">25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">05</span> hadoop102 ntpd[<span class="number">12863</span>]: <span class="number">0.0</span>.<span class="number">0.0</span> c011 <span class="number">01</span> freq_not_set</span><br><span class="line"><span class="number">5</span>月 <span class="number">25</span> <span class="number">17</span>:<span class="number">18</span>:<span class="number">06</span> hadoop102 ntpd[<span class="number">12863</span>]: <span class="number">0.0</span>.<span class="number">0.0</span> c514 <span class="number">04</span> freq_mode</span><br><span class="line">[<span class="type">root</span>@<span class="type">hadoop102</span> ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure></li><li><strong>设置ntpd服务开机启动</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">hadoop102</span> ~]<span class="comment"># chkconfig ntpd on</span></span><br><span class="line">注意：正在将请求转发到“systemctl enable ntpd.service”。</span><br><span class="line">Created symlink from /etc/systemd/system/multi<span class="literal">-user</span>.target.wants/ntpd.service to /usr/lib/systemd/system/ntpd.service.</span><br></pre></td></tr></table></figure></li><li><strong>其他机器配置（必须root用户）</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">（<span class="number">1</span>）在其他机器配置<span class="number">10</span>分钟与时间服务器同步一次</span><br><span class="line">[<span class="type">root</span>@<span class="type">hadoop103</span>桌面]<span class="comment"># crontab -e</span></span><br><span class="line">编写定时任务如下：</span><br><span class="line">*/<span class="number">10</span> * * * * /usr/sbin/ntpdate hadoop102</span><br><span class="line">（<span class="number">2</span>）修改任意机器时间</span><br><span class="line">[<span class="type">root</span>@<span class="type">hadoop103</span>桌面]<span class="comment"># date -s &quot;2017-9-11 11:11:11&quot;</span></span><br><span class="line">（<span class="number">3</span>）十分钟后查看机器是否与时间服务器同步</span><br><span class="line">[<span class="type">root</span>@<span class="type">hadoop103</span>桌面]<span class="comment"># date</span></span><br><span class="line">说明：测试的时候可以将<span class="number">10</span>分钟调整为<span class="number">1</span>分钟，节省时间。</span><br></pre></td></tr></table></figure></li></ul></li></ul><h1 id="第四章-HDFS-概述"><a href="#第四章-HDFS-概述" class="headerlink" title="第四章 HDFS 概述"></a>第四章 HDFS 概述</h1><h2 id="HDFS优缺点"><a href="#HDFS优缺点" class="headerlink" title="HDFS优缺点"></a>HDFS优缺点</h2><ul><li><p><strong>优点</strong></p><ul><li>高容错性：<br>（1）数据自动保存多个副本。它通过增加副本的形式，提高容错性；<br>（2）某一个副本丢失以后，它可以自动恢复。</li><li>适合处理大数据：<br>（1）数据规模：能够处理数据规模达到GB、TB、甚至PB级别的数据；<br>（2）文件规模：能够处理百万规模以上的文件数量，数量相当之大。</li><li>可构建在廉价机器上，通过多副本机制，提高可靠性。</li></ul></li><li><p><strong>缺点</strong></p><ul><li>不适合低延时数据访问，比如毫秒级的存储数据，是做不到的。</li><li>无法高效的对大量小文件进行存储。<br>（1）存储大量小文件的话，它会占用NameNode大量的内存来存储文件目录和块信息。这样是不可取的，因为NameNode的内存总是有限的；<br>（2）小文件存储的寻址时间会超过读取时间，它违反了HDFS的设计目标。</li><li>不支持并发写入、文件随机修改。<br>（1）一个文件只能有一个写，不允许多个线程同时写；<br>（2）仅支持数据append（追加），不支持文件的随机修改。</li></ul></li></ul><h2 id="HDFS组成架构"><a href="#HDFS组成架构" class="headerlink" title="HDFS组成架构"></a>HDFS组成架构</h2><ol><li>NameNode（nn）：就是Master，它是一个主管、管理者。<br>（1）管理HDFS的名称空间；<br>（2）配置副本策略；<br>（3）管理数据块（Block）映射信息；<br>（4）处理客户端读写请求。</li><li>DataNode：就是Slave。NameNode下达命令，DataNode执行实际的操作。<br>（1）存储实际的数据块；<br>（2）执行数据块的读/写操作。</li><li>Client：就是客户端。<br>（1）文件切分。文件上传HDFS的时候，Client将文件切分成一个一个的Block，然后进行上传；<br>（2）与NameNode交互，获取文件的位置信息；<br>（3）与DataNode交互，读取或者写入数据；<br>（4）Client提供一些命令来管理HDFS，比如NameNode格式化；<br>（5）Client可以通过一些命令来访问HDFS，比如对HDFS增删查改操作；</li><li>Secondary NameNode：并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。<br>（1）辅助NameNode，分担其工作量，比如定期合并Fsimage和Edits，并推送给NameNode ；<br>（2）在紧急情况下，可辅助恢复NameNode。</li></ol><h2 id="HDFS文件块大小"><a href="#HDFS文件块大小" class="headerlink" title="HDFS文件块大小"></a>HDFS文件块大小</h2><p>HDFS中的文件在物理上是分块存储（Block），块的大小可以通过配置参数( dfs.blocksize)来规定，默认大小在Hadoop2.x版本中是128M，老版本中是64M。<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230525195408.png" alt=""></p><h1 id="第五章-HDFS的Shell操作"><a href="#第五章-HDFS的Shell操作" class="headerlink" title="第五章 HDFS的Shell操作"></a>第五章 HDFS的Shell操作</h1><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop fs 具体命令</span><br><span class="line">bin/hdfs dfs 具体命令</span><br></pre></td></tr></table></figure><h2 id="常用命令实操"><a href="#常用命令实操" class="headerlink" title="常用命令实操"></a>常用命令实操</h2><ol><li>启动Hadoop集群<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> ~]<span class="variable">$</span> <span class="built_in">start-dfs</span>.sh</span><br><span class="line">Starting namenodes on [<span class="type">hadoop102</span>]</span><br><span class="line">hadoop102: starting namenode, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-namenode-hadoop102</span>.out</span><br><span class="line">hadoop103: starting datanode, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-datanode-hadoop103</span>.out</span><br><span class="line">hadoop104: starting datanode, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-datanode-hadoop104</span>.out</span><br><span class="line">hadoop102: starting datanode, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-datanode-hadoop102</span>.out</span><br><span class="line">Starting secondary namenodes [<span class="type">hadoop104</span>]</span><br><span class="line">hadoop104: starting secondarynamenode, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-secondarynamenode-hadoop104</span>.out</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> ~]<span class="variable">$</span> jps</span><br><span class="line"><span class="number">2305</span> DataNode</span><br><span class="line"><span class="number">2409</span> NodeManager</span><br><span class="line"><span class="number">2729</span> Jps</span><br><span class="line"><span class="number">2190</span> NameNode</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop103</span> ~]<span class="variable">$</span> <span class="built_in">start-yarn</span>.sh</span><br><span class="line">starting yarn daemons</span><br><span class="line">starting resourcemanager, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/yarn<span class="literal">-Jermyn-resourcemanager-hadoop103</span>.out</span><br><span class="line">hadoop104: starting nodemanager, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/yarn<span class="literal">-Jermyn-nodemanager-hadoop104</span>.out</span><br><span class="line">hadoop103: starting nodemanager, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/yarn<span class="literal">-Jermyn-nodemanager-hadoop103</span>.out</span><br><span class="line">hadoop102: starting nodemanager, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/yarn<span class="literal">-Jermyn-nodemanager-hadoop102</span>.out</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop103</span> ~]<span class="variable">$</span> jps</span><br><span class="line"><span class="number">2561</span> Jps</span><br><span class="line"><span class="number">2066</span> ResourceManager</span><br><span class="line"><span class="number">2005</span> DataNode</span><br><span class="line"><span class="number">2191</span> NodeManager</span><br></pre></td></tr></table></figure></li><li>-help：输出这个命令参数(查某个命令的使用)<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> ~]<span class="variable">$</span> hadoop fs <span class="literal">-help</span> mkdir</span><br><span class="line"><span class="literal">-mkdir</span> [-<span class="type">p</span>] &lt;path&gt; ... :</span><br><span class="line">  Create a directory <span class="keyword">in</span> specified location.</span><br><span class="line"></span><br><span class="line">  <span class="literal">-p</span>  <span class="keyword">Do</span> not fail <span class="keyword">if</span> the directory already exists</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> ~]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li>-ls: 显示目录信息　<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> ~]<span class="variable">$</span> hadoop fs <span class="literal">-ls</span> /</span><br><span class="line">Found <span class="number">1</span> items</span><br><span class="line">drwxr<span class="literal">-xr-x</span>   - Jermyn supergroup          <span class="number">0</span> <span class="number">2023</span><span class="literal">-05-25</span> <span class="number">14</span>:<span class="number">24</span> /user</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> ~]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li>-mkdir：在HDFS上创建目录<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> ~]<span class="variable">$</span> hadoop fs <span class="literal">-mkdir</span> <span class="literal">-p</span> /folder1/folder2/folder3</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230526103718.png" alt=""></li><li>-moveFromLocal：从本地剪切粘贴到HDFS<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> ll</span><br><span class="line">总用量 <span class="number">8</span></span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">38</span> demo.txt</span><br><span class="line">drwxr<span class="literal">-xr-x</span>. <span class="number">15</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">25</span> <span class="number">10</span>:<span class="number">52</span> hadoop<span class="literal">-2</span>.<span class="number">7.2</span></span><br><span class="line">drwxr<span class="literal">-xr-x</span>.  <span class="number">8</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">18</span>:<span class="number">55</span> jdk1.<span class="number">8.0</span>_144</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-moveFromLocal</span> ./demo.txt /folder1/folder2/folder3</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> ll</span><br><span class="line">总用量 <span class="number">8</span></span><br><span class="line">drwxr<span class="literal">-xr-x</span>. <span class="number">15</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">25</span> <span class="number">10</span>:<span class="number">52</span> hadoop<span class="literal">-2</span>.<span class="number">7.2</span></span><br><span class="line">drwxr<span class="literal">-xr-x</span>.  <span class="number">8</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">18</span>:<span class="number">55</span> jdk1.<span class="number">8.0</span>_144</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230526104029.png" alt=""></li><li>-appendToFile：追加一个文件到已经存在的文件末尾<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> vim demo2.txt</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> <span class="built_in">cat</span> demo2.txt</span><br><span class="line">hello hadoop2.<span class="number">7.2</span></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-appendToFile</span> ./demo2.txt /folder1/folder2/folder3/demo.txt</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230526104628.png" alt=""></li><li>-cat：显示文件内容<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> <span class="built_in">cat</span> demo2.txt</span><br><span class="line">hello hadoop2.<span class="number">7.2</span></span><br></pre></td></tr></table></figure></li><li>-chgrp 、-chmod、-chown：Linux文件系统中的用法一样，修改文件所属权限<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-chgrp</span> Jermyn /folder1/folder2/folder3/demo.txt</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230526105125.png" alt=""></li><li>-copyFromLocal：从本地文件系统中拷贝文件到HDFS路径去<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-copyFromLocal</span> ./DEMO.txt /folder1/folder2/folder3</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230526105506.png" alt=""></li><li>-copyToLocal：从HDFS拷贝到本地<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> ll</span><br><span class="line">总用量 <span class="number">12</span></span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root     <span class="number">18</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">43</span> demo2.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">52</span> DEMO.txt</span><br><span class="line">drwxr<span class="literal">-xr-x</span>. <span class="number">15</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">25</span> <span class="number">10</span>:<span class="number">52</span> hadoop<span class="literal">-2</span>.<span class="number">7.2</span></span><br><span class="line">drwxr<span class="literal">-xr-x</span>.  <span class="number">8</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">18</span>:<span class="number">55</span> jdk1.<span class="number">8.0</span>_144</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-copyToLocal</span> /folder1/folder2/folder3/demo.txt ./</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> ll</span><br><span class="line">总用量 <span class="number">16</span></span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root     <span class="number">18</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">43</span> demo2.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root     <span class="number">18</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">57</span> demo.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">52</span> DEMO.txt</span><br><span class="line">drwxr<span class="literal">-xr-x</span>. <span class="number">15</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">25</span> <span class="number">10</span>:<span class="number">52</span> hadoop<span class="literal">-2</span>.<span class="number">7.2</span></span><br><span class="line">drwxr<span class="literal">-xr-x</span>.  <span class="number">8</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">18</span>:<span class="number">55</span> jdk1.<span class="number">8.0</span>_144</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li>-cp ：从HDFS的一个路径拷贝到HDFS的另一个路径<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-cp</span> /user/Jermyn/input/wcinput /folder1/folder2/folder3</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-ls</span> /folder1/folder2/folder3</span><br><span class="line">Found <span class="number">3</span> items</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">3</span> Jermyn supergroup          <span class="number">0</span> <span class="number">2023</span><span class="literal">-05-26</span> <span class="number">10</span>:<span class="number">54</span> /folder1/folder2/folder3/DEMO.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">3</span> Jermyn Jermyn             <span class="number">18</span> <span class="number">2023</span><span class="literal">-05-26</span> <span class="number">10</span>:<span class="number">44</span> /folder1/folder2/folder3/demo.txt</span><br><span class="line">drwxr<span class="literal">-xr-x</span>   - Jermyn supergroup          <span class="number">0</span> <span class="number">2023</span><span class="literal">-05-26</span> <span class="number">10</span>:<span class="number">59</span> /folder1/folder2/folder3/wcinput</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230526110030.png" alt=""></li><li>-mv：在HDFS目录中移动文件<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-mv</span> /folder1/folder2/folder3/demo.txt /user/Jermyn/input</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-ls</span> /user/Jermyn/input</span><br><span class="line">Found <span class="number">3</span> items</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">3</span> Jermyn Jermyn             <span class="number">18</span> <span class="number">2023</span><span class="literal">-05-26</span> <span class="number">10</span>:<span class="number">44</span> /user/Jermyn/input/demo.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">3</span> Jermyn supergroup  <span class="number">197657687</span> <span class="number">2023</span><span class="literal">-05-25</span> <span class="number">15</span>:<span class="number">22</span> /user/Jermyn/input/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>.tar.gz</span><br><span class="line">drwxr<span class="literal">-xr-x</span>   - Jermyn supergroup          <span class="number">0</span> <span class="number">2023</span><span class="literal">-05-25</span> <span class="number">15</span>:<span class="number">19</span> /user/Jermyn/input/wcinput</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230526110313.png" alt=""></li><li>-get：等同于copyToLocal，就是从HDFS下载文件到本地<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-get</span> /folder1/folder2/folder3/wcinput /opt/module/</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> ll</span><br><span class="line">总用量 <span class="number">20</span></span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root     <span class="number">18</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">43</span> demo2.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root     <span class="number">18</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">57</span> demo.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">52</span> DEMO.txt</span><br><span class="line">drwxr<span class="literal">-xr-x</span>. <span class="number">15</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">25</span> <span class="number">10</span>:<span class="number">52</span> hadoop<span class="literal">-2</span>.<span class="number">7.2</span></span><br><span class="line">drwxr<span class="literal">-xr-x</span>.  <span class="number">8</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">18</span>:<span class="number">55</span> jdk1.<span class="number">8.0</span>_144</span><br><span class="line">drwxr<span class="literal">-xr-x</span>.  <span class="number">2</span> Jermyn root   <span class="number">4096</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">11</span>:<span class="number">09</span> wcinput</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> </span><br></pre></td></tr></table></figure></li><li>-put：等同于copyFromLocal<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> ll</span><br><span class="line">总用量 <span class="number">20</span></span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root     <span class="number">18</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">43</span> demo2.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root     <span class="number">18</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">57</span> demo.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">52</span> DEMO.txt</span><br><span class="line">drwxr<span class="literal">-xr-x</span>. <span class="number">15</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">25</span> <span class="number">10</span>:<span class="number">52</span> hadoop<span class="literal">-2</span>.<span class="number">7.2</span></span><br><span class="line">drwxr<span class="literal">-xr-x</span>.  <span class="number">8</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">18</span>:<span class="number">55</span> jdk1.<span class="number">8.0</span>_144</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">11</span>:<span class="number">12</span> log1.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">11</span>:<span class="number">12</span> log2.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">11</span>:<span class="number">12</span> log3.txt</span><br><span class="line">drwxr<span class="literal">-xr-x</span>.  <span class="number">2</span> Jermyn root   <span class="number">4096</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">11</span>:<span class="number">09</span> wcinput</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-put</span> log* /log</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230526111445.png" alt=""></li><li>-getmerge：合并下载多个文件，比如HDFS的目录 /user/Jermyn/test下有多个文件:log.1, log.2,log.3,…<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-getmerge</span> /log/log* /opt/module/log_mege.txt</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> ll</span><br><span class="line">总用量 <span class="number">20</span></span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root     <span class="number">18</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">43</span> demo2.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root     <span class="number">18</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">57</span> demo.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">10</span>:<span class="number">52</span> DEMO.txt</span><br><span class="line">drwxr<span class="literal">-xr-x</span>. <span class="number">15</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">25</span> <span class="number">10</span>:<span class="number">52</span> hadoop<span class="literal">-2</span>.<span class="number">7.2</span></span><br><span class="line">drwxr<span class="literal">-xr-x</span>.  <span class="number">8</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">5</span>月  <span class="number">24</span> <span class="number">18</span>:<span class="number">55</span> jdk1.<span class="number">8.0</span>_144</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">11</span>:<span class="number">12</span> log1.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">11</span>:<span class="number">12</span> log2.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">11</span>:<span class="number">12</span> log3.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root      <span class="number">0</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">11</span>:<span class="number">16</span> log_mege.txt</span><br><span class="line">drwxr<span class="literal">-xr-x</span>.  <span class="number">2</span> Jermyn root   <span class="number">4096</span> <span class="number">5</span>月  <span class="number">26</span> <span class="number">11</span>:<span class="number">09</span> wcinput</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li>-tail：显示一个文件的末尾<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-tail</span> /user/Jermyn/input/wcinput/wc.input</span><br><span class="line">JERMYN JREMYEN Jermfdyn java JAVA hadoop HADOOP</span><br><span class="line">JERMYTN JREMYDN Jefrmyn java JAVA hadoop HADOOP</span><br><span class="line">JERMYCN JRECMYN Jermyfn javaC JAVAA hadoop HADOOP</span><br><span class="line">EJERMYN JREEMYN Jermyn javac JAVA hadoop HADOOP</span><br><span class="line">JEERMYN JREEMYN Jermyn javaSE JAVA hadoop HADOOP</span><br><span class="line">JERDMYN JEREMYN Jermyn javaEE JAVA hadoop HADOOP</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li>-rm：删除文件或文件夹<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-rm</span> <span class="literal">-R</span> /folder1</span><br><span class="line"><span class="number">23</span>/<span class="number">05</span>/<span class="number">26</span> <span class="number">11</span>:<span class="number">21</span>:<span class="number">44</span> INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = <span class="number">0</span> minutes, Emptier interval = <span class="number">0</span> minutes.</span><br><span class="line">Deleted /folder1</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230526112207.png" alt=""></li><li>-rmdir：删除空目录<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-mkdir</span> /FolderEmpt</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-rmdir</span> /FolderEmpt</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li>-du统计文件夹的大小信息<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-du</span> /</span><br><span class="line"><span class="number">0</span>          /log</span><br><span class="line"><span class="number">197657998</span>  /user</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li>-setrep：设置HDFS中文件的副本数量<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop fs <span class="literal">-setrep</span> <span class="number">7</span> /user/Jermyn/input/wcinput/wc.input</span><br><span class="line">Replication <span class="number">7</span> <span class="built_in">set</span>: /user/Jermyn/input/wcinput/wc.input</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230526112849.png" alt=""><span class="p red">这里设置的副本数只是记录在NameNode的元数据中，是否真的会有这么多副本，还得看DataNode的数量，因为目前只有3台设备，最多也就3个副本，只有节点数的增加到7台时，副本数才能达到7</span></li></ol><h1 id="第六章-HDFS客户端操作"><a href="#第六章-HDFS客户端操作" class="headerlink" title="第六章 HDFS客户端操作"></a>第六章 HDFS客户端操作</h1><h2 id="HDFS客户端环境准备"><a href="#HDFS客户端环境准备" class="headerlink" title="HDFS客户端环境准备"></a>HDFS客户端环境准备</h2><ol><li><strong>Win下面配置高级环境变量</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">HADOOP_HOME=D:\PATH_EN\hadoop<span class="literal">-2</span>.<span class="number">7.2</span></span><br><span class="line"></span><br><span class="line">path添加：</span><br><span class="line">PATH=%HADOOP_HOME%\bin</span><br></pre></td></tr></table></figure></li><li><strong>创建一个Maven工程HdfsClient</strong><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230527195758.png" alt=""></li><li><strong>导入相应的依赖坐标+日志添加</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span> <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.example<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>HdfsClient<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">packaging</span>&gt;</span>jar<span class="tag">&lt;/<span class="name">packaging</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>HdfsClient<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.apache.org<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.8.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><strong>注意：如果Eclipse/Idea打印不出日志，需要在项目的src/main/resources目录下，新建一个文件，命名为“log4j.properties”，在文件中填入</strong><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">log4j.rootLogger</span>=<span class="string">INFO, stdout</span></span><br><span class="line"><span class="attr">log4j.appender.stdout</span>=<span class="string">org.apache.log4j.ConsoleAppender</span></span><br><span class="line"><span class="attr">log4j.appender.stdout.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="attr">log4j.appender.stdout.layout.ConversionPattern</span>=<span class="string">%d %p [%c] - %m%n</span></span><br><span class="line"><span class="attr">log4j.appender.logfile</span>=<span class="string">org.apache.log4j.FileAppender</span></span><br><span class="line"><span class="attr">log4j.appender.logfile.File</span>=<span class="string">target/spring.log</span></span><br><span class="line"><span class="attr">log4j.appender.logfile.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="attr">log4j.appender.logfile.layout.ConversionPattern</span>=<span class="string">%d %p [%c] - %m%n</span></span><br></pre></td></tr></table></figure></li><li><strong>创建HdfsClient类测试</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.hdfs;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"><span class="keyword">import</span> java.net.URISyntaxException;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HDFSClient</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, URISyntaxException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * hadoop在访问hdfs的时候会进行权限认证，取用户名的过程是这样的：</span></span><br><span class="line"><span class="comment">         * 读取HADOOP_USER_NAME系统环境变量，如果不为空，那么拿它作username，如果为空</span></span><br><span class="line"><span class="comment">         * 读取HADOOP_USER_NAME这个java环境变量，如果为空</span></span><br><span class="line"><span class="comment">         * 从com.sun.security.auth.NTUserPrincipal或者com.sun.security.auth.UnixPrincipal的实例获取username。</span></span><br><span class="line"><span class="comment">         * 如果以上尝试都失败，那么抛出异常LoginException(&quot;Can’t find user name&quot;)</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"><span class="comment">//        Properties properties = System.getProperties();</span></span><br><span class="line"><span class="comment">//        properties.setProperty(&quot;HADOOP_USER_NAME&quot;, &quot;Jermyn&quot;);</span></span><br><span class="line"></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>, <span class="string">&quot;hdfs://hadoop102:9000&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1.获取hdfs客户端对象</span></span><br><span class="line"><span class="comment">//        FileSystem fileSystem = FileSystem.get(conf);</span></span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fileSystem</span> <span class="operator">=</span> FileSystem.get(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>), conf, <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 2.在hdfs上创建路径</span></span><br><span class="line">        fileSystem.mkdirs(<span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/hdfsClient/demo/test&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3.关闭资源</span></span><br><span class="line">        fileSystem.close();</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;OVER&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230527200459.png" alt=""></li></ol><h2 id="HDFS的API操作"><a href="#HDFS的API操作" class="headerlink" title="HDFS的API操作"></a>HDFS的API操作</h2><h3 id="HDFS文件上传（测试参数优先级）"><a href="#HDFS文件上传（测试参数优先级）" class="headerlink" title="HDFS文件上传（测试参数优先级）"></a>HDFS文件上传（测试参数优先级）</h3><ol><li><strong>编写源代码</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testCopyFromLocalFile</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1.获取fs对象</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fileSystem</span> <span class="operator">=</span> FileSystem.get(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>), conf, <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2.执行上传API</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">src</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;D:/TestData.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 第一次客户端代码中设置的值默认副本为3</span></span><br><span class="line"><span class="comment">//        Path dst = new Path(&quot;/hdfsClient/demo/test&quot;);</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 第二次配置xml，副本设为1</span></span><br><span class="line"><span class="comment">//        Path dst = new Path(&quot;/hdfsClient/demo/test/TestData2.txt&quot;);</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 第三次设置副本数</span></span><br><span class="line">    conf.set(<span class="string">&quot;dfs.replication&quot;</span>,<span class="string">&quot;2&quot;</span>);</span><br><span class="line">    <span class="type">Path</span> <span class="variable">dst</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/hdfsClient/demo/test/TestData3.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">    fileSystem.copyFromLocalFile(src, dst);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3.关闭对象</span></span><br><span class="line">    fileSystem.close();</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">&quot;over&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230527202444.png" alt=""></li><li><strong>将hdfs-site.xml拷贝到项目的根目录下</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230527203019.png" alt=""></li><li><strong>参数优先级</strong><br>参数优先级排序：<span class="p red">（1）客户端代码中设置的值 >（2）ClassPath下的用户自定义配置文件 >（3）然后是服务器的默认配置</span><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230527203244.png" alt=""></li></ol><h3 id="HDFS文件下载"><a href="#HDFS文件下载" class="headerlink" title="HDFS文件下载"></a>HDFS文件下载</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testCopyToLocalFile</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1.获取文件系统</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fileSystem</span> <span class="operator">=</span> FileSystem.get(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>), configuration, <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2.执行下载操作</span></span><br><span class="line">    <span class="comment">// boolean delSrc 指是否将原文件删除</span></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">delSrc</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Path src 指要下载的文件路径</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">src</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/hdfsClient/demo/test/TestData.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Path dst 指将文件下载到的路径</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">dst</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;C:\\Users\\Administrator\\Desktop&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// boolean useRawLocalFileSystem 是否开启文件校验</span></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">useRawLocalFileSystem</span> <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line">    fileSystem.copyToLocalFile(delSrc, src, dst, useRawLocalFileSystem);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3.关闭资源</span></span><br><span class="line">    fileSystem.close();</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">&quot;OVER&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528104839.png" alt=""></p><h3 id="HDFS文件的删除"><a href="#HDFS文件的删除" class="headerlink" title="HDFS文件的删除"></a>HDFS文件的删除</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testDelete</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1 获取文件系统</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fileSystem</span> <span class="operator">=</span> FileSystem.get(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>), conf, <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2 执行删除</span></span><br><span class="line">    <span class="comment">// 要删除的路径</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">f</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/hdfsClient/demo/test/TestData3.txt&quot;</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 如果path是一个目录并设置为true，则删除该目录，否则抛出异常。在文件的情况下，递归可以设置为true或false。</span></span><br><span class="line">    <span class="type">boolean</span> recursive= <span class="literal">true</span>;</span><br><span class="line">    fileSystem.delete(f, recursive);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3 关闭资源</span></span><br><span class="line">    fileSystem.close();</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">&quot;OVER&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="HDFS文件名更改"><a href="#HDFS文件名更改" class="headerlink" title="HDFS文件名更改"></a>HDFS文件名更改</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testRename</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1 获取文件系统</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>), configuration, <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// src -要重命名的路径</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">src</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/hdfsClient/demo/test/TestData2.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// dst -重命名后的新路径</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">dst</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/hdfsClient/demo/test/TestData3.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2 修改文件名称</span></span><br><span class="line">    fs.rename(src,dst);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3 关闭资源</span></span><br><span class="line">    fs.close();</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">&quot;OVER&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="HDFS文件详情查看"><a href="#HDFS文件详情查看" class="headerlink" title="HDFS文件详情查看"></a>HDFS文件详情查看</h3><p><strong>查看文件名称、权限、长度、块信息</strong><br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testListFiles</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException &#123;</span><br><span class="line">    <span class="comment">// 1 获取文件系统</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>), configuration, <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2 获取文件详情</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// f 是递归路径</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">f</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/&quot;</span>);</span><br><span class="line">    <span class="comment">// 递归地遍历</span></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">recursive</span> <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="comment">// 返回遍历文件状态的迭代器</span></span><br><span class="line">    RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fs.listFiles(f, recursive);</span><br><span class="line">    <span class="keyword">while</span> (listFiles.hasNext()) &#123;</span><br><span class="line">        <span class="type">LocatedFileStatus</span> <span class="variable">status</span> <span class="operator">=</span> listFiles.next();</span><br><span class="line">        <span class="comment">// 输出详情</span></span><br><span class="line">        <span class="comment">// 文件名称</span></span><br><span class="line">        System.out.println(<span class="string">&quot;文件名称：&quot;</span>+status.getPath().getName());</span><br><span class="line">        <span class="comment">// 长度</span></span><br><span class="line">        System.out.println(<span class="string">&quot;文件的大小（长度）：&quot;</span>+status.getLen());</span><br><span class="line">        <span class="comment">// 权限</span></span><br><span class="line">        System.out.println(<span class="string">&quot;文件的权限：&quot;</span>+status.getPermission());</span><br><span class="line">        <span class="comment">// 分组</span></span><br><span class="line">        System.out.println(<span class="string">&quot;文件的所属组：&quot;</span>+status.getGroup());</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;----------------------------------&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 文件的块位置</span></span><br><span class="line">        BlockLocation[] blockLocations = status.getBlockLocations();</span><br><span class="line">        <span class="keyword">for</span> (BlockLocation blockLocation : blockLocations) &#123;</span><br><span class="line">            <span class="keyword">for</span> (String host : blockLocation.getHosts()) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;承载此文件的主机名：&quot;</span>+host);</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;--------------------------------------&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    fs.close();</span><br><span class="line">    System.out.println(<span class="string">&quot;OVER&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><details class="folding-tag" green><summary>点击查看运行结果</summary><div class="content"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">D:\PATH_EN\JDK17\bin\java.exe...</span><br><span class="line">文件名称：TestData.txt</span><br><span class="line">文件的大小（长度）：<span class="number">0</span></span><br><span class="line">文件的权限：rw-r--r--</span><br><span class="line">文件的所属组：supergroup</span><br><span class="line">----------------------------------</span><br><span class="line">文件名称：TestData3.txt</span><br><span class="line">文件的大小（长度）：<span class="number">0</span></span><br><span class="line">文件的权限：rw-r--r--</span><br><span class="line">文件的所属组：supergroup</span><br><span class="line">----------------------------------</span><br><span class="line">文件名称：log1.txt</span><br><span class="line">文件的大小（长度）：<span class="number">0</span></span><br><span class="line">文件的权限：rw-r--r--</span><br><span class="line">文件的所属组：supergroup</span><br><span class="line">----------------------------------</span><br><span class="line">文件名称：log2.txt</span><br><span class="line">文件的大小（长度）：<span class="number">0</span></span><br><span class="line">文件的权限：rw-r--r--</span><br><span class="line">文件的所属组：supergroup</span><br><span class="line">----------------------------------</span><br><span class="line">文件名称：log3.txt</span><br><span class="line">文件的大小（长度）：<span class="number">0</span></span><br><span class="line">文件的权限：rw-r--r--</span><br><span class="line">文件的所属组：supergroup</span><br><span class="line">----------------------------------</span><br><span class="line">文件名称：demo.txt</span><br><span class="line">文件的大小（长度）：<span class="number">18</span></span><br><span class="line">文件的权限：rw-r--r--</span><br><span class="line">文件的所属组：Jermyn</span><br><span class="line">----------------------------------</span><br><span class="line">承载此文件的主机名：hadoop104</span><br><span class="line">承载此文件的主机名：hadoop102</span><br><span class="line">承载此文件的主机名：hadoop103</span><br><span class="line">--------------------------------------</span><br><span class="line">文件名称：hadoop-<span class="number">2.7</span><span class="number">.2</span>.tar.gz</span><br><span class="line">文件的大小（长度）：<span class="number">197657687</span></span><br><span class="line">文件的权限：rw-r--r--</span><br><span class="line">文件的所属组：supergroup</span><br><span class="line">----------------------------------</span><br><span class="line">承载此文件的主机名：hadoop104</span><br><span class="line">承载此文件的主机名：hadoop102</span><br><span class="line">承载此文件的主机名：hadoop103</span><br><span class="line">--------------------------------------</span><br><span class="line">承载此文件的主机名：hadoop104</span><br><span class="line">承载此文件的主机名：hadoop102</span><br><span class="line">承载此文件的主机名：hadoop103</span><br><span class="line">--------------------------------------</span><br><span class="line">文件名称：wc.input</span><br><span class="line">文件的大小（长度）：<span class="number">293</span></span><br><span class="line">文件的权限：rw-r--r--</span><br><span class="line">文件的所属组：supergroup</span><br><span class="line">----------------------------------</span><br><span class="line">承载此文件的主机名：hadoop104</span><br><span class="line">承载此文件的主机名：hadoop102</span><br><span class="line">承载此文件的主机名：hadoop103</span><br><span class="line">--------------------------------------</span><br><span class="line">OVER</span><br><span class="line"></span><br><span class="line">Process finished with exit code <span class="number">0</span></span><br></pre></td></tr></table></figure></div></details><p></p><h3 id="HDFS文件和文件夹判断"><a href="#HDFS文件和文件夹判断" class="headerlink" title="HDFS文件和文件夹判断"></a>HDFS文件和文件夹判断</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testListStatus</span><span class="params">()</span> <span class="keyword">throws</span> IOException, URISyntaxException, InterruptedException &#123;</span><br><span class="line">    <span class="comment">// 1 获取文件系统</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>), configuration, <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="type">Path</span> <span class="variable">path</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/&quot;</span>);</span><br><span class="line">    FileStatus[] fileStatuses = fs.listStatus(path);</span><br><span class="line">    <span class="keyword">for</span> (FileStatus fileStatus : fileStatuses) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 判断是文件还是文件夹</span></span><br><span class="line">        <span class="keyword">if</span> (fileStatus.isFile()) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;f：&quot;</span> + fileStatus.getPath().getName());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;d：&quot;</span> + fileStatus.getPath().getName());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="HDFS的I-O流操作"><a href="#HDFS的I-O流操作" class="headerlink" title="HDFS的I/O流操作"></a>HDFS的I/O流操作</h2><h3 id="HDFS文件上传"><a href="#HDFS文件上传" class="headerlink" title="HDFS文件上传"></a>HDFS文件上传</h3><ol><li><strong>需求：把本机桌面(C:\Users\Administrator\Desktop)上的文件Test.txt上传到HDFS(/hdfsClient/demo/test/Test.txt)目录</strong></li><li><strong>编写代码</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">getFileFromHDFS</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1 获取文件系统</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>),</span><br><span class="line">            configuration,</span><br><span class="line">            <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2 获取输入流</span></span><br><span class="line">    <span class="type">FileInputStream</span> <span class="variable">fis</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileInputStream</span>(</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\Test.txt&quot;</span>));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3 获取输出流</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">f</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/hdfsClient/demo/test/Test.txt&quot;</span>);</span><br><span class="line">    <span class="type">FSDataOutputStream</span> <span class="variable">fos</span> <span class="operator">=</span> fs.create(f);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4 流的对拷</span></span><br><span class="line">    IOUtils.copyBytes(fis, fos, configuration);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5 关闭资源</span></span><br><span class="line">    IOUtils.closeStream(fos);</span><br><span class="line">    IOUtils.closeStream(fis);</span><br><span class="line">    fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528165150.png" alt=""></li></ol><h3 id="HDFS文件下载-1"><a href="#HDFS文件下载-1" class="headerlink" title="HDFS文件下载"></a>HDFS文件下载</h3><ol><li><strong>需求：从HDFS(/log)上下载log1.txt文件到本地桌面（C:\Users\Administrator\Desktop）上</strong></li><li><strong>编写代码</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">getFileFromHDFS</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException &#123;</span><br><span class="line">    <span class="comment">// 1 获取文件系统</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>),</span><br><span class="line">            configuration,</span><br><span class="line">            <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2 获取输入流</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">f</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/log/log1.txt&quot;</span>);</span><br><span class="line">    <span class="type">FSDataInputStream</span> <span class="variable">fis</span> <span class="operator">=</span> fs.open(f);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3 获取输出流</span></span><br><span class="line">    <span class="type">FileOutputStream</span> <span class="variable">fos</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileOutputStream</span>(<span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\log.txt&quot;</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4 流的对拷</span></span><br><span class="line">    IOUtils.copyBytes(fis, fos, configuration);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5 关闭资源</span></span><br><span class="line">    IOUtils.closeStream(fis);</span><br><span class="line">    IOUtils.closeStream(fos);</span><br><span class="line">    fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528170500.png" alt=""></li></ol><h3 id="定位文件读取"><a href="#定位文件读取" class="headerlink" title="定位文件读取"></a>定位文件读取</h3><ol><li><strong>需求：分块读取HDFS上的大文件，比如根目录下的/user/Jermyn/input/hadoop-2.7.2.tar.gz</strong></li><li><strong>编写代码</strong></li></ol><ul><li><strong>下载第一块</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFileSeek1</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException &#123;</span><br><span class="line">    <span class="comment">// 1 获取文件系统</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>),</span><br><span class="line">            configuration,</span><br><span class="line">            <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2 获取输入流</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">f</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/user/Jermyn/input/hadoop-2.7.2.tar.gz&quot;</span>);</span><br><span class="line">    <span class="type">FSDataInputStream</span> <span class="variable">fis</span> <span class="operator">=</span> fs.open(f);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3 获取输出流</span></span><br><span class="line">    <span class="type">FileOutputStream</span> <span class="variable">fos</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileOutputStream</span>(</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\hadoop-2.7.2.tar.gz.block1&quot;</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4 流的对拷(只拷贝128)</span></span><br><span class="line">    <span class="type">byte</span>[] bytes = <span class="keyword">new</span> <span class="title class_">byte</span>[<span class="number">1024</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">1024</span> * <span class="number">128</span>; i++) &#123;</span><br><span class="line">        fis.read(bytes);</span><br><span class="line">        fos.write(bytes);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5 关闭资源</span></span><br><span class="line">    IOUtils.closeStream(fis);</span><br><span class="line">    IOUtils.closeStream(fos);</span><br><span class="line">    fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528171624.png" alt=""></li><li><strong>下载第二块</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFileSeek2</span><span class="params">()</span> <span class="keyword">throws</span> URISyntaxException, IOException, InterruptedException &#123;</span><br><span class="line">    <span class="comment">// 1 获取文件系统</span></span><br><span class="line">    <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">    <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;hdfs://hadoop102:9000&quot;</span>),</span><br><span class="line">            configuration,</span><br><span class="line">            <span class="string">&quot;Jermyn&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2 获取输入流</span></span><br><span class="line">    <span class="type">Path</span> <span class="variable">f</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/user/Jermyn/input/hadoop-2.7.2.tar.gz&quot;</span>);</span><br><span class="line">    <span class="type">FSDataInputStream</span> <span class="variable">fis</span> <span class="operator">=</span> fs.open(f);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3 设置指定的读取节点</span></span><br><span class="line">    fis.seek(<span class="number">1024</span> * <span class="number">1024</span> * <span class="number">128</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4 获取输出流</span></span><br><span class="line">    <span class="type">FileOutputStream</span> <span class="variable">fos</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileOutputStream</span>(</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\hadoop-2.7.2.tar.gz.block2&quot;</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5 流的对拷</span></span><br><span class="line">    IOUtils.copyBytes(fis, fos, configuration);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 6 关闭资源</span></span><br><span class="line">    IOUtils.closeStream(fis);</span><br><span class="line">    IOUtils.closeStream(fos);</span><br><span class="line">    fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528172455.png" alt=""></li><li><strong>合并文件</strong><br>在Window命令窗口中进入到目录E:\，然后执行如下命令，对数据进行合并 type hadoop-2.7.2.tar.gz.part2 &gt;&gt; hadoop-2.7.2.tar.gz.part1<br>合并完成后，将hadoop-2.7.2.tar.gz.part1重新命名为hadoop-2.7.2.tar.gz。解压发现该tar包非常完整。</li></ul><h1 id="第七章-HDFS的数据流"><a href="#第七章-HDFS的数据流" class="headerlink" title="第七章 HDFS的数据流"></a>第七章 HDFS的数据流</h1><h2 id="HDFS写数据流程"><a href="#HDFS写数据流程" class="headerlink" title="HDFS写数据流程"></a>HDFS写数据流程</h2><h3 id="剖析文件写入"><a href="#剖析文件写入" class="headerlink" title="剖析文件写入"></a>剖析文件写入</h3><span class="p center logo large green">HDFS写数据流程</span> <span class="p center small green">点击下图可放大查看</span><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528175922.png" alt=""><br></p><div class="timeline green"><div class="timeline-item headline"><div class="timeline-item-title"><div class="item-circle"><p>HDFS写数据流程</p></div></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第一步</p></div></div><div class="timeline-item-content"><p>客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第二步</p></div></div><div class="timeline-item-content"><p>NameNode返回是否可以上传。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第三步</p></div></div><div class="timeline-item-content"><p>客户端请求第一个 Block上传到哪几个DataNode服务器上。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第四步</p></div></div><div class="timeline-item-content"><p>NameNode返回3个DataNode节点，分别为dn1、dn2、dn3（如何返回合适的datanode详细可见7.1.2）。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第五步</p></div></div><div class="timeline-item-content"><p>客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第六步</p></div></div><div class="timeline-item-content"><p>dn1、dn2、dn3逐级应答客户端。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第七步</p></div></div><div class="timeline-item-content"><p>客户端开始往dn1上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet为单位，dn1收到一个Packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第八步</p></div></div><div class="timeline-item-content"><p>当一个Block传输完成之后，客户端再次请求NameNode上传第二个Block的服务器。（重复执行3-7步）。</p></div></div></div><p></p><h3 id="网络拓扑-节点距离计算"><a href="#网络拓扑-节点距离计算" class="headerlink" title="网络拓扑-节点距离计算"></a>网络拓扑-节点距离计算</h3><p>在HDFS写数据的过程中，NameNode会选择距离待上传数据最近距离的DataNode接收数据。<br>节点距离：<span class="p red">两个节点到达最近的共同祖先的距离总和。</span><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528184907.png" alt=""></p><h3 id="机架感知（副本存储节点选择）"><a href="#机架感知（副本存储节点选择）" class="headerlink" title="机架感知（副本存储节点选择）"></a>机架感知（副本存储节点选择）</h3><ol><li><strong>官方ip地址</strong><br><strong><em>点击图片跳转链接</em></strong><br><a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html#Data_Replication"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528185714.png" alt=""></a></li><li><strong>Hadoop2.7.2副本节点选择</strong><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528185910.png" alt=""></li></ol><h2 id="HDFS读数据流程"><a href="#HDFS读数据流程" class="headerlink" title="HDFS读数据流程"></a>HDFS读数据流程</h2><span class="p center logo large green">HDFS的读数据流程</span> <span class="p center logo small green">点击下图可放大查看</span><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528190740.png" alt=""><br></p><div class="timeline green"><div class="timeline-item headline"><div class="timeline-item-title"><div class="item-circle"><p>HDFS读数据流程</p></div></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第一步</p></div></div><div class="timeline-item-content"><p>客户端通过Distributed FileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第二步</p></div></div><div class="timeline-item-content"><p>挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第三步</p></div></div><div class="timeline-item-content"><p>DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以Packet为单位来做校验）。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第四步</p></div></div><div class="timeline-item-content"><p>客户端以Packet为单位接收，先在本地缓存，然后写入目标文件。</p></div></div></div><p></p><h1 id="第八章-NameNode和SecondaryNameNode"><a href="#第八章-NameNode和SecondaryNameNode" class="headerlink" title="第八章 NameNode和SecondaryNameNode"></a>第八章 NameNode和SecondaryNameNode</h1><h2 id="NN和2NN工作机制"><a href="#NN和2NN工作机制" class="headerlink" title="NN和2NN工作机制"></a>NN和2NN工作机制</h2><span class="p red">思考：NameNode中的元数据是存储在哪里的？</span><p>首先，我们做个假设，如果存储在NameNode节点的磁盘中，因为经常需要进行随机访问，还有响应客户请求，必然是效率过低。因此，元数据需要存放在内存中。但如果只存在内存中，一旦断电，元数据丢失，整个集群就无法工作了。因此产生在磁盘中备份元数据的FsImage。这样又会带来新的问题，当在内存中的元数据更新时，如果同时更新FsImage，就会导致效率过低，但如果不更新，就会发生一致性问题，一旦NameNode节点断电，就会产生数据丢失。因此，引入Edits文件(只进行追加操作，效率很高)。每当元数据有更新或者添加元数据时，修改内存中的元数据并追加到Edits中。这样，一旦NameNode节点断电，可以通过FsImage和Edits的合并，合成元数据。但是，如果长时间添加数据到Edits中，会导致该文件数据过大，效率降低，而且一旦断电，恢复元数据需要的时间过长。因此，需要定期进行FsImage和Edits的合并，如果这个操作由NameNode节点完成，又会效率过低。因此，引入一个新的节点SecondaryNamenode，专门用于FsImage和Edits的合并。<br><span class="p center logo large green">NN和2NN工作机制</span><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528193202.png" alt=""><br></p><div class="timeline green"><div class="timeline-item headline"><div class="timeline-item-title"><div class="item-circle"><p>NN和2NN工作机制</p></div></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>NN第1步</p></div></div><div class="timeline-item-content"><p>第一次启动NameNode格式化后，创建Fsimage和Edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>NN第2步</p></div></div><div class="timeline-item-content"><p>客户端对元数据进行增删改的请求。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>NN第3步</p></div></div><div class="timeline-item-content"><p>NameNode记录操作日志，更新滚动日志（即：nd向将操作写到edits在进行相应操作）。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>NN第4步</p></div></div><div class="timeline-item-content"><p>NameNode在内存中对数据进行增删改。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>2NN第1步</p></div></div><div class="timeline-item-content"><p>Secondary NameNode询问NameNode是否需要CheckPoint。直接带回NameNode是否检查结果。<br>CheckPoint：将edits和fsimage进行合并成为最新的元数据，序列化到fsimage中</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>2NN第2步</p></div></div><div class="timeline-item-content"><p>Secondary NameNode请求执行CheckPoint。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>2NN第3步</p></div></div><div class="timeline-item-content"><p>NameNode滚动正在写的Edits日志。正在写入的edits叫edits_inprogress_001,滚动生成edits_001，同时生成edits_inprogress_002（空的内容），此后在进行的操作写入到edits_inprogress_002中，</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>2NN第4步</p></div></div><div class="timeline-item-content"><p>将滚动前的编辑日志（edits_001）和镜像文件（fsimage）拷贝到Secondary NameNode</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>2NN第5步</p></div></div><div class="timeline-item-content"><p>Secondary NameNode加载编辑日志和镜像文件到内存，并合并。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>2NN第6步</p></div></div><div class="timeline-item-content"><p>生成新的镜像文件fsimage.chkpoint。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>2NN第7步</p></div></div><div class="timeline-item-content"><p>拷贝fsimage.chkpoint到NameNode。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>2NN第8步</p></div></div><div class="timeline-item-content"><p>NameNode将fsimage.chkpoint重新命名成fsimage。</p></div></div></div><p></p><h2 id="NN和2NN工作机制详解："><a href="#NN和2NN工作机制详解：" class="headerlink" title="NN和2NN工作机制详解："></a>NN和2NN工作机制详解：</h2><p>Fsimage：NameNode内存中元数据序列化后形成的文件。<br>Edits：记录客户端更新元数据信息的每一步操作（可通过Edits运算出元数据）。<br>NameNode启动时，先滚动Edits并生成一个空的edits.inprogress，然后加载Edits和Fsimage到内存中，此时NameNode内存就持有最新的元数据信息。Client开始对NameNode发送元数据的增删改的请求，这些请求的操作首先会被记录到edits.inprogress中（查询元数据的操作不会被记录在Edits中，因为查询操作不会更改元数据信息），如果此时NameNode挂掉，重启后会从Edits中读取元数据的信息。然后，NameNode会在内存中执行元数据的增删改的操作。<br>由于Edits中记录的操作会越来越多，Edits文件会越来越大，导致NameNode在启动加载Edits时会很慢，所以需要对Edits和Fsimage进行合并（所谓合并，就是将Edits和Fsimage加载到内存中，照着Edits中的操作一步步执行，最终形成新的Fsimage）。SecondaryNameNode的作用就是帮助NameNode进行Edits和Fsimage的合并工作。<br>SecondaryNameNode首先会询问NameNode是否需要CheckPoint（触发CheckPoint需要满足两个条件中的任意一个，定时时间到和Edits中数据写满了）。直接带回NameNode是否检查结果。SecondaryNameNode执行CheckPoint操作，首先会让NameNode滚动Edits并生成一个空的edits.inprogress，滚动Edits的目的是给Edits打个标记，以后所有新的操作都写入edits.inprogress，其他未合并的Edits和Fsimage会拷贝到SecondaryNameNode的本地，然后将拷贝的Edits和Fsimage加载到内存中进行合并，生成fsimage.chkpoint，然后将fsimage.chkpoint拷贝给NameNode，重命名为Fsimage后替换掉原来的Fsimage。NameNode在启动时就只需要加载之前未合并的Edits和Fsimage即可，因为合并过的Edits中的元数据信息已经被记录在Fsimage中。</p><h2 id="Fsimage和Edits解析"><a href="#Fsimage和Edits解析" class="headerlink" title="Fsimage和Edits解析"></a>Fsimage和Edits解析</h2><span class="p center logo large green">Fsimage和Edits概念</span><p>NameNode被格式化之后，将在/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current目录中产生如下文件<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528202634.png" alt=""></p><ol><li>Fsimage文件：HDFS文件系统元数据的一个永久性的检查点，其中包含HDFS文件系统的所有目录和文件inode的序列化信息。</li><li>Edits文件：存放HDFS文件系统的所有更新操作的路径，文件系统客户端执行的所有写操作首先会被记录到Edits文件中。</li><li>seen<em>txid文件保存的是一个数字，就是最后一个edits</em>的数字(即最新的操作的edits的文件id)</li><li>每次NameNode启动的时候都会将Fsimage文件读入内存，加载Edits里面的更新操作，保证内存中的元数据信息是最新的、同步的，可以看成NameNode启动的时候就将Fsimage和Edits文件进行了合并。</li></ol><h3 id="oiv查看Fsimage文件"><a href="#oiv查看Fsimage文件" class="headerlink" title="oiv查看Fsimage文件"></a>oiv查看Fsimage文件</h3><ol><li><strong>查看oiv和oev命令</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hdfs | grep <span class="literal">-E</span>  <span class="string">&#x27;oiv|oev&#x27;</span></span><br><span class="line">  oiv                  apply the offline fsimage viewer to an fsimage</span><br><span class="line">  oiv_legacy           apply the offline fsimage viewer to an legacy fsimage</span><br><span class="line">  oev                  apply the offline edits viewer to an edits file</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li><strong>基本语法</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs oiv <span class="literal">-p</span> 文件类型 <span class="literal">-i</span>镜像文件 <span class="literal">-o</span> 转换后文件输出路径</span><br></pre></td></tr></table></figure></li><li><strong>案例实操</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">current</span>]<span class="variable">$</span> <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/<span class="keyword">data</span>/tmp/dfs/name/current</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">current</span>]<span class="variable">$</span> hdfs oiv <span class="literal">-p</span> XML <span class="literal">-i</span> fsimage_0000000000000000025 <span class="literal">-o</span> /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/fsimage.xml</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">current</span>]<span class="variable">$</span> <span class="built_in">cat</span> /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/fsimage.xml</span><br></pre></td></tr></table></figure></li></ol><ul><li><strong>思考：可以看出，Fsimage中没有记录块所对应DataNode，为什么？</strong><br>在集群启动后，要求DataNode上报数据块信息，并间隔一段时间后再次上报。</li></ul><h3 id="oev查看Edits文件"><a href="#oev查看Edits文件" class="headerlink" title="oev查看Edits文件"></a>oev查看Edits文件</h3><ol><li><strong>基本语法</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs oev <span class="literal">-p</span> 文件类型 <span class="literal">-i</span>编辑日志 <span class="literal">-o</span> 转换后文件输出路径</span><br></pre></td></tr></table></figure></li><li><strong>实例实操</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">current</span>]<span class="variable">$</span> hdfs oev <span class="literal">-p</span> XML <span class="literal">-i</span> edits_0000000000000000012<span class="literal">-0000000000000000013</span> <span class="literal">-o</span> /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/edits.xml</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">current</span>]<span class="variable">$</span> <span class="built_in">cat</span> /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/edits.xml</span><br></pre></td></tr></table></figure></li></ol><h2 id="CheckPoint时间设置"><a href="#CheckPoint时间设置" class="headerlink" title="CheckPoint时间设置"></a>CheckPoint时间设置</h2><p><a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230528222032.png" alt=""></a></p><ol><li><strong>通常情况下，SecondaryNameNode每隔一小时执行一次。</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim hdfs<span class="literal">-default</span>.xml</span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>3600<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><strong>一分钟检查一次操作次数，3当操作次数达到1百万时，SecondaryNameNode执行一次。</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.txns<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>1000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>操作动作次数<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.check.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>60<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span> 1分钟检查一次操作次数<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">&lt;/property &gt;</span><br></pre></td></tr></table></figure><h2 id="NameNode故障处理"><a href="#NameNode故障处理" class="headerlink" title="NameNode故障处理"></a>NameNode故障处理</h2>NameNode故障后，可以采用如下两种方法恢复数据。</li></ol><ul><li><strong>方法一：将SecondaryNameNode中数据拷贝到NameNode存储数据的目录(我们发现2NN和NN相比NN多个seentxid文件，其他都一样，所以此方法是将2NN的所有文件拷贝到NN所在的相应目录下)</strong></li></ul><ol><li>kill -9 NameNode进程</li><li>删除NameNode存储的数据（/opt/module/hadoop-2.7.2/data/tmp/dfs/name）<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> <span class="literal">-rf</span> /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/<span class="keyword">data</span>/tmp/dfs/name/*</span><br></pre></td></tr></table></figure></li><li>拷贝SecondaryNameNode中数据到原NameNode存储数据目录<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp <span class="literal">-r</span> Jermyn@hadoop104:/opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/<span class="keyword">data</span>/tmp/dfs/namesecondary/* ./name/</span><br></pre></td></tr></table></figure></li><li>重新启动NameNode<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop<span class="literal">-daemon</span>.sh <span class="built_in">start</span> namenode</span><br></pre></td></tr></table></figure></li></ol><ul><li><strong>方法二：使用-importCheckpoint选项启动NameNode守护进程，从而将SecondaryNameNode中数据拷贝到NameNode目录中。（CheckPoint触发条件是①定时时间到②edits中数据满，显然数据满不了了，所以我们修改定时任务，时间缩短，让他尽快触发进行Checkpoint，把内存的数据导出）</strong></li></ul><ol><li>修改hdfs-site.xml中的<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>120<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li>kill -9 NameNode进程</li><li>删除NameNode存储的数据（/opt/module/hadoop-2.7.2/data/tmp/dfs/name）<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> <span class="literal">-rf</span> /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/<span class="keyword">data</span>/tmp/dfs/name/*</span><br></pre></td></tr></table></figure></li><li>如果SecondaryNameNode不和NameNode在一个主机节点上，需要将SecondaryNameNode存储数据的目录拷贝到NameNode存储数据的平级目录，并删除in_use.lock文件<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">dfs</span>]<span class="variable">$</span> scp <span class="literal">-r</span> Jermyn@hadoop104:/opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/<span class="keyword">data</span>/tmp/dfs/namesecondary ./</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">namesecondary</span>]<span class="variable">$</span> <span class="built_in">rm</span> <span class="literal">-rf</span> in_use.lock</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">dfs</span>]<span class="variable">$</span> <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/<span class="keyword">data</span>/tmp/dfs</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">dfs</span>]<span class="variable">$</span> <span class="built_in">ls</span></span><br><span class="line"><span class="keyword">data</span>  name  namesecondary</span><br></pre></td></tr></table></figure></li><li>导入检查点数据（等待一会ctrl+c结束掉）<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs namenode <span class="literal">-importCheckpoint</span></span><br></pre></td></tr></table></figure></li><li>启动NameNode<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop<span class="literal">-daemon</span>.sh <span class="built_in">start</span> namenode</span><br></pre></td></tr></table></figure></li></ol><h2 id="集群安全模式"><a href="#集群安全模式" class="headerlink" title="集群安全模式"></a>集群安全模式</h2><ul><li><strong>概述</strong></li></ul><ol><li><strong>NN启动</strong><br>NameNode启动时，首先将镜像文件（Fsimage）载入内存，并执行编辑日志（Edits）中的各项操作。一旦在内存中成功建立文件系统元数据的映像，则创建一个新的Fsimage文件和一个空的编辑日志。此时，NameNode开始监听DataNode请求。这个过程期间，NameNode一直运行在安全模式，即NameNode的文件系统对于客户端来说是只读的。（相当于开始是是把数据加载到内存中，没有加载完成的时候就进行处理数据，肯定不可以）</li><li><strong>DN启动</strong><br>系统中的数据块的位置并不是由NameNode维护的，而是以块列表的形式存储在DataNode中。在系统的正常操作期间，NameNode会在内存中保留所有块位置的映射信息。在安全模式下，各个DataNode会向NameNode发送最新的块列表信息，NameNode了解到足够多的块位置信息之后，即可高效运行文件系统。</li><li><strong>安全模式推出判断</strong><br>如果满足“最小副本条件”，NameNode会在30秒钟之后就退出安全模式。所谓的最小副本条件指的是在整个文件系统中99.9%的块满足最小副本级别（默认值：dfs.replication.min=1）。在启动一个刚刚格式化的HDFS集群时，因为系统中还没有任何块，所以NameNode不会进入安全模式。</li></ol><ul><li><strong>基本语法</strong><span class="p red">集群处于安全模式，不能执行重要操作（写操作）。集群启动完成后，自动退出安全模式。</span><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfsadmin <span class="literal">-safemode</span> get		（功能描述：查看安全模式状态）</span><br><span class="line">bin/hdfs dfsadmin <span class="literal">-safemode</span> enter  	（功能描述：进入安全模式状态）</span><br><span class="line">bin/hdfs dfsadmin <span class="literal">-safemode</span> leave	（功能描述：离开安全模式状态）</span><br><span class="line">bin/hdfs dfsadmin <span class="literal">-safemode</span> wait	（功能描述：等待安全模式状态）</span><br></pre></td></tr></table></figure></li></ul><h2 id="NameNode多目录配置"><a href="#NameNode多目录配置" class="headerlink" title="NameNode多目录配置"></a>NameNode多目录配置</h2><ol><li>NameNode的本地目录可以配置成多个，且每个目录存放内容相同，增加了可靠性</li><li>具体配置如下</li></ol><ul><li><strong>在hdfs-site.xml文件中增加如下内容</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;file:///<span class="variable">$</span>&#123;hadoop.tmp.dir&#125;/dfs/name1,file:///<span class="variable">$</span>&#123;hadoop.tmp.dir&#125;/dfs/name2&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li><li><strong>停止集群，删除data和logs中所有数据。</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> <span class="built_in">rm</span> <span class="literal">-rf</span> <span class="keyword">data</span>/ logs/</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop103</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> <span class="built_in">rm</span> <span class="literal">-rf</span> <span class="keyword">data</span>/ logs/</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop104</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> <span class="built_in">rm</span> <span class="literal">-rf</span> <span class="keyword">data</span>/ logs/</span><br></pre></td></tr></table></figure></li><li><strong>格式化集群并启动。</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> bin/hdfs namenode –format</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> sbin/<span class="built_in">start-dfs</span>.sh</span><br></pre></td></tr></table></figure></li><li><strong>查看结果</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">dfs</span>]<span class="variable">$</span> ll</span><br><span class="line">总用量 <span class="number">12</span></span><br><span class="line">drwx<span class="literal">------</span>. <span class="number">3</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">12</span>月 <span class="number">11</span> <span class="number">08</span>:<span class="number">03</span> <span class="keyword">data</span></span><br><span class="line">drwxrwxr<span class="literal">-x</span>. <span class="number">3</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">12</span>月 <span class="number">11</span> <span class="number">08</span>:<span class="number">03</span> name1</span><br><span class="line">drwxrwxr<span class="literal">-x</span>. <span class="number">3</span> Jermyn Jermyn <span class="number">4096</span> <span class="number">12</span>月 <span class="number">11</span> <span class="number">08</span>:<span class="number">03</span> name2</span><br></pre></td></tr></table></figure></li></ul><h1 id="第九章-DataNode"><a href="#第九章-DataNode" class="headerlink" title="第九章 DataNode"></a>第九章 DataNode</h1><h2 id="DataNode工作机制"><a href="#DataNode工作机制" class="headerlink" title="DataNode工作机制"></a>DataNode工作机制</h2><span class="p center logo large green">DataNode工作机制</span><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230529155656.png" alt=""></p><ol><li>一个数据块在DataNode上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳。(即：数据和指示数据的信息)</li><li>DataNode启动后向NameNode注册，通过后，周期性（1小时）的向NameNode上报所有的块信息（即：向NN报告我这个DN还活着，同时报告我存的数据信息）。</li><li>心跳是每3秒一次，心跳返回结果带有NameNode给该DataNode的命令如复制块数据到另一台机器，或删除某个数据块。如果超过10分钟没有收到某个DataNode的心跳，则认为该节点不可用。（即：NN和DN每3秒通信一次）</li><li>集群运行中可以安全加入和退出一些机器。</li></ol><h2 id="数据完整性"><a href="#数据完整性" class="headerlink" title="数据完整性"></a>数据完整性</h2><p>思考：如果电脑磁盘里面存储的数据是控制高铁信号灯的红灯信号（1）和绿灯信号（0），但是存储该数据的磁盘坏了，一直显示是绿灯，是否很危险？同理DataNode节点上的数据损坏了，却没有发现，是否也很危险，那么如何解决呢？<br>如下是DataNode节点保证数据完整性的方法</p><ol><li>当DataNode读取Block的时候，它会计算CheckSum。</li><li>如果计算后的CheckSum，与Block创建时值不一样，说明Block已经损坏。</li><li>Client读取其他DataNode上的Block。</li><li>DataNode在其文件创建后周期验证CheckSum<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230529160950.png" alt=""></li></ol><h2 id="掉线时限参数设置"><a href="#掉线时限参数设置" class="headerlink" title="掉线时限参数设置"></a>掉线时限参数设置</h2><span class="p center logo large green">DataNode掉线时限参数设置</span><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230529203738.png" alt=""><br><span class="p red">需要注意的是hdfs-site.xml 配置文件中的heartbeat.recheck.interval的单位为毫秒，dfs.heartbeat.interval的单位为秒。</span><br></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.heartbeat.recheck-interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>300000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">    This time decides the interval to check for expired datanodes.</span><br><span class="line">    With this value and dfs.heartbeat.interval, the interval of</span><br><span class="line">    deciding the datanode is stale or not is also calculated.</span><br><span class="line">    The unit of this configuration is millisecond.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.heartbeat.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Determines datanode heartbeat interval in seconds.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p></p><h2 id="服役新数据节点-添加新工作节点"><a href="#服役新数据节点-添加新工作节点" class="headerlink" title="服役新数据节点(添加新工作节点)"></a>服役新数据节点(添加新工作节点)</h2><ul><li><strong>环境准备</strong><ul><li>在hadoop104主机上再克隆一台hadoop105主机</li><li>修改IP地址和主机名称</li><li>删除原来HDFS文件系统留存的文件（/opt/module/hadoop-2.7.2/data和log）<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop105</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> <span class="built_in">rm</span> <span class="literal">-rf</span> ./<span class="keyword">data</span></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop105</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> <span class="built_in">rm</span> <span class="literal">-rf</span> ./log</span><br></pre></td></tr></table></figure></li><li>source一下配置文件<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop105</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> source /etc/profile</span><br></pre></td></tr></table></figure></li></ul></li><li><strong>服役新节点具体步骤</strong><ul><li>直接启动DataNode，即可关联到集群<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop105</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> sbin/hadoop<span class="literal">-daemon</span>.sh <span class="built_in">start</span> datanode</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop105</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> sbin/yarn<span class="literal">-daemon</span>.sh <span class="built_in">start</span> nodemanager</span><br></pre></td></tr></table></figure></li><li>在hadoop105上上传文件<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop105</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hadoop fs <span class="literal">-put</span> /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/LICENSE.txt /</span><br></pre></td></tr></table></figure></li><li>如果数据不均衡，可以用命令实现集群的再平衡<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> [<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">sbin</span>]<span class="variable">$</span> ./<span class="built_in">start-balancer</span>.sh</span><br><span class="line">starting balancer, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-balancer-hadoop102</span>.out</span><br><span class="line">Time Stamp               Iteration<span class="comment">#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved</span></span><br></pre></td></tr></table></figure></li></ul></li></ul><h2 id="退役旧数据节点"><a href="#退役旧数据节点" class="headerlink" title="退役旧数据节点"></a>退役旧数据节点</h2><h3 id="添加白名单"><a href="#添加白名单" class="headerlink" title="添加白名单"></a>添加白名单</h3><span class="p red">添加到白名单的主机节点，都允许访问NameNode，不在白名单的主机节点，都会被退出。</span><p>配置白名单的具体步骤如下：</p><ul><li><strong>在NameNode的/opt/module/hadoop-2.7.2/etc/hadoop目录下创建dfs.hosts文件</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>]<span class="variable">$</span> <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/etc/hadoop</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>]<span class="variable">$</span> touch dfs.hosts</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>]<span class="variable">$</span> vi dfs.hosts</span><br></pre></td></tr></table></figure></li><li><strong>添加如下主机名称（不添加hadoop105）</strong><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br></pre></td></tr></table></figure></li><li><strong>在NameNode的hdfs-site.xml配置文件中增加dfs.hosts属性</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><strong>配置文件分发</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>]<span class="variable">$</span> xsync hdfs<span class="literal">-site</span>.xml</span><br></pre></td></tr></table></figure></li><li><strong>刷新NameNode</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hdfs dfsadmin <span class="literal">-refreshNodes</span></span><br></pre></td></tr></table></figure></li><li><strong>更新ResourceManager节点</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> yarn rmadmin <span class="literal">-refreshNodes</span></span><br><span class="line"><span class="number">17</span>/<span class="number">06</span>/<span class="number">24</span> <span class="number">14</span>:<span class="number">17</span>:<span class="number">11</span> INFO client.RMProxy: Connecting to ResourceManager at hadoop103/<span class="number">192.168</span>.<span class="number">10.103</span>:<span class="number">8033</span></span><br></pre></td></tr></table></figure></li><li><strong>如果数据不均衡，可以用命令实现集群的再平衡</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">sbin</span>]<span class="variable">$</span> ./<span class="built_in">start-balancer</span>.sh</span><br><span class="line">starting balancer, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-balancer-hadoop102</span>.out</span><br><span class="line">Time Stamp               Iteration<span class="comment">#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="黑名单退役"><a href="#黑名单退役" class="headerlink" title="黑名单退役"></a>黑名单退役</h3><span class="p red">在黑名单上面的主机都会被强制退出。</span><ul><li><strong>在NameNode的/opt/module/hadoop-2.7.2/etc/hadoop目录下创建dfs.hosts.exclude文件</strong><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[Jermyn@hadoop102 hadoop]$ pwd</span><br><span class="line">/opt/module/hadoop-2.7.2/etc/hadoop</span><br><span class="line">[Jermyn@hadoop102 hadoop]$ touch dfs.hosts.exclude</span><br><span class="line">[Jermyn@hadoop102 hadoop]$ vi dfs.hosts.exclude</span><br></pre></td></tr></table></figure></li><li><strong>添加如下主机名称（要退役的节点）</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop105</span><br></pre></td></tr></table></figure></li><li><strong>在NameNode的hdfs-site.xml配置文件中增加dfs.hosts.exclude属性</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.hosts.exclude<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/etc/hadoop/dfs.hosts.exclude<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><strong>刷新NameNode、刷新ResourceManager</strong><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[Jermyn@hadoop102 hadoop-2.7.2]$ hdfs dfsadmin -refreshNodes</span><br><span class="line">Refresh nodes successful</span><br><span class="line"></span><br><span class="line">[Jermyn@hadoop102 hadoop-2.7.2]$ yarn rmadmin -refreshNodes</span><br><span class="line">17/06/24 14:55:56 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.1.103:8033</span><br></pre></td></tr></table></figure></li><li><p><strong>检查Web浏览器，退役节点的状态为decommission in progress（退役中），说明数据节点正在复制块到其他节点</strong></p></li><li><p><strong>等待退役节点状态为decommissioned（所有块已经复制完成），停止该节点及节点资源管理器。注意：如果副本数是3，服役的节点小于等于3，是不能退役成功的，需要修改副本数后才能退役</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># stopping datanode</span></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop105</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> sbin/hadoop<span class="literal">-daemon</span>.sh stop datanode</span><br><span class="line"></span><br><span class="line"><span class="comment"># stopping nodemanager</span></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop105</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> sbin/yarn<span class="literal">-daemon</span>.sh stop nodemanager</span><br></pre></td></tr></table></figure></li><li><strong>如果数据不均衡，可以用命令实现集群的再平衡</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> sbin/<span class="built_in">start-balancer</span>.sh </span><br><span class="line">starting balancer, logging to /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/logs/hadoop<span class="literal">-Jermyn-balancer-hadoop102</span>.out</span><br><span class="line">Time Stamp               Iteration<span class="comment">#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved</span></span><br></pre></td></tr></table></figure><span class="p red">注意：不允许白名单和黑名单中同时出现同一个主机名称。</span></li></ul><h2 id="Datanode多目录配置"><a href="#Datanode多目录配置" class="headerlink" title="Datanode多目录配置"></a>Datanode多目录配置</h2><ol><li>DataNode也可以配置成多个目录，每个目录存储的数据不一样。即：数据不是副本</li><li>添加配置 hdfs-site.xml<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///$&#123;hadoop.tmp.dir&#125;/dfs/data1,file:///$&#123;hadoop.tmp.dir&#125;/dfs/data2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h1 id="第十章-HDFS-2-X新特性"><a href="#第十章-HDFS-2-X新特性" class="headerlink" title="第十章 HDFS 2.X新特性"></a>第十章 HDFS 2.X新特性</h1><h2 id="集群间数据拷贝"><a href="#集群间数据拷贝" class="headerlink" title="集群间数据拷贝"></a>集群间数据拷贝</h2></li><li>scp实现两个远程主机之间的文件复制<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 推 push</span></span><br><span class="line">scp <span class="literal">-r</span> hello.txt root@hadoop103:/user/Jermyn/hello.txt		</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拉 pull</span></span><br><span class="line">scp <span class="literal">-r</span> root@hadoop103:/user/Jermyn/hello.txt  hello.txt	</span><br><span class="line"></span><br><span class="line"><span class="comment"># 是通过本地主机中转实现两个远程主机的文件复制；如果在两个远程主机之间ssh没有配置的情况下可以使用该方式。</span></span><br><span class="line">scp <span class="literal">-r</span> root@hadoop103:/user/Jermyn/hello.txt root@hadoop104:/user/Jermyn   </span><br></pre></td></tr></table></figure></li><li>采用distcp命令实现两个Hadoop集群之间的递归数据复制<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span>  bin/hadoop distcp</span><br><span class="line">hdfs://haoop102:<span class="number">9000</span>/user/Jermyn/hello.txt hdfs://hadoop103:<span class="number">9000</span>/user/Jermyn/hello.txt</span><br></pre></td></tr></table></figure></li></ol><h2 id="小文件存档"><a href="#小文件存档" class="headerlink" title="小文件存档"></a>小文件存档</h2><span class="p center logo large green">小文件存档</span><ol><li>HDFS存储小文件弊端<br>每个文件均按块存储，每个块的元数据存储在NameNode的内存中，因此HDFS存储小文件会非常低效。因为大量的小文件会耗尽NameNode中的大部分内存。但注意，存储小文件所需要的磁盘容量和数据块的大小无关。例如，一个1MB的文件设置为128MB的块存储，实际使用的是1MB的磁盘空间，而不是128MB。</li><li>解决存储小文件办法之一<br>HDFS存档文件或HAR文件，是一个更高效的文件存档工具，它将文件存入HDFS块，在减少NameNode内存使用的同时，允许对文件进行透明的访问。具体说来，HDFS存档文件对内还是一个一个独立文件，对NameNode而言却是一个整体，减少了NameNode的内存。<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230529222636.png" alt=""></li><li>案例实操</li></ol><ul><li><strong>需要启动YARN进程</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">start-yarn</span>.sh</span><br></pre></td></tr></table></figure></li><li><strong>归档文件把/log目录里面的所有文件归档成一个叫input.har的归档文件，并把归档后文件存储到/user/Jermyn/output路径下。</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> bin/hadoop archive <span class="literal">-archiveName</span> input.har <span class="literal">-p</span> /log /user/Jermyn/output</span><br></pre></td></tr></table></figure></li><li><strong>查看归档(hadoop fs -lsr har://)</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hadoop fs <span class="literal">-lsr</span> /user/Jermyn/output/input.har</span><br><span class="line">lsr: DEPRECATED: Please use <span class="string">&#x27;ls -R&#x27;</span> instead.</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">3</span> Jermyn supergroup          <span class="number">0</span> <span class="number">2023</span><span class="literal">-05-29</span> <span class="number">22</span>:<span class="number">37</span> /user/Jermyn/output/input.har/_SUCCESS</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">5</span> Jermyn supergroup        <span class="number">271</span> <span class="number">2023</span><span class="literal">-05-29</span> <span class="number">22</span>:<span class="number">37</span> /user/Jermyn/output/input.har/_index</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">5</span> Jermyn supergroup         <span class="number">22</span> <span class="number">2023</span><span class="literal">-05-29</span> <span class="number">22</span>:<span class="number">37</span> /user/Jermyn/output/input.har/_masterindex</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">3</span> Jermyn supergroup          <span class="number">0</span> <span class="number">2023</span><span class="literal">-05-29</span> <span class="number">22</span>:<span class="number">37</span> /user/Jermyn/output/input.har/part<span class="literal">-0</span></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hadoop fs <span class="literal">-lsr</span> har:///user/Jermyn/output/input.har</span><br><span class="line">lsr: DEPRECATED: Please use <span class="string">&#x27;ls -R&#x27;</span> instead.</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">3</span> Jermyn supergroup          <span class="number">0</span> <span class="number">2023</span><span class="literal">-05-26</span> <span class="number">11</span>:<span class="number">13</span> har:///user/Jermyn/output/input.har/log1.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">3</span> Jermyn supergroup          <span class="number">0</span> <span class="number">2023</span><span class="literal">-05-26</span> <span class="number">11</span>:<span class="number">13</span> har:///user/Jermyn/output/input.har/log2.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">3</span> Jermyn supergroup          <span class="number">0</span> <span class="number">2023</span><span class="literal">-05-26</span> <span class="number">11</span>:<span class="number">13</span> har:///user/Jermyn/output/input.har/log3.txt</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li><li><strong>解归档文件</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hadoop fs <span class="literal">-cp</span> har:///user/Jermyn/output/input.har/* /user/Jermyn/input</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hadoop fs <span class="literal">-ls</span> /user/Jermyn/input</span><br><span class="line">Found <span class="number">6</span> items</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">3</span> Jermyn Jermyn             <span class="number">18</span> <span class="number">2023</span><span class="literal">-05-26</span> <span class="number">10</span>:<span class="number">44</span> /user/Jermyn/input/demo.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">3</span> Jermyn supergroup  <span class="number">197657687</span> <span class="number">2023</span><span class="literal">-05-25</span> <span class="number">15</span>:<span class="number">22</span> /user/Jermyn/input/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>.tar.gz</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">3</span> Jermyn supergroup          <span class="number">0</span> <span class="number">2023</span><span class="literal">-05-29</span> <span class="number">22</span>:<span class="number">43</span> /user/Jermyn/input/log1.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">3</span> Jermyn supergroup          <span class="number">0</span> <span class="number">2023</span><span class="literal">-05-29</span> <span class="number">22</span>:<span class="number">43</span> /user/Jermyn/input/log2.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">3</span> Jermyn supergroup          <span class="number">0</span> <span class="number">2023</span><span class="literal">-05-29</span> <span class="number">22</span>:<span class="number">43</span> /user/Jermyn/input/log3.txt</span><br><span class="line">drwxr<span class="literal">-xr-x</span>   - Jermyn supergroup          <span class="number">0</span> <span class="number">2023</span><span class="literal">-05-25</span> <span class="number">15</span>:<span class="number">19</span> /user/Jermyn/input/wcinput</span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="回收站"><a href="#回收站" class="headerlink" title="回收站"></a>回收站</h2><span class="p red">开启回收站功能，可以将删除的文件在不超时的情况下，恢复原数据，起到防止误删除、备份等作用。</span><ol><li>回收站参数设置及工作机制<ul><li>默认值fs.trash.interval=0，0表示禁用回收站;其他值表示设置文件的存活时间。</li><li>默认值fs.trash.checkpoint.interval=0，检查回收站的间隔时间。如果该值为0，则该值设置和fs.trash.interval的参数值相等。</li><li>要求fs.trash.checkpoint.interval&lt;=fs.trash.interval。</li></ul></li><li>回收站工作机制：<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230529231231.png" alt=""></li><li>启用回收站:修改core-site.xml，配置垃圾回收时间为1分钟。<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim core<span class="literal">-site</span>.xml</span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.checkpoint.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Number of minutes between trash checkpoints.</span><br><span class="line">  Should be smaller or equal to fs.trash.interval. If zero,</span><br><span class="line">  the value is set to the value of fs.trash.interval.</span><br><span class="line">  Every time the checkpointer runs it creates a new checkpoint </span><br><span class="line">  out of current and removes checkpoints created more than </span><br><span class="line">  fs.trash.interval minutes ago.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li>查看回收站,回收站在集群中的路径：/user/Jermyn/.Trash/….</li><li>修改访问垃圾回收站用户名称<br>进入垃圾回收站用户名称，默认是dr.who，修改为Jermyn用户<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim core<span class="literal">-site</span>.xml</span><br></pre></td></tr></table></figure><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">    The user name to filter as, on static web filters</span><br><span class="line">    while rendering content. An example use is the HDFS</span><br><span class="line">    web UI (user to be used for browsing files).</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>Jermyn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li>分发core-site.xml到其他节点<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> xsync /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/etc/hadoop/core<span class="literal">-site</span>.xml</span><br></pre></td></tr></table></figure></li><li>通过程序删除的文件不会经过回收站，需要调用moveToTrash()才进入回收站<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Trash</span> <span class="variable">trash</span> <span class="operator">=</span> New <span class="title function_">Trash</span><span class="params">(conf)</span>;</span><br><span class="line">trash.moveToTrash(path);</span><br></pre></td></tr></table></figure></li><li>恢复回收站数据<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hadoop fs <span class="literal">-mv</span></span><br><span class="line">/user/Jermyn/.Trash/Current/user/Jermyn/input    /user/Jermyn/input</span><br></pre></td></tr></table></figure></li><li>清空回收站<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hadoop fs <span class="literal">-expunge</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="快照管理"><a href="#快照管理" class="headerlink" title="快照管理"></a>快照管理</h2><span class="p center logo large green">快照管理</span><ol><li>快照相当于对目录做一个备份。并不会立即复制所有文件，而是记录文件变化。<ul><li>hdfs dfsadmin -allowSnapshot 路径 （功能描述：开启指定目录的快照功能）</li><li>hdfs dfsadmin -disallowSnapshot 路径 （功能描述：禁用指定目录的快照功能，默认是禁用）</li><li>hdfs dfs -createSnapshot 路径 （功能描述：对目录创建快照）</li><li>hdfs dfs -createSnapshot 路径 名称 （功能描述：指定名称创建快照）</li><li>hdfs dfs -renameSnapshot 路径 旧名称 新名称 （功能描述：重命名快照）</li><li>hdfs lsSnapshottableDir （功能描述：列出当前用户所有可快照目录）</li><li>hdfs snapshotDiff 路径1 路径2 （功能描述：比较两个快照目录的不同之处）</li><li>hdfs dfs -deleteSnapshot<path><snapshotname>（功能描述：删除快照）</snapshotname></path></li></ul></li><li>案例实操<ul><li>开启/禁用指定目录的快照功能<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hdfs dfsadmin <span class="literal">-allowSnapshot</span> /user/Jermyn/input</span><br><span class="line"></span><br><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hdfs dfsadmin <span class="literal">-disallowSnapshot</span> /user/Jermyn/input</span><br></pre></td></tr></table></figure></li><li>对目录创建快照<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hdfs dfs <span class="literal">-createSnapshot</span> /user/Jermyn/input</span><br></pre></td></tr></table></figure></li><li>通过web访问hdfs://hadoop102:50070/user/Jermyn/input/.snapshot/s…..// 快照和源文件使用相同数据<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hdfs dfs <span class="literal">-lsr</span> /user/Jermyn/input/.snapshot/</span><br></pre></td></tr></table></figure></li><li>指定名称创建快照<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hdfs dfs <span class="literal">-createSnapshot</span> /user/Jermyn/input  miao170508</span><br></pre></td></tr></table></figure></li><li>重命名快照<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hdfs dfs <span class="literal">-renameSnapshot</span> /user/Jermyn/input/  miao170508 Jermyn170508</span><br></pre></td></tr></table></figure></li><li>列出当前用户所有可快照目录<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hdfs snapshotDiff /user/Jermyn/input/  .  .snapshot/Jermyn170508	</span><br></pre></td></tr></table></figure></li><li>比较两个快照目录的不同之处<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> hdfs snapshotDiff /user/Jermyn/input/  .  .snapshot/Jermyn170508	</span><br></pre></td></tr></table></figure></li></ul></li></ol><h1 id="第十一章-MapReduce概述"><a href="#第十一章-MapReduce概述" class="headerlink" title="第十一章 MapReduce概述"></a>第十一章 MapReduce概述</h1><h2 id="MapReduce优缺点"><a href="#MapReduce优缺点" class="headerlink" title="MapReduce优缺点"></a>MapReduce优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ol><li><strong>MapReduce 易于编程</strong><br>它简单的实现一些接口，就可以完成一个分布式程序，这个分布式程序可以分布到大量廉价的PC机器上运行。也就是说你写一个分布式程序，跟写一个简单的串行程序是一模一样的。就是因为这个特点使得MapReduce编程变得非常流行。</li><li><strong>良好的扩展性</strong><br>当你的计算资源不能得到满足的时候，你可以通过简单的增加机器来扩展它的计算能力。</li><li><strong>高容错性</strong><br>MapReduce设计的初衷就是使程序能够部署在廉价的PC机器上，这就要求它具有很高的容错性。比如其中一台机器挂了，它可以把上面的计算任务转移到另外一个节点上运行，不至于这个任务运行失败，而且这个过程不需要人工参与，而完全是由Hadoop内部完成的。</li><li>适合PB级以上海量数据的离线处理<br>可以实现上千台服务器集群并发工作，提供数据处理能力。</li></ol><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ol><li><strong>不擅长实时计算</strong><br>MapReduce无法像MySQL一样，在毫秒或者秒级内返回结果。</li><li><strong>不擅长流式计算</strong><br>流式计算的输入数据是动态的，而MapReduce的输入数据集是静态的，不能动态变化。这是因为MapReduce自身的设计特点决定了数据源必须是静态的。</li><li><strong>不擅长DAG（有向图）计算</strong><br>多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下，MapReduce并不是不能做，而是使用后，每个MapReduce作业的输出结果都会写入到磁盘，会造成大量的磁盘IO，导致性能非常的低下。</li></ol><h2 id="MapReduce核心思想"><a href="#MapReduce核心思想" class="headerlink" title="MapReduce核心思想"></a>MapReduce核心思想</h2><span class="p center logo large green">MapReduce核心编程思想</span><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230530133834.png" alt=""></p><ol><li>分布式的运算程序往往需要分成至少2个阶段。</li><li>第一个阶段的MapTask并发实例，完全并行运行，互不相干。</li><li>第二个阶段的ReduceTask并发实例互不相干，但是他们的数据依赖于上一个阶段的所有MapTask并发实例的输出。</li><li>MapReduce编程模型只能包含一个Map阶段和一个Reduce阶段，如果用户的业务逻辑非常复杂，那就只能多个MapReduce程序，串行运行。<span class="p red">总结：分析WordCount数据流走向深入理解MapReduce核心思想。</span></li></ol><h2 id="MapReduce进程"><a href="#MapReduce进程" class="headerlink" title="MapReduce进程"></a>MapReduce进程</h2><p>一个完整的MapReduce程序在分布式运行时有三类实例进程：</p><ul><li>MrAppMaster：负责整个程序的过程调度及状态协调。</li><li>MapTask：负责Map阶段的整个数据处理流程。</li><li>ReduceTask：负责Reduce阶段的整个数据处理流程。</li></ul><h2 id="常用数据序列化类型"><a href="#常用数据序列化类型" class="headerlink" title="常用数据序列化类型"></a>常用数据序列化类型</h2><p><strong><em>常用的数据类型对应的Hadoop数据序列化类型</em></strong><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230530134851.png" alt=""></p><h2 id="MapReduce编程规范"><a href="#MapReduce编程规范" class="headerlink" title="MapReduce编程规范"></a>MapReduce编程规范</h2><p>用户编写的程序分成三个部分：<span class="p red">Mapper、Reducer和Driver。</span></p><ol><li><strong>Mapper阶段</strong><ul><li>用户自定义的Mapper要继承自己的父类</li><li>Mapper的输入数据是KV对的形式（KV的类型可自定义）</li><li>Mapper中的业务逻辑写在map()方法中</li><li>Mapper的输出数据是KV对的形式（KV的类型可自定义）</li><li>map()方法（MapTask进程）对每一个<k ,v>调用一次</k></li></ul></li><li><strong>Reducer阶段</strong><ul><li>用户自定义的Reducer要继承自己的父类</li><li>Reducer的输入数据类型对应Mapper的输出数据类型，也是KV</li><li>Reducer的业务逻辑写在reduce()方法中</li><li>ReduceTask进程对每一组相同k的<k ,v>组调用一次reduce()方法</k></li></ul></li><li><strong>Driver阶段</strong><br>相当于YARN集群的客户端，用于提交我们整个程序到YARN集群，提交的是封装了MapReduce程序相关运行参数的job对象</li></ol><h2 id="WordCount案例实操"><a href="#WordCount案例实操" class="headerlink" title="WordCount案例实操"></a>WordCount案例实操</h2><ol><li>需求:在给定的文本文件中统计输出每一个单词出现的总次数</li><li>需求分析<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230530140320.png" alt=""></li><li>环境准备</li></ol><ul><li><strong>创建配置maven工程</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><strong>在项目的src/main/resources目录下，新建一个文件，命名为“log4j.properties”，在文件中填入。</strong><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">log4j.rootLogger</span>=<span class="string">INFO, stdout</span></span><br><span class="line"><span class="attr">log4j.appender.stdout</span>=<span class="string">org.apache.log4j.ConsoleAppender</span></span><br><span class="line"><span class="attr">log4j.appender.stdout.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="attr">log4j.appender.stdout.layout.ConversionPattern</span>=<span class="string">%d %p [%c] - %m%n</span></span><br><span class="line"><span class="attr">log4j.appender.logfile</span>=<span class="string">org.apache.log4j.FileAppender</span></span><br><span class="line"><span class="attr">log4j.appender.logfile.File</span>=<span class="string">target/spring.log</span></span><br><span class="line"><span class="attr">log4j.appender.logfile.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="attr">log4j.appender.logfile.layout.ConversionPattern</span>=<span class="string">%d %p [%c] - %m%n</span></span><br></pre></td></tr></table></figure></li><li><strong>编写程序</strong></li></ul><div class="tabs" id="分栏"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#分栏-1">编写Mapper类</button></li><li class="tab"><button type="button" data-href="#分栏-2">编写Reducer类</button></li><li class="tab"><button type="button" data-href="#分栏-3">编写Driver驱动类</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="分栏-1"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.wordcount;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * map 阶段</span></span><br><span class="line"><span class="comment"> * Mapper&lt;KEYIN, VALUEIN, KEYOUT, VALUEOUT&gt;</span></span><br><span class="line"><span class="comment"> * KEYIN 输入数据的key</span></span><br><span class="line"><span class="comment"> * VALUEIN 输入数据的value Jermyn Jermyn</span></span><br><span class="line"><span class="comment"> * KEYOUT 输出数据的key的类型 Jermyn,1</span></span><br><span class="line"><span class="comment"> * VALUEOUT 输出数据的value类型</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, IntWritable&gt; &#123;</span><br><span class="line">    <span class="type">Text</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">    <span class="type">IntWritable</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1.获取一行（line=&quot;Jermyn Jermyn&quot;）</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2.切割（以空格）</span></span><br><span class="line">        String[] words = line.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3.循环写出</span></span><br><span class="line">        <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// Jermyn</span></span><br><span class="line">            k.set(word);</span><br><span class="line"></span><br><span class="line">            context.write(k, v);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="分栏-2"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.wordcount;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * reduce阶段</span></span><br><span class="line"><span class="comment"> * Reducer&lt;KEYIN,VALUEIN,KEYOUT,VALUEOUT&gt;</span></span><br><span class="line"><span class="comment"> * KEYIN,VALUEIN map阶段输出的key和value</span></span><br><span class="line"><span class="comment"> * KEYOUT,VALUEOUT reduce 阶段输出的目的格式</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="type">IntWritable</span> <span class="variable">value</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Reducer&lt;Text, IntWritable, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="comment">// 1.累加求和</span></span><br><span class="line">        <span class="keyword">for</span> (IntWritable value : values) &#123;</span><br><span class="line">            sum += value.get();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        value.set(sum);</span><br><span class="line">        <span class="comment">// 2.写出</span></span><br><span class="line">        context.write(key, value);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="分栏-3"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.wordcount;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountDriver</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="comment">// 1.获取Job对象</span></span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2.设置jar存储位置</span></span><br><span class="line">        job.setJarByClass(WordCountDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3.关联Map和Reduce类</span></span><br><span class="line">        job.setMapperClass(WordCountMapper.class);</span><br><span class="line">        job.setReducerClass(WordCountReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4.设置Mapper阶段输出的数据的key和value类型</span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5.设置最终数据输出的key和value类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6.设置输入路径和输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 7.提交Job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">resule</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">        System.exit(resule ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><details class="folding-tag" green><summary>点击查看运行结果</summary><div class="content"><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">pwd</span></span><br><span class="line"></span><br><span class="line">Path</span><br><span class="line"><span class="literal">----</span></span><br><span class="line">C:\Users\Administrator\Desktop\output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">ls</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    目录: C:\Users\Administrator\Desktop\output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Mode                 LastWriteTime         Length Name</span><br><span class="line"><span class="literal">----</span>                 <span class="literal">-------------</span>         <span class="literal">------</span> <span class="literal">----</span></span><br><span class="line"><span class="literal">-a----</span>         <span class="number">2023</span>/<span class="number">5</span>/<span class="number">30</span>     <span class="number">17</span>:<span class="number">21</span>             <span class="number">12</span> .part<span class="literal">-r-00000</span>.crc</span><br><span class="line"><span class="literal">-a----</span>         <span class="number">2023</span>/<span class="number">5</span>/<span class="number">30</span>     <span class="number">17</span>:<span class="number">21</span>              <span class="number">8</span> ._SUCCESS.crc</span><br><span class="line"><span class="literal">-a----</span>         <span class="number">2023</span>/<span class="number">5</span>/<span class="number">30</span>     <span class="number">17</span>:<span class="number">21</span>             <span class="number">81</span> part<span class="literal">-r-00000</span></span><br><span class="line"><span class="literal">-a----</span>         <span class="number">2023</span>/<span class="number">5</span>/<span class="number">30</span>     <span class="number">17</span>:<span class="number">21</span>              <span class="number">0</span> _SUCCESS</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">cat</span> .\part<span class="literal">-r-00000</span></span><br><span class="line">        <span class="number">1</span></span><br><span class="line">JERMYN  <span class="number">2</span></span><br><span class="line">Jermyn  <span class="number">3</span></span><br><span class="line">JermynJermyn    <span class="number">1</span></span><br><span class="line">hadoop102       <span class="number">3</span></span><br><span class="line">hadoop103       <span class="number">2</span></span><br><span class="line">hadoop105       <span class="number">2</span></span><br><span class="line">jermyn  <span class="number">2</span></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt;</span><br></pre></td></tr></table></figure></div></details><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div><ul><li><strong>集群上测试</strong><ul><li><strong>用maven打jar包，需要添加的打包插件依赖</strong><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"> <span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>cn.jermyn<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>MapReduceMaven<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>11<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>11<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">project.build.sourceEncoding</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-assembly-plugin <span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">descriptorRef</span>&gt;</span>jar-with-dependencies<span class="tag">&lt;/<span class="name">descriptorRef</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">archive</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">manifest</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">mainClass</span>&gt;</span>cn.jermyn.mr.wordcount.WordCountDriver<span class="tag">&lt;/<span class="name">mainClass</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">manifest</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">archive</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">id</span>&gt;</span>make-assembly<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">goal</span>&gt;</span>single<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><strong>将程序打成jar包，然后拷贝到Hadoop集群中</strong></li><li><strong>执行WordCount程序</strong><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">Jermyn</span>@<span class="type">hadoop102</span> <span class="type">module</span>]<span class="variable">$</span> hadoop jar wc.jar cn.jermyn.mr.wordcount.WordCountDriver /user/Jermyn/input/wcinput/wc.input /user/Jermyn/output</span><br></pre></td></tr></table></figure><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230530174935.png" alt=""></li></ul></li></ul><h1 id="第十二章-Hadoop序列化"><a href="#第十二章-Hadoop序列化" class="headerlink" title="第十二章 Hadoop序列化"></a>第十二章 Hadoop序列化</h1><h2 id="自定义bean对象实现序列化接口（Writable）"><a href="#自定义bean对象实现序列化接口（Writable）" class="headerlink" title="自定义bean对象实现序列化接口（Writable）"></a>自定义bean对象实现序列化接口（Writable）</h2><p>在企业开发中往往常用的基本序列化类型不能满足所有需求，比如在Hadoop框架内部传递一个bean对象，那么该对象就需要实现序列化接口。<br><span class="p center logo large green">实现bean对象序列化步骤</span><br></p><div class="timeline green"><div class="timeline-item headline"><div class="timeline-item-title"><div class="item-circle"><p>实现bean对象序列化步骤</p></div></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第1步</p></div></div><div class="timeline-item-content"><p>必须实现Writable接口</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第2步</p></div></div><div class="timeline-item-content"><p>反序列化时，需要反射调用空参构造函数，所以必须有空参构造<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="title function_">FlowBean</span><span class="params">()</span> &#123;</span><br><span class="line">	<span class="built_in">super</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第3步</p></div></div><div class="timeline-item-content"><p>重写序列化方法:<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">	out.writeLong(upFlow);</span><br><span class="line">	out.writeLong(downFlow);</span><br><span class="line">	out.writeLong(sumFlow);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第4步</p></div></div><div class="timeline-item-content"><p>重写反序列化方法:<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">	upFlow = in.readLong();</span><br><span class="line">	downFlow = in.readLong();</span><br><span class="line">	sumFlow = in.readLong();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第5步</p></div></div><div class="timeline-item-content"><p>注意反序列化的顺序和序列化的顺序完全一致</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第6步</p></div></div><div class="timeline-item-content"><p>要想把结果显示在文件中，需要重写toString()，可用”\t”分开，方便后续用。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第7步</p></div></div><div class="timeline-item-content"><p>如果需要将自定义的bean放在key中传输，则还需要实现Comparable接口，因为MapReduce框中的Shuffle过程要求对key必须能排序。<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(FlowBean o)</span> &#123;</span><br><span class="line">	<span class="comment">// 倒序排列，从大到小</span></span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">this</span>.sumFlow &gt; o.getSumFlow() ? -<span class="number">1</span> : <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p></div></div></div><p></p><h2 id="序列化案例实操"><a href="#序列化案例实操" class="headerlink" title="序列化案例实操"></a>序列化案例实操</h2><ol><li>需求:统计每一个手机号耗费的总上行流量、下行流量、总流量</li><li>需求分析<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230530182450.png" alt=""></li><li>编写MapReduce程序<div class="tabs" id="程序编写"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#程序编写-1">FlowBean.java</button></li><li class="tab"><button type="button" data-href="#程序编写-2">FlowCountMapper.java</button></li><li class="tab"><button type="button" data-href="#程序编写-3">FlowCountReducer.java</button></li><li class="tab"><button type="button" data-href="#程序编写-4">FlowSumDriver.java</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="程序编写-1"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.flowsum;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Writable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataInput;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowBean</span> <span class="keyword">implements</span> <span class="title class_">Writable</span> &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> upFlow; <span class="comment">// 上行流量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> downFlow; <span class="comment">// 下行流量</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> sumFlow; <span class="comment">// 总流量</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">FlowBean</span><span class="params">(<span class="type">long</span> upFlow, <span class="type">long</span> downFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.upFlow = upFlow;</span><br><span class="line">        <span class="built_in">this</span>.downFlow = downFlow;</span><br><span class="line">        sumFlow = upFlow + downFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">FlowBean</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getUpFlow</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> upFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setUpFlow</span><span class="params">(<span class="type">long</span> upFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.upFlow = upFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getDownFlow</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> downFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setDownFlow</span><span class="params">(<span class="type">long</span> downFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.downFlow = downFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getSumFlow</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> sumFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSumFlow</span><span class="params">(<span class="type">long</span> sumFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.sumFlow = sumFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 序列化方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput dataOutput)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        dataOutput.writeLong(upFlow);</span><br><span class="line">        dataOutput.writeLong(downFlow);</span><br><span class="line">        dataOutput.writeLong(sumFlow);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 反序列方法</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput dataInput)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        <span class="comment">// 必须和序列化顺序一致</span></span><br><span class="line">        upFlow = dataInput.readLong();</span><br><span class="line">        downFlow = dataInput.readLong();</span><br><span class="line">        sumFlow = dataInput.readLong();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> upFlow + <span class="string">&quot;\t&quot;</span> + downFlow + <span class="string">&quot;\t&quot;</span> + sumFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">set</span><span class="params">(<span class="type">long</span> upFlow1, <span class="type">long</span> downFlow1)</span> &#123;</span><br><span class="line">        upFlow = upFlow1;</span><br><span class="line">        downFlow = downFlow1;</span><br><span class="line">        sumFlow = upFlow1 + downFlow1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="程序编写-2"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.flowsum;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * map 阶段</span></span><br><span class="line"><span class="comment"> * Mapper&lt;KEYIN, VALUEIN, KEYOUT, VALUEOUT&gt;</span></span><br><span class="line"><span class="comment"> * KEYIN 输入数据的key</span></span><br><span class="line"><span class="comment"> * VALUEIN 输入数据的value</span></span><br><span class="line"><span class="comment"> * KEYOUT 输出数据的key的类型</span></span><br><span class="line"><span class="comment"> * VALUEOUT 输出数据的value类型</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowCountMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, FlowBean&gt; &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="type">Text</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">    <span class="type">FlowBean</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FlowBean</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, FlowBean&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1.获取第一行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2.切割以“\t”</span></span><br><span class="line">        String[] keys = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3.封装对象</span></span><br><span class="line">        k.set(keys[<span class="number">1</span>]);</span><br><span class="line">        <span class="type">long</span> <span class="variable">upFlow</span> <span class="operator">=</span> Long.parseLong(keys[keys.length - <span class="number">3</span>]);</span><br><span class="line">        <span class="type">long</span> <span class="variable">downFlow</span> <span class="operator">=</span> Long.parseLong(keys[keys.length - <span class="number">2</span>]);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        v.set(upFlow,downFlow);</span><br><span class="line">        <span class="comment">// 4. 写出</span></span><br><span class="line">        context.write(k, v);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="程序编写-3"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.flowsum;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowCountReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, FlowBean, Text, FlowBean&gt; &#123;</span><br><span class="line">    <span class="type">FlowBean</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FlowBean</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;FlowBean&gt; values, Reducer&lt;Text, FlowBean, Text, FlowBean&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.累加求和</span></span><br><span class="line">        <span class="type">long</span> <span class="variable">sumUpFlow</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="type">long</span> <span class="variable">sumDownFlow</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (FlowBean flowbean : values) &#123;</span><br><span class="line">            sumUpFlow += flowbean.getUpFlow();</span><br><span class="line">            sumDownFlow += flowbean.getDownFlow();</span><br><span class="line">        &#125;</span><br><span class="line">        v.set(sumUpFlow, sumDownFlow);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.写出</span></span><br><span class="line">        context.write(key, v);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="程序编写-4"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.flowsum;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowSumDriver</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line"></span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\phone.txt&quot;</span>, <span class="string">&quot;C:\\Users\\Administrator\\Desktop\\output&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="comment">// 1.获取Job对象</span></span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2.设置jar的路径</span></span><br><span class="line">        job.setJarByClass(FlowSumDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3.关联Map和Reduce类</span></span><br><span class="line">        job.setMapperClass(FlowCountMapper.class);</span><br><span class="line">        job.setReducerClass(FlowCountReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4.设置Mapper阶段输出的key和value的数据类型</span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(FlowBean.class);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5.设置最终输出的key和value类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(FlowBean.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6.设置输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 7.提交job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(b ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><details class="folding-tag" green><summary>点击查看运行结果</summary><div class="content"><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">ls</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    目录: C:\Users\Administrator\Desktop\output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Mode                 LastWriteTime         Length Name</span><br><span class="line"><span class="literal">----</span>                 <span class="literal">-------------</span>         <span class="literal">------</span> <span class="literal">----</span></span><br><span class="line"><span class="literal">-a----</span>         <span class="number">2023</span>/<span class="number">5</span>/<span class="number">31</span>     <span class="number">11</span>:<span class="number">05</span>             <span class="number">16</span> .part<span class="literal">-r-00000</span>.crc</span><br><span class="line"><span class="literal">-a----</span>         <span class="number">2023</span>/<span class="number">5</span>/<span class="number">31</span>     <span class="number">11</span>:<span class="number">05</span>              <span class="number">8</span> ._SUCCESS.crc</span><br><span class="line"><span class="literal">-a----</span>         <span class="number">2023</span>/<span class="number">5</span>/<span class="number">31</span>     <span class="number">11</span>:<span class="number">05</span>            <span class="number">550</span> part<span class="literal">-r-00000</span></span><br><span class="line"><span class="literal">-a----</span>         <span class="number">2023</span>/<span class="number">5</span>/<span class="number">31</span>     <span class="number">11</span>:<span class="number">05</span>              <span class="number">0</span> _SUCCESS</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">cat</span> .\part<span class="literal">-r-00000</span></span><br><span class="line"><span class="number">13470253144</span>     <span class="number">180</span>     <span class="number">180</span>     <span class="number">360</span></span><br><span class="line"><span class="number">13509468723</span>     <span class="number">7335</span>    <span class="number">110349</span>  <span class="number">117684</span></span><br><span class="line"><span class="number">13560439638</span>     <span class="number">918</span>     <span class="number">4938</span>    <span class="number">5856</span></span><br><span class="line"><span class="number">13568436656</span>     <span class="number">3597</span>    <span class="number">25635</span>   <span class="number">29232</span></span><br><span class="line"><span class="number">13590439668</span>     <span class="number">1116</span>    <span class="number">954</span>     <span class="number">2070</span></span><br><span class="line"><span class="number">13630577991</span>     <span class="number">6960</span>    <span class="number">690</span>     <span class="number">7650</span></span><br><span class="line"><span class="number">13682846555</span>     <span class="number">1938</span>    <span class="number">2910</span>    <span class="number">4848</span></span><br><span class="line"><span class="number">13729199489</span>     <span class="number">240</span>     <span class="number">0</span>       <span class="number">240</span></span><br><span class="line"><span class="number">13736230513</span>     <span class="number">2481</span>    <span class="number">24681</span>   <span class="number">27162</span></span><br><span class="line"><span class="number">13768778790</span>     <span class="number">120</span>     <span class="number">120</span>     <span class="number">240</span></span><br><span class="line"><span class="number">13846544121</span>     <span class="number">264</span>     <span class="number">0</span>       <span class="number">264</span></span><br><span class="line"><span class="number">13956435636</span>     <span class="number">132</span>     <span class="number">1512</span>    <span class="number">1644</span></span><br><span class="line"><span class="number">13966251146</span>     <span class="number">240</span>     <span class="number">0</span>       <span class="number">240</span></span><br><span class="line"><span class="number">13975057813</span>     <span class="number">11058</span>   <span class="number">48243</span>   <span class="number">59301</span></span><br><span class="line"><span class="number">13992314666</span>     <span class="number">3008</span>    <span class="number">3720</span>    <span class="number">6728</span></span><br><span class="line"><span class="number">15043685818</span>     <span class="number">3659</span>    <span class="number">3538</span>    <span class="number">7197</span></span><br><span class="line"><span class="number">15910133277</span>     <span class="number">3156</span>    <span class="number">2936</span>    <span class="number">6092</span></span><br><span class="line"><span class="number">15959002129</span>     <span class="number">1938</span>    <span class="number">180</span>     <span class="number">2118</span></span><br><span class="line"><span class="number">18271575951</span>     <span class="number">1527</span>    <span class="number">2106</span>    <span class="number">3633</span></span><br><span class="line"><span class="number">18390173782</span>     <span class="number">9531</span>    <span class="number">2412</span>    <span class="number">11943</span></span><br><span class="line"><span class="number">84188413</span>        <span class="number">4116</span>    <span class="number">1432</span>    <span class="number">5548</span></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt;</span><br></pre></td></tr></table></figure></div></details><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div></li></ol><h1 id="第十三章-MapReduce框架原理"><a href="#第十三章-MapReduce框架原理" class="headerlink" title="第十三章 MapReduce框架原理"></a>第十三章 MapReduce框架原理</h1><h2 id="InputFormat数据输入"><a href="#InputFormat数据输入" class="headerlink" title="InputFormat数据输入"></a>InputFormat数据输入</h2><h3 id="切片与MapTask并行度决定机制"><a href="#切片与MapTask并行度决定机制" class="headerlink" title="切片与MapTask并行度决定机制"></a>切片与MapTask并行度决定机制</h3><span class="p center logo large green">MapTask并行度决定机制</span><p>数据块：Block是HDFS物理上把数据分成一块一块。<br>数据切片：数据切片只是在逻辑上对输入进行分片，并不会在磁盘上将其切分成片进行存储。</p><blockquote><p>第（4）点，例如多了一个100M的数据需要处理，并不会放在DN2的MapTask处理而是单独启动一个MapTask处理</p></blockquote><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230531113409.png" alt=""></p><h3 id="Job提交流程源码和切片源码详解"><a href="#Job提交流程源码和切片源码详解" class="headerlink" title="Job提交流程源码和切片源码详解"></a>Job提交流程源码和切片源码详解</h3><ul><li><p><strong>Job提交流程源码详解</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">waitForCompletion()</span><br><span class="line"></span><br><span class="line">submit();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1建立连接</span></span><br><span class="line">	connect();	</span><br><span class="line">		<span class="comment">// 1）创建提交Job的代理</span></span><br><span class="line">		<span class="keyword">new</span> <span class="title class_">Cluster</span>(getConfiguration());</span><br><span class="line">			<span class="comment">// （1）判断是本地yarn还是远程</span></span><br><span class="line">			initialize(jobTrackAddr, conf); </span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 提交job</span></span><br><span class="line">submitter.submitJobInternal(Job.<span class="built_in">this</span>, cluster)</span><br><span class="line">	<span class="comment">// 1）创建给集群提交数据的Stag路径</span></span><br><span class="line">	<span class="type">Path</span> <span class="variable">jobStagingArea</span> <span class="operator">=</span> JobSubmissionFiles.getStagingDir(cluster, conf);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 2）获取jobid ，并创建Job路径</span></span><br><span class="line">	<span class="type">JobID</span> <span class="variable">jobId</span> <span class="operator">=</span> submitClient.getNewJobID();</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 3）拷贝jar包到集群</span></span><br><span class="line">copyAndConfigureFiles(job, submitJobDir);	</span><br><span class="line">	rUploader.uploadFiles(job, jobSubmitDir);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4）计算切片，生成切片规划文件</span></span><br><span class="line">writeSplits(job, submitJobDir);</span><br><span class="line">		maps = writeNewSplits(job, jobSubmitDir);</span><br><span class="line">		input.getSplits(job);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 5）向Stag路径写XML配置文件</span></span><br><span class="line">writeConf(conf, submitJobFile);</span><br><span class="line">	conf.writeXml(out);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 6）提交Job,返回提交状态</span></span><br><span class="line">status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());</span><br></pre></td></tr></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/job提交流程.gif" alt=""></p></li><li><p><strong>FileInputFormat切片源码解析(input.getSplits(job))</strong><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/切片源码解析.gif" alt=""></p></li></ul><h3 id="FileInputFormat切片机制"><a href="#FileInputFormat切片机制" class="headerlink" title="FileInputFormat切片机制"></a>FileInputFormat切片机制</h3><span class="p center logo large green">FileInputFormat切片机制</span><ol><li>切片机制<ul><li>简单地按照文件的内容长度进行切片</li><li>切片大小，默认等于Block大小</li><li>切片时不考虑数据集整体，而是逐个针对每一个文件单独切片</li></ul></li><li>案例分析<ul><li>输入数据有两个文件：<pre><code>   file1.txt    320M   
   file2.txt    10M
</code></pre></li><li>经过FileInputFormat的切片机制运算后，形成的切片信息如下：<pre><code>   file1.txt.split1--  0~128
   file1.txt.split2--  128~256
   file1.txt.split3--  256~320
   file2.txt.split1--  0~10M
</code></pre></li></ul></li></ol><span class="p center logo large green">FileInputFormat切片大小的参数配置</span><ul><li>源码中计算切片大小的公式<pre><code>  Math.max(minSize, Math.min(maxSize, blockSize)); 
  mapreduce.input.fileinputformat.split.minsize=1 默认值为1
  mapreduce.input.fileinputformat.split.maxsize= Long.MAXValue 默认值Long.MAXValue
  因此，默认情况下，切片大小=blocksize。
</code></pre></li><li>切片大小设置<br>maxsize（切片最大值）：参数如果调得比blockSize小，则会让切片变小，而且就等于配置的这个参数的值。<br>minsize（切片最小值）：参数调的比blockSize大，则可以让切片变得比blockSize还大。</li><li>获取切片信息API<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取切片的文件名称</span></span><br><span class="line"><span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> inputSplit.getPath().getName();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 根据文件类型获取切片信息</span></span><br><span class="line"><span class="type">FileSplit</span> <span class="variable">inputSplit</span> <span class="operator">=</span> (FileSplit) context.getInputSplit();</span><br></pre></td></tr></table></figure></li></ul><h3 id="CombineTextInputFormat切片机制-小文件处理"><a href="#CombineTextInputFormat切片机制-小文件处理" class="headerlink" title="CombineTextInputFormat切片机制(小文件处理)"></a>CombineTextInputFormat切片机制(小文件处理)</h3><p>框架默认的TextInputFormat切片机制是对任务按文件规划切片，不管文件多小，都会是一个单独的切片，都会交给一个MapTask，这样如果有大量小文件，就会产生大量的MapTask，处理效率极其低下。</p><ol><li>应用场景：<br>CombineTextInputFormat用于小文件过多的场景，它可以将多个小文件从逻辑上规划到一个切片中，这样，多个小文件就可以交给一个MapTask处理。</li><li>虚拟存储切片最大值设置<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CombineTextInputFormat.setMaxInputSplitSize(job, <span class="number">4194304</span>);<span class="comment">// 4m</span></span><br></pre></td></tr></table></figure><span class="p red">注意：虚拟存储切片最大值设置最好根据实际的小文件大小情况来设置具体的值。</span></li><li>切片机制<br>生成切片过程包括：虚拟存储过程和切片过程二部分。<span class="p center logo large green">CombineTextInputFormat切片机制</span> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230531184213.png" alt=""></li></ol><ul><li><strong>虚拟存储过程：</strong><br>将输入目录下所有文件大小，依次和设置的setMaxInputSplitSize值比较，如果不大于设置的最大值，逻辑上划分一个块。如果输入文件大于设置的最大值且大于两倍，那么以最大值切割一块；当剩余数据大小超过设置的最大值且不大于最大值2倍，此时将文件均分成2个虚拟存储块（防止出现太小切片）。<br>例如setMaxInputSplitSize值为4M，输入文件大小为8.02M，则先逻辑上分成一个4M。剩余的大小为4.02M，如果按照4M逻辑划分，就会出现0.02M的小的虚拟存储文件，所以将剩余的4.02M文件切分成（2.01M和2.01M）两个文件。</li><li><strong>切片过程：</strong><ul><li>判断虚拟存储的文件大小是否大于setMaxInputSplitSize值，大于等于则单独形成一个切片。</li><li>如果不大于则跟下一个虚拟存储文件进行合并，共同形成一个切片。</li></ul></li><li><strong>测试举例：</strong><br>有4个小文件大小分别为<strong>1.7M、5.1M、3.4M以及6.8M</strong>这四个小文件，则虚拟存储之后形成6个文件块，大小分别为：1.7M，（2.55M、2.55M），3.4M以及（3.4M、3.4M）最终会形成3个切片，大小分别为：（1.7+2.55）M，（2.55+3.4）M，（3.4+3.4）M</li></ul><h3 id="CombineTextInputFormat案例实操"><a href="#CombineTextInputFormat案例实操" class="headerlink" title="CombineTextInputFormat案例实操"></a>CombineTextInputFormat案例实操</h3><ul><li><p><strong>默认情况下</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root   <span class="number">2.1</span>M <span class="number">5</span>月  <span class="number">31</span> <span class="number">18</span>:<span class="number">59</span> <span class="number">1</span>.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root   <span class="number">5.4</span>M <span class="number">5</span>月  <span class="number">31</span> <span class="number">18</span>:<span class="number">59</span> <span class="number">2</span>.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root   <span class="number">1.3</span>M <span class="number">5</span>月  <span class="number">31</span> <span class="number">18</span>:<span class="number">59</span> <span class="number">3</span>.txt</span><br><span class="line"><span class="literal">-rw-r--r--</span>.  <span class="number">1</span> Jermyn root   <span class="number">4.4</span>M <span class="number">5</span>月  <span class="number">31</span> <span class="number">18</span>:<span class="number">59</span> <span class="number">4</span>.txt</span><br><span class="line"></span><br><span class="line">（<span class="number">2.1</span>M <span class="number">5.4</span>M <span class="number">1.3</span>M <span class="number">4.4</span>M） <span class="number">4</span>个切片</span><br></pre></td></tr></table></figure></li><li><p><strong>驱动类中添加代码如下：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 如果不设置InputFormat，它默认用的是TextInputFormat.class</span></span><br><span class="line">job.setInputFormatClass(CombineTextInputFormat.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">//虚拟存储切片最大值设置4m</span></span><br><span class="line">CombineTextInputFormat.setMaxInputSplitSize(job, <span class="number">4194304</span>);</span><br></pre></td></tr></table></figure><details class="folding-tag" green><summary>点击查看运行结果</summary><div class="content"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:<span class="number">3</span></span><br></pre></td></tr></table></figure><p>2.1M (2.7M 2.7M) 1.3M (2.2M 2.2M) 6个文件块<br>（2.1M 2.7M）（2.7M 1.3M）（2.2M 2.2M） 3个切片</p></div></details></li><li><strong>在WordcountDriver中增加如下代码：</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 如果不设置InputFormat，它默认用的是TextInputFormat.class</span></span><br><span class="line">job.setInputFormatClass(CombineTextInputFormat.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">//虚拟存储切片最大值设置20m</span></span><br><span class="line">CombineTextInputFormat.setMaxInputSplitSize(job, <span class="number">20971520</span>);</span><br></pre></td></tr></table></figure><details class="folding-tag" green><summary>点击查看运行结果</summary><div class="content"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INFO [org.apache.hadoop.mapreduce.JobSubmitter] - number of splits:<span class="number">1</span></span><br></pre></td></tr></table></figure><p>2.1M (2.7M 2.7M) 1.3M (2.2M 2.2M) 6个文件块<br>（2.1M 2.7M 2.7M 1.3M 2.2M 2.2M） 1个切片</p></div></details></li></ul><h3 id="FileInputFormat实现类"><a href="#FileInputFormat实现类" class="headerlink" title="FileInputFormat实现类"></a>FileInputFormat实现类</h3><p>FileInputFormat常见的接口实现类包括：TextInputFormat、KeyValueTextInputFormat、NLineInputFormat、CombineTextInputFormat和自定义InputFormat等。</p><ol><li>TextInputFormat<br>TextInputFormat是默认的FileInputFormat实现类。按行读取每条记录。键是存储该行在整个文件中的起始字节偏移量， LongWritable类型。值是这行的内容，不包括任何行终止符（换行符和回车符），Text类型。<br>以下是一个示例，比如，一个分片包含了如下4条文本记录。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Rich learning form</span><br><span class="line">Intelligent learning engine</span><br><span class="line">Learning more convenient</span><br><span class="line">From the real demand for more close to the enterprise</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">每条记录表示为以下键/值对：</span><br><span class="line">(0,Rich learning form)</span><br><span class="line">(19,Intelligent learning engine)</span><br><span class="line">(47,Learning more convenient)</span><br><span class="line">(72,From the real demand for more close to the enterprise)</span><br></pre></td></tr></table></figure></li><li>KeyValueTextInputFormat<br>每一行均为一条记录，被分隔符分割为key，value。可以通过在驱动类中设置conf.set(KeyValueLineRecordReader.KEY_VALUE_SEPERATOR, “\t”);来设定分隔符。默认分隔符是tab（\t）。<br>以下是一个示例，输入是一个包含4条记录的分片。其中——&gt;表示一个（水平方向的）制表符。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">line1 ——&gt;Rich learning form</span><br><span class="line">line2 ——&gt;Intelligent learning engine</span><br><span class="line">line3 ——&gt;Learning more convenient</span><br><span class="line">line4 ——&gt;From the real demand for more close to the enterprise</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">每条记录表示为以下键/值对：</span><br><span class="line">(line1,Rich learning form)</span><br><span class="line">(line2,Intelligent learning engine)</span><br><span class="line">(line3,Learning more convenient)</span><br><span class="line">(line4,From the real demand for more close to the enterprise)</span><br></pre></td></tr></table></figure>此时的键是每行排在制表符之前的Text序列。</li><li>NLineInputFormat<br>如果使用NlineInputFormat，代表每个map进程处理的InputSplit不再按Block块去划分，而是按NlineInputFormat指定的行数N来划分。即输入文件的总行数/N=切片数，如果不整除，切片数=商+1。<br>以下是一个示例，仍然以上面的4行输入为例。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Rich learning form</span><br><span class="line">Intelligent learning engine</span><br><span class="line">Learning more convenient</span><br><span class="line">From the real demand for more close to the enterprise</span><br></pre></td></tr></table></figure>例如，如果N是2，则每个输入分片包含两行。开启2个MapTask。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(0,Rich learning form)</span><br><span class="line">(19,Intelligent learning engine)</span><br></pre></td></tr></table></figure>另一个 mapper 则收到后两行：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(47,Learning more convenient)</span><br><span class="line">(72,From the real demand for more close to the enterprise)</span><br></pre></td></tr></table></figure>这里的键和值与TextInputFormat生成的一样。</li></ol><h3 id="KeyValueTextInputFormat使用案例"><a href="#KeyValueTextInputFormat使用案例" class="headerlink" title="KeyValueTextInputFormat使用案例"></a>KeyValueTextInputFormat使用案例</h3><div class="btns rounded grid5"><a class="button" target="_blank" rel="noopener" href="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/KVText.txt" title="查看KVText.txt"><i class="fas fa-book-open"></i> 查看KVText.txt</a></div><ol><li>需求:统计输入文件中每一行的第一个单词相同的行数。</li><li>需求分析<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230531222737.png" alt=""></li><li>代码实现<div class="tabs" id="keyvaluetextinputformat"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#keyvaluetextinputformat-1">KVTextMapper.java</button></li><li class="tab"><button type="button" data-href="#keyvaluetextinputformat-2">KVTextReducer.java</button></li><li class="tab"><button type="button" data-href="#keyvaluetextinputformat-3">KVTextDriver.java</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="keyvaluetextinputformat-1"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.kvtext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KVTextMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Text, Text, Text, IntWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Text key, Text value, Mapper&lt;Text, Text, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 1 设置value</span></span><br><span class="line">        <span class="type">IntWritable</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 写出</span></span><br><span class="line">        context.write(key, v);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="keyvaluetextinputformat-2"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.kvtext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KVTextReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">IntWritable</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Reducer&lt;Text, IntWritable, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 汇总统计</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (IntWritable value : values) &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> value.get();</span><br><span class="line">            sum += i;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 输出</span></span><br><span class="line">        v.set(sum);</span><br><span class="line">        context.write(key, v);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="keyvaluetextinputformat-3"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.kvtext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.KeyValueTextInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KVTextDriver</span> &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line"></span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\input\\KVText.txt&quot;</span>, <span class="string">&quot;C:\\Users\\Administrator\\Desktop\\output&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.获取job</span></span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置分割符为空格</span></span><br><span class="line">        conf.set(KeyValueLineRecordReader.KEY_VALUE_SEPERATOR, <span class="string">&quot; &quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置输入的数据类型为KVText</span></span><br><span class="line">        job.setInputFormatClass(KeyValueTextInputFormat.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.设置jar包的存储位置</span></span><br><span class="line">        job.setJarByClass(KVTextDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.关联Map和Reducer类</span></span><br><span class="line">        job.setMapperClass(KVTextMapper.class);</span><br><span class="line">        job.setReducerClass(KVTextReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4.设置Map阶段输出的k和v的类型</span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//5.设置最终阶段输出的kv的类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//6.设置输入路径和输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//7.提交Job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(b ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><details class="folding-tag" green><summary>点击查看运行结果</summary><div class="content"><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">ls</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    目录: C:\Users\Administrator\Desktop\output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Mode                 LastWriteTime         Length Name</span><br><span class="line"><span class="literal">----</span>                 <span class="literal">-------------</span>         <span class="literal">------</span> <span class="literal">----</span></span><br><span class="line"><span class="literal">-a----</span>         <span class="number">2023</span>/<span class="number">5</span>/<span class="number">31</span>     <span class="number">22</span>:<span class="number">22</span>             <span class="number">12</span> .part<span class="literal">-r-00000</span>.crc</span><br><span class="line"><span class="literal">-a----</span>         <span class="number">2023</span>/<span class="number">5</span>/<span class="number">31</span>     <span class="number">22</span>:<span class="number">22</span>              <span class="number">8</span> ._SUCCESS.crc</span><br><span class="line"><span class="literal">-a----</span>         <span class="number">2023</span>/<span class="number">5</span>/<span class="number">31</span>     <span class="number">22</span>:<span class="number">22</span>             <span class="number">20</span> part<span class="literal">-r-00000</span></span><br><span class="line"><span class="literal">-a----</span>         <span class="number">2023</span>/<span class="number">5</span>/<span class="number">31</span>     <span class="number">22</span>:<span class="number">22</span>              <span class="number">0</span> _SUCCESS</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">cat</span> .\part<span class="literal">-r-00000</span></span><br><span class="line">banzhang        <span class="number">2</span></span><br><span class="line">xihuan  <span class="number">2</span></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt;</span><br></pre></td></tr></table></figure></div></details><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div></li></ol><h3 id="NLineInputFormat使用案例"><a href="#NLineInputFormat使用案例" class="headerlink" title="NLineInputFormat使用案例"></a>NLineInputFormat使用案例</h3><ol><li>需求:对每个单词进行个数统计，要求根据每个输入文件的行数来规定输出多少个切片。此案例要求每三行放入一个切片中。<div class="btns rounded grid5"><a class="button" target="_blank" rel="noopener" href="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/Nline.txt" title="Nline.txt"><i class="fas fa-book-open"></i> Nline.txt</a></div></li><li>需求分析<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230603091642.png" alt=""></li><li>编辑代码<div class="tabs" id="nline"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#nline-1">NlineMapper.java</button></li><li class="tab"><button type="button" data-href="#nline-2">NlineReducer.java</button></li><li class="tab"><button type="button" data-href="#nline-3">NlineDriver</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="nline-1"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.nline;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NLineMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, LongWritable&gt; &#123;</span><br><span class="line">    <span class="type">Text</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">    <span class="type">LongWritable</span> <span class="variable">val</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">LongWritable</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, LongWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取一行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">values</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 划分</span></span><br><span class="line">        String[] s = values.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 封装</span></span><br><span class="line">        <span class="keyword">for</span> (String s1 : s) &#123;</span><br><span class="line">            k.set(s1);</span><br><span class="line">            context.write(k, val);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="nline-2"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.nline;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NLineReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, LongWritable, Text, LongWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;LongWritable&gt; values, Reducer&lt;Text, LongWritable, Text, LongWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取</span></span><br><span class="line">        <span class="type">Long</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0L</span>;</span><br><span class="line">        <span class="keyword">for</span> (LongWritable value : values) &#123;</span><br><span class="line">            sum += value.get();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 封装</span></span><br><span class="line">        <span class="type">LongWritable</span> <span class="variable">longWritable</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">LongWritable</span>(sum);</span><br><span class="line">        context.write(key, longWritable);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="nline-3"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.nline;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.NLineInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NLineDriver</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\input\\Nline.txt&quot;</span>,</span><br><span class="line">                <span class="string">&quot;C:\\Users\\Administrator\\Desktop\\output&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">entries</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="comment">// 获取一个job</span></span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(entries);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置每个切片InputSplit中划分三条记录</span></span><br><span class="line">        NLineInputFormat.setNumLinesPerSplit(job, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 使用NLineInputFormat处理记录数</span></span><br><span class="line">        job.setInputFormatClass(NLineInputFormat.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取jar包存储的位置</span></span><br><span class="line">        job.setJarByClass(NLineDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 关联Map和reduce</span></span><br><span class="line">        job.setMapperClass(NLineMapper.class);</span><br><span class="line">        job.setReducerClass(NLineReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置Map阶段输出的KV数据类型</span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(LongWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置最终的输出数据类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(LongWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置文件读取的路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 提交job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(b ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><details class="folding-tag" green><summary>点击查看运行结果</summary><div class="content"><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">ls</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    目录: C:\Users\Administrator\Desktop\output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Mode                 LastWriteTime         Length Name</span><br><span class="line"><span class="literal">----</span>                 <span class="literal">-------------</span>         <span class="literal">------</span> <span class="literal">----</span></span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>      <span class="number">9</span>:<span class="number">06</span>             <span class="number">12</span> .part<span class="literal">-r-00000</span>.crc</span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>      <span class="number">9</span>:<span class="number">06</span>              <span class="number">8</span> ._SUCCESS.crc</span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>      <span class="number">9</span>:<span class="number">06</span>             <span class="number">87</span> part<span class="literal">-r-00000</span></span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>      <span class="number">9</span>:<span class="number">06</span>              <span class="number">0</span> _SUCCESS</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">cat</span> .\part<span class="literal">-r-00000</span></span><br><span class="line"><span class="number">1</span>       <span class="number">1</span></span><br><span class="line"><span class="number">10</span>      <span class="number">1</span></span><br><span class="line"><span class="number">11</span>      <span class="number">1</span></span><br><span class="line"><span class="number">2</span>       <span class="number">1</span></span><br><span class="line"><span class="number">3</span>       <span class="number">1</span></span><br><span class="line"><span class="number">4</span>       <span class="number">1</span></span><br><span class="line"><span class="number">5</span>       <span class="number">1</span></span><br><span class="line"><span class="number">6</span>       <span class="number">1</span></span><br><span class="line"><span class="number">7</span>       <span class="number">1</span></span><br><span class="line"><span class="number">8</span>       <span class="number">1</span></span><br><span class="line"><span class="number">9</span>       <span class="number">1</span></span><br><span class="line">banzhang        <span class="number">12</span></span><br><span class="line">hadoop  <span class="number">6</span></span><br><span class="line">hao     <span class="number">6</span></span><br><span class="line"><span class="built_in">ni</span>      <span class="number">6</span></span><br><span class="line">xihuan  <span class="number">6</span></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt;</span><br></pre></td></tr></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230603091953.png" alt=""></p></div></details><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div></li></ol><h3 id="自定义InputFormat案例实操-小文件"><a href="#自定义InputFormat案例实操-小文件" class="headerlink" title="自定义InputFormat案例实操(小文件)"></a>自定义InputFormat案例实操(小文件)</h3><p>无论HDFS还是MapReduce，在处理小文件时效率都非常低，但又难免面临处理大量小文件的场景，此时，就需要有相应解决方案。可以自定义InputFormat实现小文件的合并。</p><ol><li>需求：将多个小文件合并成一个SequenceFile文件（SequenceFile文件是Hadoop用来存储二进制形式的key-value对的文件格式），SequenceFile里面存储着多个文件，存储的形式为文件路径+名称为key，文件内容为value。<div class="btns rounded grid5"><a class="button" target="_blank" rel="noopener" href="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/one.txt" title="one.txt"><i class="fas fa-book-open"></i> one.txt</a><a class="button" target="_blank" rel="noopener" href="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/two.txt" title="two.txt"><i class="fas fa-book-open"></i> two.txt</a><a class="button" target="_blank" rel="noopener" href="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/three.txt" title="three.txt"><i class="fas fa-book-open"></i> three.txt</a></div></li><li>需求分析<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230603153132.png" alt=""></li><li>代码编写<div class="tabs" id="代码编写"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#代码编写-1">AllFileInputFormat.java</button></li><li class="tab"><button type="button" data-href="#代码编写-2">AllRecordReader.java</button></li><li class="tab"><button type="button" data-href="#代码编写-3">SequenceFileMapper.java</button></li><li class="tab"><button type="button" data-href="#代码编写-4">SequenceFileReducer.java</button></li><li class="tab"><button type="button" data-href="#代码编写-5">SequenceFileDriver.java</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="代码编写-1"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.customizeinputformat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.BytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.InputSplit;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.RecordReader;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.TaskAttemptContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AllFileInputFormat</span> <span class="keyword">extends</span> <span class="title class_">FileInputFormat</span>&lt;Text, BytesWritable&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> RecordReader <span class="title function_">createRecordReader</span><span class="params">(InputSplit split, TaskAttemptContext context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">AllRecordReader</span> <span class="variable">recordReader</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">AllRecordReader</span>();</span><br><span class="line"></span><br><span class="line">        recordReader.initialize(split, context);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> recordReader;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="代码编写-2"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.customizeinputformat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataInputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.BytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.InputSplit;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.RecordReader;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.TaskAttemptContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileSplit;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AllRecordReader</span> <span class="keyword">extends</span> <span class="title class_">RecordReader</span>&lt;Text, BytesWritable&gt; &#123;</span><br><span class="line">    <span class="keyword">private</span> Configuration configuration;</span><br><span class="line">    <span class="keyword">private</span> FileSplit split;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">boolean</span> <span class="variable">isProgress</span> <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">BytesWritable</span> <span class="variable">value</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BytesWritable</span>();</span><br><span class="line">    <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">initialize</span><span class="params">(InputSplit split, TaskAttemptContext context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">this</span>.split = (FileSplit) split;</span><br><span class="line">        configuration = context.getConfiguration();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">nextKeyValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (isProgress) &#123;</span><br><span class="line">            <span class="comment">// 1 定义缓存区</span></span><br><span class="line">            <span class="type">byte</span>[] contents = <span class="keyword">new</span> <span class="title class_">byte</span>[(<span class="type">int</span>) split.getLength()];</span><br><span class="line">            <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">            <span class="type">FSDataInputStream</span> <span class="variable">fis</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">// 2 获取文件系统</span></span><br><span class="line">                <span class="type">Path</span> <span class="variable">path</span> <span class="operator">=</span> split.getPath();</span><br><span class="line">                fs = path.getFileSystem(configuration);</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 3 读取数据</span></span><br><span class="line">                fis = fs.open(path);</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 4 读取文件内容</span></span><br><span class="line">                IOUtils.readFully(fis, contents, <span class="number">0</span>, contents.length);</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 5 输出文件内容</span></span><br><span class="line">                value.set(contents, <span class="number">0</span>, contents.length);</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 6 获取文件路径及名称</span></span><br><span class="line">                <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> split.getPath().toString();</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 7 设置输出的key值</span></span><br><span class="line">                k.set(name);</span><br><span class="line"></span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line"></span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                org.apache.hadoop.io.IOUtils.closeStream(fis);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            isProgress = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Text <span class="title function_">getCurrentKey</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        k = <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">        <span class="keyword">return</span> k;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> BytesWritable <span class="title function_">getCurrentValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        value = <span class="keyword">new</span> <span class="title class_">BytesWritable</span>();</span><br><span class="line">        <span class="keyword">return</span> value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">float</span> <span class="title function_">getProgress</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="代码编写-3"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.customizeinputformat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.BytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SequenceFileMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;Text, BytesWritable, Text, BytesWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(Text key, BytesWritable value, Mapper&lt;Text, BytesWritable, Text, BytesWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        context.write(key, value);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="代码编写-4"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.customizeinputformat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.BytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SequenceFileReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, BytesWritable, Text, BytesWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;BytesWritable&gt; values, Reducer&lt;Text, BytesWritable, Text, BytesWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (BytesWritable value : values) &#123;</span><br><span class="line">            context.write(key, value);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="代码编写-5"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.customizeinputformat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.BytesWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SequenceFileDriver</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line"></span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\input&quot;</span>,<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\output&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">entries</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="comment">// 获取一个job</span></span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(entries);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置输入的inputFormat</span></span><br><span class="line">        job.setInputFormatClass(AllFileInputFormat.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置输出的outputFormat</span></span><br><span class="line">        job.setOutputFormatClass(SequenceFileOutputFormat.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置jar包的位置</span></span><br><span class="line">        job.setJarByClass(SequenceFileDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 关联映射的 Map和reduce</span></span><br><span class="line">        job.setMapperClass(SequenceFileMapper.class);</span><br><span class="line">        job.setReducerClass(SequenceFileReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置map阶段输出的数据的kv类型</span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(BytesWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置最终阶段输出的数据的kv类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(BytesWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置输入和输出的路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 提交job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(b ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><details class="folding-tag" green><summary>点击查看运行结果</summary><div class="content"><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">ls</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    目录: C:\Users\Administrator\Desktop\output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Mode                 LastWriteTime         Length Name</span><br><span class="line"><span class="literal">----</span>                 <span class="literal">-------------</span>         <span class="literal">------</span> <span class="literal">----</span></span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>     <span class="number">15</span>:<span class="number">08</span>             <span class="number">12</span> .part<span class="literal">-r-00000</span>.crc</span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>     <span class="number">15</span>:<span class="number">08</span>              <span class="number">8</span> ._SUCCESS.crc</span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>     <span class="number">15</span>:<span class="number">08</span>            <span class="number">126</span> part<span class="literal">-r-00000</span></span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>     <span class="number">15</span>:<span class="number">08</span>              <span class="number">0</span> _SUCCESS</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">cat</span> .\part<span class="literal">-r-00000</span></span><br><span class="line">SEQorg.apache.hadoop.io.Text<span class="string">&quot;org.apache.hadoop.io.BytesWritableS圝谻斈XG`3!FGzE</span></span><br><span class="line"><span class="string">PS C:\Users\Administrator\Desktop\output&gt;</span></span><br></pre></td></tr></table></figure></div></details><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div></li></ol><h2 id="MapReduce工作流程"><a href="#MapReduce工作流程" class="headerlink" title="MapReduce工作流程"></a>MapReduce工作流程</h2><h3 id="MapReduce详细工作流程一（Map）"><a href="#MapReduce详细工作流程一（Map）" class="headerlink" title="MapReduce详细工作流程一（Map）"></a>MapReduce详细工作流程一（Map）</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/流程.gif" alt=""><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230603160107.png" alt=""></p><h3 id="MapReduce详细工作流程一（Reduce）"><a href="#MapReduce详细工作流程一（Reduce）" class="headerlink" title="MapReduce详细工作流程一（Reduce）"></a>MapReduce详细工作流程一（Reduce）</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/流程2.gif" alt=""><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230603160501.png" alt=""></p><h3 id="流程详解"><a href="#流程详解" class="headerlink" title="流程详解"></a>流程详解</h3><p>上面的流程是整个MapReduce最全工作流程，但是Shuffle过程只是从第7步开始到第16步结束，具体Shuffle过程详解，如下：</p><ol><li>MapTask收集我们的map()方法输出的kv对，放到内存缓冲区中</li><li>从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件</li><li>多个溢出文件会被合并成大的溢出文件</li><li>在溢出过程及合并的过程中，都要调用Partitioner进行分区和针对key进行排序</li><li>ReduceTask根据自己的分区号，去各个MapTask机器上取相应的结果分区数据</li><li>ReduceTask会取到同一个分区的来自不同MapTask的结果文件，ReduceTask会将这些文件再进行合并（归并排序）</li><li>合并成大文件后，Shuffle的过程也就结束了，后面进入ReduceTask的逻辑运算过程（从文件中取出一个一个的键值对Group，调用用户自定义的reduce()方法）<blockquote><p>注意：Shuffle中的缓冲区大小会影响到MapReduce程序的执行效率，原则上说，缓冲区越大，磁盘io的次数越少，执行速度就越快。缓冲区的大小可以通过参数调整，参数：io.sort.mb默认100M</p></blockquote></li></ol><h2 id="Shuffle机制"><a href="#Shuffle机制" class="headerlink" title="Shuffle机制"></a>Shuffle机制</h2><h3 id="Shuffle机制-1"><a href="#Shuffle机制-1" class="headerlink" title="Shuffle机制"></a>Shuffle机制</h3><div class="tip fa-gamepad faa-horizontal animated"><p>Map方法之后，Reduce方法之前的数据处理过程称之为Shuffle。</p></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/流程4.gif" alt=""><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230603162454.png" alt=""></p><h3 id="Partition分区"><a href="#Partition分区" class="headerlink" title="Partition分区"></a>Partition分区</h3><ol><li>问题引出<br>要求将统计结果按照条件输出到不同文件中（分区）。比如：将统计结果按照手机归属地不同省份输出到不同文件中（分区）</li><li>默认Partitioner分区<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HashPartitioner</span>&lt;K, V&gt; <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;K, V&gt; &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(K key, V value, <span class="type">int</span> numReduceTasks)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>默认分区是根据key的hashCode对ReduceTasks个数取模得到的。用户没法控制哪个key存储到哪个分区。</li><li>自定义Partitioner步骤<ol><li>自定义类继承Partitioner，重写getPartition()方法<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomPartitioner</span> <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;Text, FlowBean&gt; &#123;</span><br><span class="line"> 	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(Text key, FlowBean value, <span class="type">int</span> numPartitions)</span> &#123;</span><br><span class="line">          <span class="comment">// 控制分区代码逻辑</span></span><br><span class="line">    … …</span><br><span class="line">		<span class="keyword">return</span> partition;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>在Job驱动中，设置自定义Partitioner<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setPartitionerClass(CustomPartitioner.class);</span><br></pre></td></tr></table></figure></li><li>自定义Partition后，要根据自定义Partitioner的逻辑设置相应数量的ReduceTask<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setNumReduceTasks(<span class="number">5</span>);</span><br></pre></td></tr></table></figure></li></ol></li><li>分区总结<ol><li>如果ReduceTask的数量&gt; getPartition的结果数，则会多产生几个空的输出文件part-r-000xx；</li><li>如果1 &lt; ReduceTask的数量 &lt; getPartition的结果数，则有一部分分区数据无处安放，会Exception；</li><li>如果ReduceTask的数量=1，则不管MapTask端输出多少个分区文件，最终结果都交给这一个ReduceTask，最终也就只会产生一个结果文件 part-r-00000</li><li>分区号必须从零开始，逐一累加。</li></ol></li><li>案例分析:<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">例如：假设自定义分区数为5，则</span><br><span class="line">job.setNumReduceTasks(1);   会正常运行，只不过会产生一个输出文件</span><br><span class="line">job.setNumReduceTasks(2);   会报错</span><br><span class="line">job.setNumReduceTasks(6);   大于5，程序会正常运行，会产生空文件</span><br></pre></td></tr></table></figure></li></ol><h3 id="Partition分区案例实操"><a href="#Partition分区案例实操" class="headerlink" title="Partition分区案例实操"></a>Partition分区案例实操</h3><ol><li>需求:将统计结果按照手机归属地不同省份输出到不同文件中（分区）</li><li>期望输出数据:手机号136、137、138、139开头都分别放到一个独立的4个文件中，其他开头的放到一个文件中。</li><li>需求分析<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230603165421.png" alt=""></li><li>编写代码<div class="tip fa-gamepad faa-horizontal animated"><p>在案例12.2的基础上，增加一个分区类</p></div><div class="tabs" id="provincepartitioner"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#provincepartitioner-1">ProvincePartitioner.java</button></li><li class="tab"><button type="button" data-href="#provincepartitioner-2">FlowSumDriver</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="provincepartitioner-1"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.flowsum;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Partitioner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ProvincePartitioner</span> <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;Text, FlowBean&gt; &#123;</span><br><span class="line">    <span class="comment">// key是手机号</span></span><br><span class="line">    <span class="comment">// value 是流量信息</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(Text text, FlowBean flowBean, <span class="type">int</span> numPartitions)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> <span class="variable">partition</span> <span class="operator">=</span> <span class="number">4</span>;</span><br><span class="line">        <span class="comment">// 获取手机号前3位</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">pre3OfPhoneNum</span> <span class="operator">=</span> text.toString().substring(<span class="number">0</span>, <span class="number">3</span>);</span><br><span class="line">        <span class="keyword">if</span> (<span class="string">&quot;136&quot;</span>.equals(pre3OfPhoneNum)) &#123;</span><br><span class="line">            partition = <span class="number">0</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;137&quot;</span>.equals(pre3OfPhoneNum)) &#123;</span><br><span class="line">            partition = <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;138&quot;</span>.equals(pre3OfPhoneNum)) &#123;</span><br><span class="line">            partition = <span class="number">2</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;139&quot;</span>.equals(pre3OfPhoneNum)) &#123;</span><br><span class="line">            partition = <span class="number">3</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> partition;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="provincepartitioner-2"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.flowsum;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowSumDriver</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line"></span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\input\\phone.txt&quot;</span>, <span class="string">&quot;C:\\Users\\Administrator\\Desktop\\output&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="comment">// 1.获取Job对象</span></span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//指定自定义数据分区</span></span><br><span class="line">        job.setPartitionerClass(ProvincePartitioner.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//同时指定相应数量的reduce task</span></span><br><span class="line">        job.setNumReduceTasks(<span class="number">5</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2.设置jar的路径</span></span><br><span class="line">        job.setJarByClass(FlowSumDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3.关联Map和Reduce类</span></span><br><span class="line">        job.setMapperClass(FlowCountMapper.class);</span><br><span class="line">        job.setReducerClass(FlowCountReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4.设置Mapper阶段输出的key和value的数据类型</span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(FlowBean.class);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5.设置最终输出的key和value类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(FlowBean.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6.设置输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 7.提交job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(b ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><details class="folding-tag" green><summary>点击查看运行结果</summary><div class="content"><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">ls</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    目录: C:\Users\Administrator\Desktop\output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Mode                 LastWriteTime         Length Name</span><br><span class="line"><span class="literal">----</span>                 <span class="literal">-------------</span>         <span class="literal">------</span> <span class="literal">----</span></span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>     <span class="number">17</span>:<span class="number">12</span>             <span class="number">12</span> .part<span class="literal">-r-00000</span>.crc</span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>     <span class="number">17</span>:<span class="number">12</span>             <span class="number">12</span> .part<span class="literal">-r-00001</span>.crc</span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>     <span class="number">17</span>:<span class="number">12</span>             <span class="number">12</span> .part<span class="literal">-r-00002</span>.crc</span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>     <span class="number">17</span>:<span class="number">12</span>             <span class="number">12</span> .part<span class="literal">-r-00003</span>.crc</span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>     <span class="number">17</span>:<span class="number">12</span>             <span class="number">12</span> .part<span class="literal">-r-00004</span>.crc</span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>     <span class="number">17</span>:<span class="number">12</span>              <span class="number">8</span> ._SUCCESS.crc</span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>     <span class="number">17</span>:<span class="number">12</span>             <span class="number">53</span> part<span class="literal">-r-00000</span></span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>     <span class="number">17</span>:<span class="number">12</span>             <span class="number">75</span> part<span class="literal">-r-00001</span></span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>     <span class="number">17</span>:<span class="number">12</span>             <span class="number">22</span> part<span class="literal">-r-00002</span></span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>     <span class="number">17</span>:<span class="number">12</span>            <span class="number">105</span> part<span class="literal">-r-00003</span></span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>     <span class="number">17</span>:<span class="number">12</span>            <span class="number">295</span> part<span class="literal">-r-00004</span></span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>     <span class="number">17</span>:<span class="number">12</span>              <span class="number">0</span> _SUCCESS</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">cat</span> .\part<span class="literal">-r-00000</span></span><br><span class="line"><span class="number">13630577991</span>     <span class="number">6960</span>    <span class="number">690</span>     <span class="number">7650</span></span><br><span class="line"><span class="number">13682846555</span>     <span class="number">1938</span>    <span class="number">2910</span>    <span class="number">4848</span></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">cat</span> .\part<span class="literal">-r-00001</span></span><br><span class="line"><span class="number">13729199489</span>     <span class="number">240</span>     <span class="number">0</span>       <span class="number">240</span></span><br><span class="line"><span class="number">13736230513</span>     <span class="number">2481</span>    <span class="number">24681</span>   <span class="number">27162</span></span><br><span class="line"><span class="number">13768778790</span>     <span class="number">120</span>     <span class="number">120</span>     <span class="number">240</span></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">cat</span> .\part<span class="literal">-r-00002</span></span><br><span class="line"><span class="number">13846544121</span>     <span class="number">264</span>     <span class="number">0</span>       <span class="number">264</span></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">cat</span> .\part<span class="literal">-r-00003</span></span><br><span class="line"><span class="number">13956435636</span>     <span class="number">132</span>     <span class="number">1512</span>    <span class="number">1644</span></span><br><span class="line"><span class="number">13966251146</span>     <span class="number">240</span>     <span class="number">0</span>       <span class="number">240</span></span><br><span class="line"><span class="number">13975057813</span>     <span class="number">11058</span>   <span class="number">48243</span>   <span class="number">59301</span></span><br><span class="line"><span class="number">13992314666</span>     <span class="number">3008</span>    <span class="number">3720</span>    <span class="number">6728</span></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">cat</span> .\part<span class="literal">-r-00004</span></span><br><span class="line"><span class="number">13470253144</span>     <span class="number">180</span>     <span class="number">180</span>     <span class="number">360</span></span><br><span class="line"><span class="number">13509468723</span>     <span class="number">7335</span>    <span class="number">110349</span>  <span class="number">117684</span></span><br><span class="line"><span class="number">13560439638</span>     <span class="number">918</span>     <span class="number">4938</span>    <span class="number">5856</span></span><br><span class="line"><span class="number">13568436656</span>     <span class="number">3597</span>    <span class="number">25635</span>   <span class="number">29232</span></span><br><span class="line"><span class="number">13590439668</span>     <span class="number">1116</span>    <span class="number">954</span>     <span class="number">2070</span></span><br><span class="line"><span class="number">15043685818</span>     <span class="number">3659</span>    <span class="number">3538</span>    <span class="number">7197</span></span><br><span class="line"><span class="number">15910133277</span>     <span class="number">3156</span>    <span class="number">2936</span>    <span class="number">6092</span></span><br><span class="line"><span class="number">15959002129</span>     <span class="number">1938</span>    <span class="number">180</span>     <span class="number">2118</span></span><br><span class="line"><span class="number">18271575951</span>     <span class="number">1527</span>    <span class="number">2106</span>    <span class="number">3633</span></span><br><span class="line"><span class="number">18390173782</span>     <span class="number">9531</span>    <span class="number">2412</span>    <span class="number">11943</span></span><br><span class="line"><span class="number">84188413</span>        <span class="number">4116</span>    <span class="number">1432</span>    <span class="number">5548</span></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt;</span><br></pre></td></tr></table></figure></div></details><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div></li></ol><h3 id="WritableComparable排序"><a href="#WritableComparable排序" class="headerlink" title="WritableComparable排序"></a>WritableComparable排序</h3><ul><li>排序是MapReduce框架中最重要的操作之一。</li><li>MapTask和ReduceTask均会对数据按照key进行排序。该操作属于Hadoop的默认行为。任何应用程序中的数据均会被排序，而不管逻辑上是否需要。</li><li>默认排序是按照字典顺序排序，且实现该排序的方法是快速排序。</li><li>对于MapTask，它会将处理的结果暂时放到环形缓冲区中，当环形缓冲区使用率达到一定阈值后，再对缓冲区中的数据进行一次快速排序，并将这些有序数据溢写到磁盘上，而当数据处理完毕后，它会对磁盘上所有文件进行归并排序。</li><li>对于ReduceTask，它从每个MapTask上远程拷贝相应的数据文件，如果文件大小超过一定阈值，则溢写磁盘上，否则存储在内存中。如果磁盘上文件数目达到一定阈值，则进行一次归并排序以生成一个更大文件；如果内存中文件大小或者数目超过一定阈值，则进行一次合并后将数据溢写到磁盘上。当所有数据拷贝完毕后，ReduceTask统一对内存和磁盘上的所有数据进行一次归并排序。</li></ul><ol><li><strong>排序的分类</strong><ul><li><strong>部分排序</strong>:MapReduce根据输入记录的键对数据集排序。保证输出的每个文件内部有序。</li><li><strong>全排序:</strong>最终输出结果只有一个文件，且文件内部有序。实现方式是只设置一个ReduceTask。但该方法在处理大型文件时效率极低，因为一台机器处理所有文件，完全丧失了MapReduce所提供的并行架构。</li><li><strong>辅助排序：</strong>（GroupingComparator分组） 在Reduce端对key进行分组。应用于：在接收的key为bean对象时，想让一个或几个字段相同（全部字段比较不相同）的key进入到同一个reduce方法时，可以采用分组排序。</li><li><strong>二次排序:</strong>在自定义排序过程中，如果compareTo中的判断条件为两个即为二次排序。</li></ul></li><li><strong>自定义排序WritableComparable</strong><br><strong>原理分析:</strong>bean对象做为key传输，需要实现WritableComparable接口重写compareTo方法，就可以实现排序。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(FlowBean o)</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="type">int</span> result;</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 按照总流量大小，倒序排列</span></span><br><span class="line">	<span class="keyword">if</span> (sumFlow &gt; bean.getSumFlow()) &#123;</span><br><span class="line">		result = -<span class="number">1</span>;</span><br><span class="line">	&#125;<span class="keyword">else</span> <span class="keyword">if</span> (sumFlow &lt; bean.getSumFlow()) &#123;</span><br><span class="line">		result = <span class="number">1</span>;</span><br><span class="line">	&#125;<span class="keyword">else</span> &#123;</span><br><span class="line">		result = <span class="number">0</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h3 id="WritableComparable排序案例实操（全排序）"><a href="#WritableComparable排序案例实操（全排序）" class="headerlink" title="WritableComparable排序案例实操（全排序）"></a>WritableComparable排序案例实操（全排序）</h3><ol><li>需求:根据案例12.2产生的结果再次对总流量进行排序。<div class="btns rounded grid5"><a class="button" target="_blank" rel="noopener" href="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/phone.txt" title="phone.txt"><i class="fas fa-book-open"></i> phone.txt</a></div></li><li>需求分析<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230603194438.png" alt=""></li><li>代码实现<div class="tabs" id="分栏4"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#分栏4-1">FlowBean.java</button></li><li class="tab"><button type="button" data-href="#分栏4-2">FlowCountSortMapper.java</button></li><li class="tab"><button type="button" data-href="#分栏4-3">FlowCountSortReducer.java</button></li><li class="tab"><button type="button" data-href="#分栏4-4">FlowCountSortDriver.java</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="分栏4-1"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.writablecomparable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataInput;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowBean</span> <span class="keyword">implements</span> <span class="title class_">WritableComparable</span>&lt;FlowBean&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> upFlow;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> downFlow;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> sumFlow;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">FlowBean</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">FlowBean</span><span class="params">(<span class="type">long</span> upFlow, <span class="type">long</span> downFlow, <span class="type">long</span> sumFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.upFlow = upFlow;</span><br><span class="line">        <span class="built_in">this</span>.downFlow = downFlow;</span><br><span class="line">        <span class="built_in">this</span>.sumFlow = sumFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getUpFlow</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> upFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setUpFlow</span><span class="params">(<span class="type">long</span> upFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.upFlow = upFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getDownFlow</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> downFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setDownFlow</span><span class="params">(<span class="type">long</span> downFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.downFlow = downFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getSumFlow</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> sumFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSumFlow</span><span class="params">(<span class="type">long</span> sumFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.sumFlow = sumFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> upFlow + <span class="string">&quot;\t&quot;</span> + downFlow + <span class="string">&quot;\t&quot;</span> + sumFlow;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(FlowBean o)</span> &#123;</span><br><span class="line">        <span class="type">int</span> result;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span>.sumFlow &gt; o.sumFlow) &#123;</span><br><span class="line">            result = -<span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">this</span>.sumFlow &lt; o.sumFlow) &#123;</span><br><span class="line">            result = <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            result = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        out.writeLong(upFlow);</span><br><span class="line">        out.writeLong(downFlow);</span><br><span class="line">        out.writeLong(sumFlow);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 反序列化方法 注意反序列化的顺序和序列化的顺序完全一致</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> in</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        upFlow = in.readLong();</span><br><span class="line">        downFlow = in.readLong();</span><br><span class="line">        sumFlow = in.readLong();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">set</span><span class="params">(<span class="type">long</span> upFlow, <span class="type">long</span> downFlow)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.upFlow = upFlow;</span><br><span class="line">        <span class="built_in">this</span>.downFlow = downFlow;</span><br><span class="line">        <span class="built_in">this</span>.sumFlow = upFlow + downFlow;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="分栏4-2"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.writablecomparable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowCountSortMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, FlowBean, Text&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">FlowBean</span> <span class="variable">bean</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FlowBean</span>();</span><br><span class="line">    <span class="type">Text</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span>	<span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 获取一行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 截取</span></span><br><span class="line">        String[] fields = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3 封装对象</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">phoneNbr</span> <span class="operator">=</span> fields[<span class="number">0</span>];</span><br><span class="line">        <span class="type">long</span> <span class="variable">upFlow</span> <span class="operator">=</span> Long.parseLong(fields[<span class="number">1</span>]);</span><br><span class="line">        <span class="type">long</span> <span class="variable">downFlow</span> <span class="operator">=</span> Long.parseLong(fields[<span class="number">2</span>]);</span><br><span class="line"></span><br><span class="line">        bean.set(upFlow, downFlow);</span><br><span class="line">        v.set(phoneNbr);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4 输出</span></span><br><span class="line">        context.write(bean, v);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="分栏4-3"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.writablecomparable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowCountSortReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;FlowBean, Text, Text, FlowBean&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(FlowBean key, Iterable&lt;Text&gt; values, Reducer&lt;FlowBean, Text, Text, FlowBean&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (Text value : values) &#123;</span><br><span class="line">            context.write(value, key);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="分栏4-4"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.writablecomparable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowCountSortDriver</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line"></span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\output\\part-r-00000&quot;</span>,</span><br><span class="line">                <span class="string">&quot;C:\\Users\\Administrator\\Desktop\\output1&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="comment">// 获取一个job</span></span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(configuration);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置jar包的位置</span></span><br><span class="line">        job.setJarByClass(FlowCountSortDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 关联map和reduce类</span></span><br><span class="line">        job.setMapperClass(FlowCountSortMapper.class);</span><br><span class="line">        job.setReducerClass(FlowCountSortReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置Map阶段输出的kv</span></span><br><span class="line">        job.setMapOutputKeyClass(FlowBean.class);</span><br><span class="line">        job.setMapOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置最终的输出的kv</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(FlowBean.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置文件输入输入的路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 提交job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(b ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><details class="folding-tag" green><summary>点击查看运行结果</summary><div class="content"><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output1&gt; <span class="built_in">ls</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    目录: C:\Users\Administrator\Desktop\output1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Mode                 LastWriteTime         Length Name</span><br><span class="line"><span class="literal">----</span>                 <span class="literal">-------------</span>         <span class="literal">------</span> <span class="literal">----</span></span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>     <span class="number">21</span>:<span class="number">16</span>             <span class="number">16</span> .part<span class="literal">-r-00000</span>.crc</span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>     <span class="number">21</span>:<span class="number">16</span>              <span class="number">8</span> ._SUCCESS.crc</span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>     <span class="number">21</span>:<span class="number">16</span>            <span class="number">550</span> part<span class="literal">-r-00000</span></span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">3</span>     <span class="number">21</span>:<span class="number">16</span>              <span class="number">0</span> _SUCCESS</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output1&gt; <span class="built_in">cat</span> .\part<span class="literal">-r-00000</span></span><br><span class="line"><span class="number">13509468723</span>     <span class="number">7335</span>    <span class="number">110349</span>  <span class="number">117684</span></span><br><span class="line"><span class="number">13975057813</span>     <span class="number">11058</span>   <span class="number">48243</span>   <span class="number">59301</span></span><br><span class="line"><span class="number">13568436656</span>     <span class="number">3597</span>    <span class="number">25635</span>   <span class="number">29232</span></span><br><span class="line"><span class="number">13736230513</span>     <span class="number">2481</span>    <span class="number">24681</span>   <span class="number">27162</span></span><br><span class="line"><span class="number">18390173782</span>     <span class="number">9531</span>    <span class="number">2412</span>    <span class="number">11943</span></span><br><span class="line"><span class="number">13630577991</span>     <span class="number">6960</span>    <span class="number">690</span>     <span class="number">7650</span></span><br><span class="line"><span class="number">15043685818</span>     <span class="number">3659</span>    <span class="number">3538</span>    <span class="number">7197</span></span><br><span class="line"><span class="number">13992314666</span>     <span class="number">3008</span>    <span class="number">3720</span>    <span class="number">6728</span></span><br><span class="line"><span class="number">15910133277</span>     <span class="number">3156</span>    <span class="number">2936</span>    <span class="number">6092</span></span><br><span class="line"><span class="number">13560439638</span>     <span class="number">918</span>     <span class="number">4938</span>    <span class="number">5856</span></span><br><span class="line"><span class="number">84188413</span>        <span class="number">4116</span>    <span class="number">1432</span>    <span class="number">5548</span></span><br><span class="line"><span class="number">13682846555</span>     <span class="number">1938</span>    <span class="number">2910</span>    <span class="number">4848</span></span><br><span class="line"><span class="number">18271575951</span>     <span class="number">1527</span>    <span class="number">2106</span>    <span class="number">3633</span></span><br><span class="line"><span class="number">15959002129</span>     <span class="number">1938</span>    <span class="number">180</span>     <span class="number">2118</span></span><br><span class="line"><span class="number">13590439668</span>     <span class="number">1116</span>    <span class="number">954</span>     <span class="number">2070</span></span><br><span class="line"><span class="number">13956435636</span>     <span class="number">132</span>     <span class="number">1512</span>    <span class="number">1644</span></span><br><span class="line"><span class="number">13470253144</span>     <span class="number">180</span>     <span class="number">180</span>     <span class="number">360</span></span><br><span class="line"><span class="number">13846544121</span>     <span class="number">264</span>     <span class="number">0</span>       <span class="number">264</span></span><br><span class="line"><span class="number">13729199489</span>     <span class="number">240</span>     <span class="number">0</span>       <span class="number">240</span></span><br><span class="line"><span class="number">13768778790</span>     <span class="number">120</span>     <span class="number">120</span>     <span class="number">240</span></span><br><span class="line"><span class="number">13966251146</span>     <span class="number">240</span>     <span class="number">0</span>       <span class="number">240</span></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output1&gt;</span><br></pre></td></tr></table></figure></div></details><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div></li></ol><h3 id="WritableComparable排序案例实操（区内排序）"><a href="#WritableComparable排序案例实操（区内排序）" class="headerlink" title="WritableComparable排序案例实操（区内排序）"></a>WritableComparable排序案例实操（区内排序）</h3><ol><li>需求:要求每个省份手机号输出的文件中按照总流量内部排序。</li><li>需求分析:基于前一个需求，增加自定义分区类，分区按照省份手机号设置。<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230603212158.png" alt=""></li><li>案例实操<ul><li><strong>增加自定义分区类</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">package</span> cn.jermyn.mr.writablecomparable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Partitioner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ProvincePartitioner</span> <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;FlowBean, Text&gt; &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(FlowBean flowBean, Text value, <span class="type">int</span> numPartitions)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> <span class="variable">partition</span> <span class="operator">=</span> <span class="number">4</span>;</span><br><span class="line">        <span class="comment">// 获取手机号前3位</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">pre3OfPhoneNum</span> <span class="operator">=</span> value.toString().substring(<span class="number">0</span>, <span class="number">3</span>);</span><br><span class="line">        <span class="keyword">if</span> (<span class="string">&quot;136&quot;</span>.equals(pre3OfPhoneNum)) &#123;</span><br><span class="line">            partition = <span class="number">0</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;137&quot;</span>.equals(pre3OfPhoneNum)) &#123;</span><br><span class="line">            partition = <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;138&quot;</span>.equals(pre3OfPhoneNum)) &#123;</span><br><span class="line">            partition = <span class="number">2</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">&quot;139&quot;</span>.equals(pre3OfPhoneNum)) &#123;</span><br><span class="line">            partition = <span class="number">3</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> partition;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><strong>在驱动类中添加分区类</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">// 加载自定义分区类</span></span><br><span class="line">job.setPartitionerClass(ProvincePartitioner.class);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置Reducetask个数</span></span><br><span class="line">job.setNumReduceTasks(<span class="number">5</span>);</span><br></pre></td></tr></table></figure></li></ul></li></ol><h3 id="Combiner合并-优化"><a href="#Combiner合并-优化" class="headerlink" title="Combiner合并(优化)"></a>Combiner合并(优化)</h3><ol><li>Combiner是MR程序中Mapper和Reducer之外的一种组件。</li><li>Combiner组件的父类就是Reducer。</li><li>Combiner和Reducer的区别在于运行的位置<ol><li>Combiner是在每一个MapTask所在的节点运行;</li><li>Reducer是接收全局所有Mapper的输出结果；</li></ol></li><li>Combiner的意义就是对每一个MapTask的输出进行局部汇总，以减小网络传输量。</li><li>Combiner能够应用的前提是不能影响最终的业务逻辑，而且，Combiner的输出kv应该跟Reducer的输入kv类型要对应起来。</li><li>自定义Combiner实现步骤:1.自定义一个Combiner继承Reducer，重写Reduce方法 2. 在Job驱动类中设置<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordcountCombiner</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text,IntWritable&gt;&#123;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values,Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 汇总操作</span></span><br><span class="line">		<span class="type">int</span> <span class="variable">count</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">for</span>(IntWritable v :values)&#123;</span><br><span class="line">			count += v.get();</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 写出</span></span><br><span class="line">		context.write(key, <span class="keyword">new</span> <span class="title class_">IntWritable</span>(count));</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setCombinerClass(WordcountCombiner.class);</span><br></pre></td></tr></table></figure></li></ol><h3 id="Combiner合并案例实操"><a href="#Combiner合并案例实操" class="headerlink" title="Combiner合并案例实操"></a>Combiner合并案例实操</h3><ol><li>需求:统计过程中对每一个MapTask的输出进行局部汇总，以减小网络传输量即采用Combiner功能。<div class="btns rounded grid5"><a class="button" target="_blank" rel="noopener" href="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/combiner.txt" title="combiner.txt"><i class="fas fa-book-open"></i> combiner.txt</a></div></li><li>需求分析<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230604092204.png" alt=""></li><li>案例实操-方案一<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.wordcount;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountCombiner</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line">    <span class="type">IntWritable</span> <span class="variable">v</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Reducer&lt;Text, IntWritable, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 累加求和</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (IntWritable value : values) &#123;</span><br><span class="line">            sum += value.get();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        v.set(sum);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 写出</span></span><br><span class="line">        context.write(key, v);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>在WordcountDriver驱动类中指定Combiner<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 指定需要使用combiner，以及用哪个类作为combiner的逻辑</span></span><br><span class="line">job.setCombinerClass(WordcountCombiner.class);</span><br></pre></td></tr></table></figure></li><li>案例实操-方案二<br>将WordcountReducer作为Combiner在WordcountDriver驱动类中指定<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 指定需要使用Combiner，以及用哪个类作为Combiner的逻辑</span></span><br><span class="line">job.setCombinerClass(WordcountReducer.class);</span><br></pre></td></tr></table></figure></li></ol><h3 id="GroupingComparator分组（辅助排序）"><a href="#GroupingComparator分组（辅助排序）" class="headerlink" title="GroupingComparator分组（辅助排序）"></a>GroupingComparator分组（辅助排序）</h3><ul><li>对Reduce阶段的数据根据某一个或几个字段进行分组。</li><li>分组排序步骤：<ul><li>自定义类继承WritableComparator</li><li>重写compare()方法<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compare</span><span class="params">(WritableComparable a, WritableComparable b)</span> &#123;</span><br><span class="line">		<span class="comment">// 比较的业务逻辑</span></span><br><span class="line">		<span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>创建一个构造将比较对象的类传给父类<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="title function_">OrderGroupingComparator</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="built_in">super</span>(OrderBean.class, <span class="literal">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="GroupingComparator分组案例实操"><a href="#GroupingComparator分组案例实操" class="headerlink" title="GroupingComparator分组案例实操"></a>GroupingComparator分组案例实操</h3><ol><li>需求:有如下订单数据<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230604114701.png" alt=""><br>现在需要求出每一个订单中最贵的商品。</li><li>需求分析<ol><li>利用“订单id和成交金额”作为key，可以将Map阶段读取到的所有订单数据按照id升序排序，如果id相同再按照金额降序排序，发送到Reduce。</li><li>在Reduce端利用groupingComparator将订单id相同的kv聚合成组，然后取第一个即是该订单中最贵商品，<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230604114834.png" alt=""></li></ol></li><li>代码实现<div class="tabs" id="5分栏"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#5分栏-1">OrderBean.java</button></li><li class="tab"><button type="button" data-href="#5分栏-2">OrderMapper.java</button></li><li class="tab"><button type="button" data-href="#5分栏-3">OrderReducer</button></li><li class="tab"><button type="button" data-href="#5分栏-4">OrderGroupingComparator.java</button></li><li class="tab"><button type="button" data-href="#5分栏-5">OrderDriver.java</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="5分栏-1"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.order;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataInput;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderBean</span>  <span class="keyword">implements</span> <span class="title class_">WritableComparable</span>&lt;OrderBean&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> id;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">double</span> price;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">OrderBean</span><span class="params">(<span class="type">int</span> id, <span class="type">double</span> price)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.id = id;</span><br><span class="line">        <span class="built_in">this</span>.price = price;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">OrderBean</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getId</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setId</span><span class="params">(<span class="type">int</span> id)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.id = id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">double</span> <span class="title function_">getPrice</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> price;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setPrice</span><span class="params">(<span class="type">double</span> price)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.price = price;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> id + <span class="string">&quot;\t&quot;</span> + price;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(OrderBean o)</span> &#123;</span><br><span class="line">        <span class="comment">// 按照id升二次排序是价格降</span></span><br><span class="line">        <span class="type">int</span> result;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span>.id &gt; o.id) &#123;</span><br><span class="line">            result = <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">this</span>.id &lt; o.id) &#123;</span><br><span class="line">            result = -<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            result = Double.compare(o.price, <span class="built_in">this</span>.price);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        out.writeInt(id);</span><br><span class="line">        out.writeDouble(price);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        id = in.readInt();</span><br><span class="line">        price = in.readDouble();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="5分栏-2"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.order;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, OrderBean, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">OrderBean</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">OrderBean</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, OrderBean, NullWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取一行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">string</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 切割</span></span><br><span class="line">        String[] fields = string.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 封装</span></span><br><span class="line">        k.setId(Integer.parseInt(fields[<span class="number">0</span>]));</span><br><span class="line">        k.setPrice(Double.parseDouble(fields[<span class="number">2</span>]));</span><br><span class="line">        context.write(k, NullWritable.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="5分栏-3"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.order;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;OrderBean, NullWritable, OrderBean, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(OrderBean key, Iterable&lt;NullWritable&gt; values, Reducer&lt;OrderBean, NullWritable, OrderBean, NullWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        context.write(key,NullWritable.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="5分栏-4"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.order;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparator;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderGroupingComparator</span> <span class="keyword">extends</span> <span class="title class_">WritableComparator</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">protected</span> <span class="title function_">OrderGroupingComparator</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>(OrderBean.class, <span class="literal">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compare</span><span class="params">(WritableComparable a, WritableComparable b)</span> &#123;</span><br><span class="line">        <span class="type">OrderBean</span> <span class="variable">aBean</span> <span class="operator">=</span> (OrderBean) a;</span><br><span class="line">        <span class="type">OrderBean</span> <span class="variable">bBean</span> <span class="operator">=</span> (OrderBean) b;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> result;</span><br><span class="line">        <span class="keyword">if</span> (aBean.getId() &gt; bBean.getId()) &#123;</span><br><span class="line">            result = <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (aBean.getId() &lt; bBean.getId()) &#123;</span><br><span class="line">            result = -<span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            result = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="5分栏-5"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.order;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderDriver</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line"></span><br><span class="line">        args=<span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\input\\GroupingComparator.txt&quot;</span>,</span><br><span class="line">                <span class="string">&quot;C:\\Users\\Administrator\\Desktop\\output&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">entries</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="comment">// 获取一个job</span></span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(entries);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置jar的位置</span></span><br><span class="line">        job.setJarByClass(OrderDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 关联mapper 和reducer类</span></span><br><span class="line">        job.setMapperClass(OrderMapper.class);</span><br><span class="line">        job.setReducerClass(OrderReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置map阶段输出的kv数据类型</span></span><br><span class="line">        job.setMapOutputKeyClass(OrderBean.class);</span><br><span class="line">        job.setMapOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置最终阶段输出的kv数据类型</span></span><br><span class="line">        job.setOutputKeyClass(OrderBean.class);</span><br><span class="line">        job.setOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置文件输入输出的位置</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        job.setGroupingComparatorClass(OrderGroupingComparator.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 提交job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(b ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><details class="folding-tag" green><summary>点击查看运行结果</summary><div class="content"><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">ls</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    目录: C:\Users\Administrator\Desktop\output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Mode                 LastWriteTime         Length Name</span><br><span class="line"><span class="literal">----</span>                 <span class="literal">-------------</span>         <span class="literal">------</span> <span class="literal">----</span></span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">4</span>     <span class="number">11</span>:<span class="number">03</span>             <span class="number">12</span> .part<span class="literal">-r-00000</span>.crc</span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">4</span>     <span class="number">11</span>:<span class="number">03</span>              <span class="number">8</span> ._SUCCESS.crc</span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">4</span>     <span class="number">11</span>:<span class="number">03</span>             <span class="number">24</span> part<span class="literal">-r-00000</span></span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">4</span>     <span class="number">11</span>:<span class="number">03</span>              <span class="number">0</span> _SUCCESS</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">cat</span> .\part<span class="literal">-r-00000</span></span><br><span class="line"><span class="number">1</span>       <span class="number">222.8</span></span><br><span class="line"><span class="number">2</span>       <span class="number">722.4</span></span><br><span class="line"><span class="number">3</span>       <span class="number">232.8</span></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt;</span><br></pre></td></tr></table></figure></div></details><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div></li></ol><h2 id="MapTask工作机制"><a href="#MapTask工作机制" class="headerlink" title="MapTask工作机制"></a>MapTask工作机制</h2><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230604121320.png" alt=""><br></p><div class="timeline green"><div class="timeline-item headline"><div class="timeline-item-title"><div class="item-circle"><p>MapTask工作机制</p></div></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第1步</p></div></div><div class="timeline-item-content"><p>Read阶段：MapTask通过用户编写的RecordReader，从输入InputSplit中解析出一个个key/value。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第2步</p></div></div><div class="timeline-item-content"><p>Map阶段：该节点主要是将解析出的key/value交给用户编写map()函数处理，并产生一系列新的key/value。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第3步</p></div></div><div class="timeline-item-content"><p>Collect收集阶段：在用户编写map()函数中，当数据处理完成后，一般会调用OutputCollector.collect()输出结果。在该函数内部，它会将生成的key/value分区（调用Partitioner），并写入一个环形内存缓冲区中。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第4步</p></div></div><div class="timeline-item-content"><p>Spill阶段：即“溢写”，当环形缓冲区满后，MapReduce会将数据写到本地磁盘上，生成一个临时文件。需要注意的是，将数据写入本地磁盘之前，先要对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。<br>溢写阶段详情：<br>步骤1：利用快速排序算法对缓存区内的数据进行排序，排序方式是，先按照分区编号Partition进行排序，然后按照key进行排序。这样，经过排序后，数据以分区为单位聚集在一起，且同一分区内所有数据按照key有序。<br>步骤2：按照分区编号由小到大依次将每个分区中的数据写入任务工作目录下的临时文件output/spillN.out（N表示当前溢写次数）中。如果用户设置了Combiner，则写入文件之前，对每个分区中的数据进行一次聚集操作。<br>步骤3：将分区数据的元信息写到内存索引数据结构SpillRecord中，其中每个分区的元信息包括在临时文件中的偏移量、压缩前数据大小和压缩后数据大小。如果当前内存索引大小超过1MB，则将内存索引写到文件output/spillN.out.index中。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第5步</p></div></div><div class="timeline-item-content"><p>Combine阶段：当所有数据处理完成后，MapTask对所有临时文件进行一次合并，以确保最终只会生成一个数据文件。<br>当所有数据处理完后，MapTask会将所有临时文件合并成一个大文件，并保存到文件output/file.out中，同时生成相应的索引文件output/file.out.index。<br>在进行文件合并过程中，MapTask以分区为单位进行合并。对于某个分区，它将采用多轮递归合并的方式。每轮合并io.sort.factor（默认10）个文件，并将产生的文件重新加入待合并列表中，对文件排序后，重复以上过程，直到最终得到一个大文件。<br>让每个MapTask最终只生成一个数据文件，可避免同时打开大量文件和同时读取大量小文件产生的随机读取带来的开销。</p></div></div></div><p></p><h2 id="ReduceTask工作机制"><a href="#ReduceTask工作机制" class="headerlink" title="ReduceTask工作机制"></a>ReduceTask工作机制</h2><ol><li>ReduceTask工作机制<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230604151032.png" alt=""><div class="timeline green"><div class="timeline-item headline"><div class="timeline-item-title"><div class="item-circle"><p>ReduceTask工作机制</p></div></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第1步</p></div></div><div class="timeline-item-content"><p>Copy阶段：ReduceTask从各个MapTask上远程拷贝一片数据，并针对某一片数据，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第2步</p></div></div><div class="timeline-item-content"><p>Merge阶段：在远程拷贝数据的同时，ReduceTask启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或磁盘上文件过多。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第3步</p></div></div><div class="timeline-item-content"><p>Sort阶段：按照MapReduce语义，用户编写reduce()函数输入数据是按key进行聚集的一组数据。为了将key相同的数据聚在一起，Hadoop采用了基于排序的策略。由于各个MapTask已经实现对自己的处理结果进行了局部排序，因此，ReduceTask只需对所有数据进行一次归并排序即可。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第4步</p></div></div><div class="timeline-item-content"><p>Reduce阶段：reduce()函数将计算结果写到HDFS上。</p></div></div></div></li><li>设置ReduceTask并行度（个数）<br>ReduceTask的并行度同样影响整个Job的执行并发度和执行效率，但与MapTask的并发数由切片数决定不同，ReduceTask数量的决定是可以直接手动设置：<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 默认值是1，手动设置为4</span></span><br><span class="line">job.setNumReduceTasks(<span class="number">4</span>);</span><br></pre></td></tr></table></figure></li><li>注意事项<ol><li>ReduceTask=0，表示没有Reduce阶段，输出文件个数和Map个数一致。</li><li>ReduceTask默认值就是1，所以输出文件个数为一个。</li><li>如果数据分布不均匀，就有可能在Reduce阶段产生数据倾斜</li><li>ReduceTask数量并不是任意设置，还要考虑业务逻辑需求，有些情况下，需要计算全局汇总结果，就只能有1个ReduceTask。</li><li>具体多少个ReduceTask，需要根据集群性能而定。</li><li>如果分区数不是1，但是ReduceTask为1，是否执行分区过程。答案是：不执行分区过程。因为在MapTask的源码中，执行分区的前提是先判断ReduceNum个数是否大于1。不大于1肯定不执行。</li></ol></li></ol><h2 id="OutputFormat数据输出"><a href="#OutputFormat数据输出" class="headerlink" title="OutputFormat数据输出"></a>OutputFormat数据输出</h2><h3 id="OutputFormat接口实现类"><a href="#OutputFormat接口实现类" class="headerlink" title="OutputFormat接口实现类"></a>OutputFormat接口实现类</h3><p>OutputFormat是MapReduce输出的基类，所有实现MapReduce输出都实现了 OutputFormat接口。</p><ol><li>文本输出TextOutputFormat<br>默认的输出格式是TextOutputFormat，它把每条记录写为文本行。它的键和值可以是任意类型，因为TextOutputFormat调用toString()方法把它们转换为字符串。</li><li>SequenceFileOutputFormat<br>将SequenceFileOutputFormat输出作为后续 MapReduce任务的输入，这便是一种好的输出格式，因为它的格式紧凑，很容易被压缩。</li><li>自定义OutputFormat<br>根据用户需求，自定义实现输出。</li></ol><h3 id="自定义OutputFormat"><a href="#自定义OutputFormat" class="headerlink" title="自定义OutputFormat"></a>自定义OutputFormat</h3><ol><li>使用场景<br>为了实现控制最终文件的输出路径和输出格式，可以自定义OutputFormat。<br>例如：要在一个MapReduce程序中根据数据的不同输出两类结果到不同目录，这类灵活的输出需求可以通过自定义OutputFormat来实现。</li><li>自定义OutputFormat步骤<ol><li>自定义一个类继承FileOutputFormat。</li><li>改写RecordWriter，具体改写输出数据的方法write()。</li></ol></li></ol><h3 id="自定义OutputFormat案例实操"><a href="#自定义OutputFormat案例实操" class="headerlink" title="自定义OutputFormat案例实操"></a>自定义OutputFormat案例实操</h3><ol><li>需求:过滤输入的log日志，包含jermyn的网站输出到C:\Users\Administrator\Desktop\output\jermyn，不包含jermyn的网站输出到C:\Users\Administrator\Desktop\output\others。<div class="btns rounded grid5"><a class="button" target="_blank" rel="noopener" href="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/log.txt" title="log.txt"><i class="fas fa-book-open"></i> log.txt</a></div></li><li>需求分析<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230604154644.png" alt=""></li><li>案例实操<div class="tabs" id="5分栏"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#5分栏-1">FRecordWriter</button></li><li class="tab"><button type="button" data-href="#5分栏-2">OutputFormat.java</button></li><li class="tab"><button type="button" data-href="#5分栏-3">FilterReducer.java</button></li><li class="tab"><button type="button" data-href="#5分栏-4">FilterMapper.java</button></li><li class="tab"><button type="button" data-href="#5分栏-5">FilterDriver.java</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="5分栏-1"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.outputformat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataOutputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.RecordWriter;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.TaskAttemptContext;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FRecordWriter</span> <span class="keyword">extends</span> <span class="title class_">RecordWriter</span>&lt;Text, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    FSDataOutputStream fosAtJermyn;</span><br><span class="line">    FSDataOutputStream fosAtOther;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">FRecordWriter</span><span class="params">(TaskAttemptContext job)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 1 获取文件系统</span></span><br><span class="line">            <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(job.getConfiguration());</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 2 创建输出到jermyn.log的输出流</span></span><br><span class="line"></span><br><span class="line">            fosAtJermyn = fs.create(</span><br><span class="line">                    <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\output\\jermyn\\jermyn.log&quot;</span>));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 3 创建输出到other.log的输出流</span></span><br><span class="line">            fosAtOther = fs.create(</span><br><span class="line">                    <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\output\\other\\other.log&quot;</span>));</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(Text key, NullWritable value)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 判断key中是否有jermyn，有的话写出到jermyn.log 没有的话就写到other.log</span></span><br><span class="line">        <span class="keyword">if</span> (key.toString().contains(<span class="string">&quot;jermyn&quot;</span>)) &#123;</span><br><span class="line">            <span class="comment">//jermyn输出流</span></span><br><span class="line">            fosAtJermyn.write(key.toString().getBytes());</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//other输出流</span></span><br><span class="line">            fosAtOther.write(key.toString().getBytes());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">(TaskAttemptContext context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        IOUtils.closeStream(fosAtJermyn);</span><br><span class="line">        IOUtils.closeStream(fosAtOther);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="5分栏-2"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.outputformat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.RecordWriter;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.TaskAttemptContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OutputFormat</span> <span class="keyword">extends</span> <span class="title class_">FileOutputFormat</span>&lt;Text, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> RecordWriter&lt;Text, NullWritable&gt; <span class="title function_">getRecordWriter</span><span class="params">(TaskAttemptContext job)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">FRecordWriter</span>(job);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="5分栏-3"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.outputformat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FilterReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, NullWritable, Text, NullWritable&gt; &#123;</span><br><span class="line">    <span class="type">Text</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;NullWritable&gt; values, Reducer&lt;Text, NullWritable, Text, NullWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">string</span> <span class="operator">=</span> key.toString();</span><br><span class="line">        string = string + <span class="string">&quot;\n&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (NullWritable nu : values) &#123;</span><br><span class="line">            k.set(string);</span><br><span class="line">            context.write(k, NullWritable.get());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="5分栏-4"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.outputformat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FilterMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, NullWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        context.write(value,NullWritable.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="5分栏-5"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.outputformat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FilterDriver</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException &#123;</span><br><span class="line"></span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\input\\log.txt&quot;</span>,</span><br><span class="line">                <span class="string">&quot;C:\\Users\\Administrator\\Desktop\\output&quot;</span>&#125;;</span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">entries</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="comment">// 获取一个job</span></span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(entries);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置jar的路径</span></span><br><span class="line">        job.setJarByClass(FilterDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 关联mapper和reducer</span></span><br><span class="line">        job.setMapperClass(FilterMapper.class);</span><br><span class="line">        job.setReducerClass(FilterReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 要将自定义的输出格式组件设置到job中</span></span><br><span class="line">        job.setOutputFormatClass(OutputFormat.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置map阶段输出的kv数据类型</span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置最终阶段输出的kv数据类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置文件的输入输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 提交job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(b ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><details class="folding-tag" green><summary>点击查看运行结果</summary><div class="content"><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output\jermyn&gt; <span class="built_in">ls</span></span><br><span class="line">    目录: C:\Users\Administrator\Desktop\output\jermyn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Mode                 LastWriteTime         Length Name</span><br><span class="line"><span class="literal">----</span>                 <span class="literal">-------------</span>         <span class="literal">------</span> <span class="literal">----</span></span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">4</span>     <span class="number">16</span>:<span class="number">56</span>             <span class="number">12</span> .jermyn.log.crc</span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">4</span>     <span class="number">16</span>:<span class="number">56</span>             <span class="number">43</span> jermyn.log</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output\jermyn&gt; <span class="built_in">cat</span> .\jermyn.log</span><br><span class="line">http://www.jermyn.cn</span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output\jermyn&gt; <span class="built_in">cd</span> ..</span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">ls</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    目录: C:\Users\Administrator\Desktop\output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Mode                 LastWriteTime         Length Name</span><br><span class="line"><span class="literal">----</span>                 <span class="literal">-------------</span>         <span class="literal">------</span> <span class="literal">----</span></span><br><span class="line">d<span class="literal">-----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">4</span>     <span class="number">16</span>:<span class="number">56</span>                jermyn</span><br><span class="line">d<span class="literal">-----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">4</span>     <span class="number">16</span>:<span class="number">56</span>                other</span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">4</span>     <span class="number">16</span>:<span class="number">56</span>              <span class="number">8</span> ._SUCCESS.crc</span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">4</span>     <span class="number">16</span>:<span class="number">56</span>              <span class="number">0</span> _SUCCESS</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">cd</span> .\other\</span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output\other&gt; <span class="built_in">ls</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    目录: C:\Users\Administrator\Desktop\output\other</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Mode                 LastWriteTime         Length Name</span><br><span class="line"><span class="literal">----</span>                 <span class="literal">-------------</span>         <span class="literal">------</span> <span class="literal">----</span></span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">4</span>     <span class="number">16</span>:<span class="number">56</span>             <span class="number">12</span> .other.log.crc</span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">4</span>     <span class="number">16</span>:<span class="number">56</span>            <span class="number">171</span> other.log</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output\other&gt; <span class="built_in">cat</span> .\other.log</span><br><span class="line">http://cn.bing.com</span><br><span class="line">http://www.baidu.com</span><br><span class="line">http://www.google.com</span><br><span class="line">http://www.sin2a.com</span><br><span class="line">http://www.sin2desa.com</span><br><span class="line">http://www.sina.com</span><br><span class="line">http://www.sindsafa.com</span><br><span class="line">http://www.sohu.com</span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output\other&gt;</span><br></pre></td></tr></table></figure></div></details><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div></li></ol><h2 id="Join多种应用"><a href="#Join多种应用" class="headerlink" title="Join多种应用"></a>Join多种应用</h2><h3 id="Reduce-Join"><a href="#Reduce-Join" class="headerlink" title="Reduce Join"></a>Reduce Join</h3><ul><li><strong>Reduce Join工作原理</strong><ul><li>Map端的主要工作：为来自不同表或文件的key/value对，打标签以区别不同来源的记录。然后用连接字段作为key，其余部分和新加的标志作为value，最后进行输出。</li><li>Reduce端的主要工作：在Reduce端以连接字段作为key的分组已经完成，我们只需要在每一个分组当中将那些来源于不同文件的记录(在Map阶段已经打标志)分开，最后进行合并就ok了。</li></ul></li></ul><h3 id="Reduce-Join案例实操"><a href="#Reduce-Join案例实操" class="headerlink" title="Reduce Join案例实操"></a>Reduce Join案例实操</h3><ol><li>需求<div class="btns rounded grid5"><a class="button" target="_blank" rel="noopener" href="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/order.txt" title="order.txt"><i class="fas fa-book-open"></i> order.txt</a></div><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">订单数据表t_order</span><br><span class="line">id	pid	amount</span><br><span class="line">1001	01	1</span><br><span class="line">1002	02	2</span><br><span class="line">1003	03	3</span><br><span class="line">1004	01	4</span><br><span class="line">1005	02	5</span><br><span class="line">1006	03	6</span><br></pre></td></tr></table></figure><div class="btns rounded grid5"><a class="button" target="_blank" rel="noopener" href="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/pd.txt" title="pd.txt"><i class="fas fa-book-open"></i> pd.txt</a></div><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">商品信息表t_product</span><br><span class="line">pid	pname</span><br><span class="line">01	小米</span><br><span class="line">02	华为</span><br><span class="line">03	格力</span><br></pre></td></tr></table></figure>将商品信息表中数据根据商品pid合并到订单数据表中。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">最终数据形式</span><br><span class="line">id	pname	amount</span><br><span class="line">1001	小米	1</span><br><span class="line">1004	小米	4</span><br><span class="line">1002	华为	2</span><br><span class="line">1005	华为	5</span><br><span class="line">1003	格力	3</span><br><span class="line">1006	格力	6</span><br></pre></td></tr></table></figure></li><li>需求分析<br>通过将关联条件作为Map输出的key，将两表满足Join条件的数据并携带数据所来源的文件信息，发往同一个ReduceTask，在Reduce中进行数据的串联<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230604171410.png" alt=""></li><li>代码实现<div class="tabs" id="4分栏"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#4分栏-1">TableBean.java</button></li><li class="tab"><button type="button" data-href="#4分栏-2">TableMapper.java</button></li><li class="tab"><button type="button" data-href="#4分栏-3">TableReducer.java</button></li><li class="tab"><button type="button" data-href="#4分栏-4">TableDriver.java</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="4分栏-1"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.table;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Writable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataInput;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TableBean</span> <span class="keyword">implements</span> <span class="title class_">Writable</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String id; <span class="comment">// 订单号</span></span><br><span class="line">    <span class="keyword">private</span> String pid; <span class="comment">// 产品号</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> amount; <span class="comment">// 产品数量</span></span><br><span class="line">    <span class="keyword">private</span> String pName; <span class="comment">// 产品名称</span></span><br><span class="line">    <span class="keyword">private</span> String flag;  <span class="comment">// 表的名称</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">TableBean</span><span class="params">()</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">TableBean</span><span class="params">(String id, String pid, <span class="type">int</span> amount, String pName, String flag)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.id = id;</span><br><span class="line">        <span class="built_in">this</span>.pid = pid;</span><br><span class="line">        <span class="built_in">this</span>.amount = amount;</span><br><span class="line">        <span class="built_in">this</span>.pName = pName;</span><br><span class="line">        <span class="built_in">this</span>.flag = flag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *  序列化</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> out &lt;code&gt;DataOuput&lt;/code&gt; to serialize this object into.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        out.writeUTF(id);</span><br><span class="line">        out.writeUTF(pid);</span><br><span class="line">        out.writeInt(amount);</span><br><span class="line">        out.writeUTF(pName);</span><br><span class="line">        out.writeUTF(flag);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *  反序列化,注意和序列的顺序一致</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> in &lt;code&gt;DataInput&lt;/code&gt; to deseriablize this object from.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        id=in.readUTF();</span><br><span class="line">        pid=in.readUTF();</span><br><span class="line">        amount=in.readInt();</span><br><span class="line">        pName=in.readUTF();</span><br><span class="line">        flag=in.readUTF();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getId</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setId</span><span class="params">(String id)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.id = id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getPid</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> pid;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setPid</span><span class="params">(String pid)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.pid = pid;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getAmount</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> amount;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setAmount</span><span class="params">(<span class="type">int</span> amount)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.amount = amount;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getpName</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> pName;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setpName</span><span class="params">(String pName)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.pName = pName;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getFlag</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> flag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setFlag</span><span class="params">(String flag)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.flag = flag;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> id + <span class="string">&quot;\t&quot;</span> + pName + <span class="string">&quot;\t&quot;</span> + amount + <span class="string">&quot;\t&quot;</span> ;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="4分栏-2"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.table;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileSplit;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TableMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, TableBean&gt; &#123;</span><br><span class="line">    String name;</span><br><span class="line">    <span class="type">TableBean</span> <span class="variable">tableBean</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TableBean</span>();</span><br><span class="line">    <span class="type">Text</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *  启动 maptask 会先执行setup加载配置信息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">setup</span><span class="params">(Mapper&lt;LongWritable, Text, Text, TableBean&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 因为我们有两个文件，默认情况下会分两个切片，也是两个maptask，</span></span><br><span class="line">        <span class="comment">// 可以通过切片获取到文件的传入路径，进而得到文件名（即订单名）</span></span><br><span class="line">        <span class="type">FileSplit</span> <span class="variable">inputSplit</span> <span class="operator">=</span> (FileSplit) context.getInputSplit();</span><br><span class="line">        name = inputSplit.getPath().getName();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, TableBean&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取一行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 得到文件名后和&quot;order&quot;,&quot;pb&quot;相匹配目的是new出相对应的实例对象，用来封装，</span></span><br><span class="line">        <span class="comment">// 获取相应字段，按照order和pb</span></span><br><span class="line">        <span class="keyword">if</span> (name.startsWith(<span class="string">&quot;order&quot;</span>)) &#123;</span><br><span class="line">            String[] fields = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">            tableBean.setId(fields[<span class="number">0</span>]);</span><br><span class="line">            tableBean.setPid(fields[<span class="number">1</span>]);</span><br><span class="line">            tableBean.setAmount(Integer.parseInt(fields[<span class="number">2</span>]));</span><br><span class="line">            tableBean.setpName(<span class="string">&quot;&quot;</span>);</span><br><span class="line">            tableBean.setFlag(<span class="string">&quot;order&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 根据商品pid合并到订单数据表中，所以以pid为key，TableBean实例为value</span></span><br><span class="line">            k.set(fields[<span class="number">1</span>]);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            String[] fields = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">            tableBean.setId(<span class="string">&quot;&quot;</span>);</span><br><span class="line">            tableBean.setPid(fields[<span class="number">0</span>]);</span><br><span class="line">            tableBean.setAmount(<span class="number">0</span>);</span><br><span class="line">            tableBean.setpName(fields[<span class="number">1</span>]);</span><br><span class="line">            tableBean.setFlag(<span class="string">&quot;pd&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 根据商品pid合并到订单数据表中，所以以pid为key，TableBean实例为value</span></span><br><span class="line">            k.set(fields[<span class="number">0</span>]);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 封装</span></span><br><span class="line">        context.write(k, tableBean);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="4分栏-3"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.table;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.beanutils.BeanUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.InvocationTargetException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TableReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, TableBean, TableBean, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;TableBean&gt; values, Reducer&lt;Text, TableBean, TableBean, NullWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 对于一个商品信息表可以有多个订单表，所以封装TableBean实例封装数组</span></span><br><span class="line">        ArrayList&lt;TableBean&gt; orderBeans = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 商品信息表只有一个</span></span><br><span class="line">        <span class="type">TableBean</span> <span class="variable">pdBean</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TableBean</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 此时的values中是一个的TableBean对象，包含order和pb</span></span><br><span class="line">        <span class="keyword">for</span> (TableBean tableBean : values) &#123;</span><br><span class="line">            <span class="comment">// 如果实例对象的flag是order，需要将其添加到orderBeans中</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="string">&quot;order&quot;</span>.equals(tableBean.getFlag())) &#123;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 在迭代器中的value存储的地址，不可以直接添加到数组</span></span><br><span class="line">                <span class="type">TableBean</span> <span class="variable">tmpBean</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TableBean</span>();</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">// 通过工具类来进行拷贝</span></span><br><span class="line">                    BeanUtils.copyProperties(tmpBean, tableBean);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (IllegalAccessException | InvocationTargetException e) &#123;</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 添加到数组中</span></span><br><span class="line">                orderBeans.add(tmpBean);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 如果实例对象的flag是pb</span></span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">// 直接进行拷贝</span></span><br><span class="line">                    BeanUtils.copyProperties(pdBean, tableBean);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (IllegalAccessException | InvocationTargetException e) &#123;</span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 遍历订单表构成的数组，把每个orderBean实例的pname属性，设置为相同pid的name</span></span><br><span class="line">        <span class="keyword">for</span> (TableBean orderBean : orderBeans) &#123;</span><br><span class="line">            orderBean.setpName(pdBean.getpName());</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 封装</span></span><br><span class="line">            context.write(orderBean, NullWritable.get());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="4分栏-4"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.table;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TableDriver</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 0 根据自己电脑路径重新配置</span></span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\input&quot;</span>,</span><br><span class="line">                <span class="string">&quot;C:\\Users\\Administrator\\Desktop\\output&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 获取配置信息，或者job对象实例</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(configuration);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 指定本程序的jar包所在的本地路径</span></span><br><span class="line">        job.setJarByClass(TableDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3 指定本业务job要使用的Mapper/Reducer业务类</span></span><br><span class="line">        job.setMapperClass(TableMapper.class);</span><br><span class="line">        job.setReducerClass(TableReducer.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4 指定Mapper输出数据的kv类型</span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(TableBean.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5 指定最终输出的数据的kv类型</span></span><br><span class="line">        job.setOutputKeyClass(TableBean.class);</span><br><span class="line">        job.setOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6 指定job的输入原始文件所在目录</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 7 将job中配置的相关参数，以及job所用的java类所在的jar包， 提交给yarn去运行</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(result ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><details class="folding-tag" green><summary>点击查看运行结果</summary><div class="content"><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">ls</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    目录: C:\Users\Administrator\Desktop\output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Mode                 LastWriteTime         Length Name</span><br><span class="line"><span class="literal">----</span>                 <span class="literal">-------------</span>         <span class="literal">------</span> <span class="literal">----</span></span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">4</span>     <span class="number">21</span>:<span class="number">39</span>             <span class="number">12</span> .part<span class="literal">-r-00000</span>.crc</span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">4</span>     <span class="number">21</span>:<span class="number">39</span>              <span class="number">8</span> ._SUCCESS.crc</span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">4</span>     <span class="number">21</span>:<span class="number">39</span>             <span class="number">90</span> part<span class="literal">-r-00000</span></span><br><span class="line"><span class="literal">-a----</span>          <span class="number">2023</span>/<span class="number">6</span>/<span class="number">4</span>     <span class="number">21</span>:<span class="number">39</span>              <span class="number">0</span> _SUCCESS</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt; <span class="built_in">cat</span> .\part<span class="literal">-r-00000</span></span><br><span class="line"><span class="number">1004</span>    灏忕背  <span class="number">4</span></span><br><span class="line"><span class="number">1001</span>    灏忕背  <span class="number">1</span></span><br><span class="line"><span class="number">1005</span>    鍗庝负  <span class="number">5</span></span><br><span class="line"><span class="number">1002</span>    鍗庝负  <span class="number">2</span></span><br><span class="line"><span class="number">1006</span>    鏍煎姏  <span class="number">6</span></span><br><span class="line"><span class="number">1003</span>    鏍煎姏  <span class="number">3</span></span><br><span class="line"><span class="built_in">PS</span> C:\Users\Administrator\Desktop\output&gt;</span><br></pre></td></tr></table></figure></div></details><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div></li><li>总结<br><strong>缺点：</strong>这种方式中，合并的操作是在Reduce阶段完成，Reduce端的处理压力太大，Map节点的运算负载则很低，资源利用率不高，且在Reduce阶段极易产生数据倾斜。<br><strong>解决方案</strong>：Map端实现数据合并</li></ol><h3 id="Map-Join"><a href="#Map-Join" class="headerlink" title="Map Join"></a>Map Join</h3><ol><li>使用场景：Map Join适用于一张表十分小、一张表很大的场景。</li><li>优点:在Reduce端处理过多的表，非常容易产生数据倾斜。怎么办？<br>在Map端缓存多张表，提前处理业务逻辑，这样增加Map端业务，减少Reduce端数据的压力，尽可能的减少数据倾斜。</li><li>具体办法：采用DistributedCache<ul><li>在Mapper的setup阶段，将文件读取到缓存集合中。</li><li>在驱动函数中加载缓存。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 缓存普通文件到Task运行节点。</span></span><br><span class="line">job.addCacheFile(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;file://e:/cache/pd.txt&quot;</span>));</span><br></pre></td></tr></table></figure></li></ul></li></ol><h3 id="Map-Join案例实操"><a href="#Map-Join案例实操" class="headerlink" title="Map Join案例实操"></a>Map Join案例实操</h3><ol><li>需求<div class="btns rounded grid5"><a class="button" target="_blank" rel="noopener" href="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/order.txt" title="order.txt"><i class="fas fa-book-open"></i> order.txt</a></div><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">订单数据表t_order</span><br><span class="line">id	pid	amount</span><br><span class="line">1001	01	1</span><br><span class="line">1002	02	2</span><br><span class="line">1003	03	3</span><br><span class="line">1004	01	4</span><br><span class="line">1005	02	5</span><br><span class="line">1006	03	6</span><br></pre></td></tr></table></figure><div class="btns rounded grid5"><a class="button" target="_blank" rel="noopener" href="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/pd.txt" title="pd.txt"><i class="fas fa-book-open"></i> pd.txt</a></div><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">商品信息表t_product</span><br><span class="line">pid	pname</span><br><span class="line">01	小米</span><br><span class="line">02	华为</span><br><span class="line">03	格力</span><br></pre></td></tr></table></figure>将商品信息表中数据根据商品pid合并到订单数据表中。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">最终数据形式</span><br><span class="line">id	pname	amount</span><br><span class="line">1001	小米	1</span><br><span class="line">1004	小米	4</span><br><span class="line">1002	华为	2</span><br><span class="line">1005	华为	5</span><br><span class="line">1003	格力	3</span><br><span class="line">1006	格力	6</span><br></pre></td></tr></table></figure></li><li>需求分析:MapJoin适用于关联表中有小表的情形<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230605090424.png" alt=""></li><li>实现代码<div class="tabs" id="2分栏"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#2分栏-1">DistributedCacheMapper.java</button></li><li class="tab"><button type="button" data-href="#2分栏-2">DistributedCacheDriver.java</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="2分栏-1"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.table;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.BufferedReader;</span><br><span class="line"><span class="keyword">import</span> java.io.FileInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStreamReader;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DistributedCacheMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    Map&lt;String, String&gt; pdMap = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">setup</span><span class="params">(Mapper&lt;LongWritable, Text, Text, NullWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 获取缓存的文件</span></span><br><span class="line">        URI[] cacheFiles = context.getCacheFiles();</span><br><span class="line">        <span class="type">String</span> <span class="variable">path</span> <span class="operator">=</span> cacheFiles[<span class="number">0</span>].getPath().toString();</span><br><span class="line"></span><br><span class="line">        <span class="type">BufferedReader</span> <span class="variable">reader</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BufferedReader</span>(<span class="keyword">new</span> <span class="title class_">InputStreamReader</span>(<span class="keyword">new</span> <span class="title class_">FileInputStream</span>(path), <span class="string">&quot;UTF-8&quot;</span>));</span><br><span class="line"></span><br><span class="line">        String line;</span><br><span class="line">        <span class="keyword">while</span> (StringUtils.isNotEmpty(line = reader.readLine())) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 2 切割</span></span><br><span class="line">            String[] fields = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 3 缓存数据到集合</span></span><br><span class="line">            pdMap.put(fields[<span class="number">0</span>], fields[<span class="number">1</span>]);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4 关流</span></span><br><span class="line">        reader.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">Text</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 获取一行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 截取</span></span><br><span class="line">        String[] fields = line.split(<span class="string">&quot;\t&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3 获取产品id</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">pId</span> <span class="operator">=</span> fields[<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4 获取商品名称</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">pdName</span> <span class="operator">=</span> pdMap.get(pId);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5 拼接</span></span><br><span class="line">        k.set(line + <span class="string">&quot;\t&quot;</span> + pdName);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6 写出</span></span><br><span class="line">        context.write(k, NullWritable.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="2分栏-2"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.table;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DistributedCacheDriver</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 0 根据自己电脑路径重新配置</span></span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\input\\order&quot;</span>,</span><br><span class="line">                <span class="string">&quot;C:\\Users\\Administrator\\Desktop\\output&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 获取job信息</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(configuration);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 设置加载jar包路径</span></span><br><span class="line">        job.setJarByClass(DistributedCacheDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3 关联map</span></span><br><span class="line">        job.setMapperClass(DistributedCacheMapper.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4 设置最终输出数据类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5 设置输入输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6 加载缓存数据</span></span><br><span class="line">        job.addCacheFile(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;file:///C:\\Users\\Administrator\\Desktop\\input\\pd&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 7 Map端Join的逻辑不需要Reduce阶段，设置reduceTask数量为0</span></span><br><span class="line">        job.setNumReduceTasks(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 8 提交</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        System.exit(result ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div></li></ol><h2 id="计数器应用"><a href="#计数器应用" class="headerlink" title="计数器应用"></a>计数器应用</h2><p>Hadoop为每个作业维护若干内置计数器，以描述多项指标。例如，某些计数器记录已处理的字节数和记录数，使用户可监控已处理的输入数据量和已产生的输出数据量。</p><ol><li>计数器API<ul><li>采用枚举的方式统计计数<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">MyCounter</span>&#123;MALFORORMED,NORMAL&#125;</span><br><span class="line"><span class="comment">//对枚举定义的自定义计数器加1</span></span><br><span class="line">context.getCounter(MyCounter.MALFORORMED).increment(<span class="number">1</span>);</span><br></pre></td></tr></table></figure></li><li>采用计数器组、计数器名称的方式统计<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">context.getCounter(<span class="string">&quot;counterGroup&quot;</span>, <span class="string">&quot;counter&quot;</span>).increment(<span class="number">1</span>);</span><br></pre></td></tr></table></figure>组名和计数器名称随便起，但最好有意义。</li><li>计数结果在程序运行后的控制台上查看。</li></ul></li><li>计数器案例实操</li></ol><h2 id="数据清洗（ETL）"><a href="#数据清洗（ETL）" class="headerlink" title="数据清洗（ETL）"></a>数据清洗（ETL）</h2><p>在运行核心业务MapReduce程序之前，往往要先对数据进行清洗，清理掉不符合用户要求的数据。清理的过程往往只需要运行Mapper程序，不需要运行Reduce程序。</p><h3 id="数据清洗案例实操-简单解析版"><a href="#数据清洗案例实操-简单解析版" class="headerlink" title="数据清洗案例实操-简单解析版"></a>数据清洗案例实操-简单解析版</h3><ol><li>需求:去除日志中字段长度小于等于11的日志。<div class="btns rounded grid5"><a class="button" target="_blank" rel="noopener" href="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/web.txt" title="web.txt"><i class="fas fa-book-open"></i> web.txt</a></div></li><li>需求分析:需要在Map阶段对输入的数据根据规则进行过滤清洗。</li><li>实现代码<div class="tabs" id="2分栏"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#2分栏-1">LogMapper.java</button></li><li class="tab"><button type="button" data-href="#2分栏-2">LogDriver.java</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="2分栏-1"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.log;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LogMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, NullWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取一行</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 解析数据</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> parserLog(line, context);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 解析不通过的直接return</span></span><br><span class="line">        <span class="keyword">if</span> (!result) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 解析通过的写出</span></span><br><span class="line">        context.write(value, NullWritable.get());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">boolean</span> <span class="title function_">parserLog</span><span class="params">(String line, Mapper&lt;LongWritable, Text, Text, NullWritable&gt;.Context context)</span> &#123;</span><br><span class="line"></span><br><span class="line">        String[] fields = line.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">        <span class="keyword">if</span> (fields.length &gt; <span class="number">11</span>) &#123;</span><br><span class="line">            context.getCounter(<span class="string">&quot;map&quot;</span>, <span class="string">&quot;true&quot;</span>).increment(<span class="number">1</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            context.getCounter(<span class="string">&quot;map&quot;</span>, <span class="string">&quot;false&quot;</span>).increment(<span class="number">1</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="2分栏-2"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.log;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LogDriver</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 输入输出路径需要根据自己电脑上实际的输入输出路径设置</span></span><br><span class="line">        args = <span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\input\\web.txt&quot;</span>,</span><br><span class="line">                <span class="string">&quot;C:\\Users\\Administrator\\Desktop\\output&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 获取job信息</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 加载jar包</span></span><br><span class="line">        job.setJarByClass(LogDriver.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3 关联map</span></span><br><span class="line">        job.setMapperClass(LogMapper.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4 设置最终输出类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置reducetask个数为0</span></span><br><span class="line">        job.setNumReduceTasks(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5 设置输入和输出路径</span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6 提交</span></span><br><span class="line">        job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div></li></ol><h3 id="数据清洗案例实操-复杂解析版"><a href="#数据清洗案例实操-复杂解析版" class="headerlink" title="数据清洗案例实操-复杂解析版"></a>数据清洗案例实操-复杂解析版</h3><ol><li>需求:对Web访问日志中的各字段识别切分，去除日志中不合法的记录。根据清洗规则，输出过滤后的数据。</li><li>实现代码<div class="tabs" id="3分栏"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#3分栏-1">LogBean.java</button></li><li class="tab"><button type="button" data-href="#3分栏-2">LogMapper.java</button></li><li class="tab"><button type="button" data-href="#3分栏-3">LogDriver.java</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="3分栏-1"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LogBean</span> &#123;</span><br><span class="line">	<span class="keyword">private</span> String remote_addr;<span class="comment">// 记录客户端的ip地址</span></span><br><span class="line">	<span class="keyword">private</span> String remote_user;<span class="comment">// 记录客户端用户名称,忽略属性&quot;-&quot;</span></span><br><span class="line">	<span class="keyword">private</span> String time_local;<span class="comment">// 记录访问时间与时区</span></span><br><span class="line">	<span class="keyword">private</span> String request;<span class="comment">// 记录请求的url与http协议</span></span><br><span class="line">	<span class="keyword">private</span> String status;<span class="comment">// 记录请求状态；成功是200</span></span><br><span class="line">	<span class="keyword">private</span> String body_bytes_sent;<span class="comment">// 记录发送给客户端文件主体内容大小</span></span><br><span class="line">	<span class="keyword">private</span> String http_referer;<span class="comment">// 用来记录从那个页面链接访问过来的</span></span><br><span class="line">	<span class="keyword">private</span> String http_user_agent;<span class="comment">// 记录客户浏览器的相关信息</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> <span class="type">boolean</span> <span class="variable">valid</span> <span class="operator">=</span> <span class="literal">true</span>;<span class="comment">// 判断数据是否合法</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> String <span class="title function_">getRemote_addr</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> remote_addr;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setRemote_addr</span><span class="params">(String remote_addr)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.remote_addr = remote_addr;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> String <span class="title function_">getRemote_user</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> remote_user;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setRemote_user</span><span class="params">(String remote_user)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.remote_user = remote_user;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> String <span class="title function_">getTime_local</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> time_local;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setTime_local</span><span class="params">(String time_local)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.time_local = time_local;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> String <span class="title function_">getRequest</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> request;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setRequest</span><span class="params">(String request)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.request = request;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> String <span class="title function_">getStatus</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> status;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setStatus</span><span class="params">(String status)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.status = status;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> String <span class="title function_">getBody_bytes_sent</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> body_bytes_sent;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setBody_bytes_sent</span><span class="params">(String body_bytes_sent)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.body_bytes_sent = body_bytes_sent;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> String <span class="title function_">getHttp_referer</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> http_referer;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setHttp_referer</span><span class="params">(String http_referer)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.http_referer = http_referer;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> String <span class="title function_">getHttp_user_agent</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> http_user_agent;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setHttp_user_agent</span><span class="params">(String http_user_agent)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.http_user_agent = http_user_agent;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isValid</span><span class="params">()</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> valid;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setValid</span><span class="params">(<span class="type">boolean</span> valid)</span> &#123;</span><br><span class="line">		<span class="built_in">this</span>.valid = valid;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">		<span class="type">StringBuilder</span> <span class="variable">sb</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringBuilder</span>();</span><br><span class="line">		sb.append(<span class="built_in">this</span>.valid);</span><br><span class="line">		sb.append(<span class="string">&quot;\001&quot;</span>).append(<span class="built_in">this</span>.remote_addr);</span><br><span class="line">		sb.append(<span class="string">&quot;\001&quot;</span>).append(<span class="built_in">this</span>.remote_user);</span><br><span class="line">		sb.append(<span class="string">&quot;\001&quot;</span>).append(<span class="built_in">this</span>.time_local);</span><br><span class="line">		sb.append(<span class="string">&quot;\001&quot;</span>).append(<span class="built_in">this</span>.request);</span><br><span class="line">		sb.append(<span class="string">&quot;\001&quot;</span>).append(<span class="built_in">this</span>.status);</span><br><span class="line">		sb.append(<span class="string">&quot;\001&quot;</span>).append(<span class="built_in">this</span>.body_bytes_sent);</span><br><span class="line">		sb.append(<span class="string">&quot;\001&quot;</span>).append(<span class="built_in">this</span>.http_referer);</span><br><span class="line">		sb.append(<span class="string">&quot;\001&quot;</span>).append(<span class="built_in">this</span>.http_user_agent);</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">return</span> sb.toString();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="3分栏-2"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LogMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, NullWritable&gt;&#123;</span><br><span class="line">	<span class="type">Text</span> <span class="variable">k</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line">	</span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span>	<span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 1 获取1行</span></span><br><span class="line">		<span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 解析日志是否合法</span></span><br><span class="line">		<span class="type">LogBean</span> <span class="variable">bean</span> <span class="operator">=</span> parseLog(line);</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">if</span> (!bean.isValid()) &#123;</span><br><span class="line">			<span class="keyword">return</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		k.set(bean.toString());</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 3 输出</span></span><br><span class="line">		context.write(k, NullWritable.get());</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 解析日志</span></span><br><span class="line">	<span class="keyword">private</span> LogBean <span class="title function_">parseLog</span><span class="params">(String line)</span> &#123;</span><br><span class="line"></span><br><span class="line">		<span class="type">LogBean</span> <span class="variable">logBean</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">LogBean</span>();</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 1 截取</span></span><br><span class="line">		String[] fields = line.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">if</span> (fields.length &gt; <span class="number">11</span>) &#123;</span><br><span class="line"></span><br><span class="line">			<span class="comment">// 2封装数据</span></span><br><span class="line">			logBean.setRemote_addr(fields[<span class="number">0</span>]);</span><br><span class="line">			logBean.setRemote_user(fields[<span class="number">1</span>]);</span><br><span class="line">			logBean.setTime_local(fields[<span class="number">3</span>].substring(<span class="number">1</span>));</span><br><span class="line">			logBean.setRequest(fields[<span class="number">6</span>]);</span><br><span class="line">			logBean.setStatus(fields[<span class="number">8</span>]);</span><br><span class="line">			logBean.setBody_bytes_sent(fields[<span class="number">9</span>]);</span><br><span class="line">			logBean.setHttp_referer(fields[<span class="number">10</span>]);</span><br><span class="line">			</span><br><span class="line">			<span class="keyword">if</span> (fields.length &gt; <span class="number">12</span>) &#123;</span><br><span class="line">				logBean.setHttp_user_agent(fields[<span class="number">11</span>] + <span class="string">&quot; &quot;</span>+ fields[<span class="number">12</span>]);</span><br><span class="line">			&#125;<span class="keyword">else</span> &#123;</span><br><span class="line">				logBean.setHttp_user_agent(fields[<span class="number">11</span>]);</span><br><span class="line">			&#125;</span><br><span class="line">			</span><br><span class="line">			<span class="comment">// 大于400，HTTP错误</span></span><br><span class="line">			<span class="keyword">if</span> (Integer.parseInt(logBean.getStatus()) &gt;= <span class="number">400</span>) &#123;</span><br><span class="line">				logBean.setValid(<span class="literal">false</span>);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;<span class="keyword">else</span> &#123;</span><br><span class="line">			logBean.setValid(<span class="literal">false</span>);</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">return</span> logBean;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="3分栏-3"><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LogDriver</span> &#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">		</span><br><span class="line"><span class="comment">// 1 获取job信息</span></span><br><span class="line">		<span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">		<span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 2 加载jar包</span></span><br><span class="line">		job.setJarByClass(LogDriver.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 3 关联map</span></span><br><span class="line">		job.setMapperClass(LogMapper.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 4 设置最终输出类型</span></span><br><span class="line">		job.setOutputKeyClass(Text.class);</span><br><span class="line">		job.setOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 5 设置输入和输出路径</span></span><br><span class="line">		FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 6 提交</span></span><br><span class="line">		job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div></li></ol><h1 id="第十四章-MapReduce开发总结"><a href="#第十四章-MapReduce开发总结" class="headerlink" title="第十四章 MapReduce开发总结"></a>第十四章 MapReduce开发总结</h1><span class="p center logo large">MapReduce开发总结</span><h2 id="输入数据接口：InputFormat"><a href="#输入数据接口：InputFormat" class="headerlink" title="输入数据接口：InputFormat"></a>输入数据接口：InputFormat</h2><ol><li>默认使用的实现类是：TextInputFormat <span class="p red">(切片：默认按照块的大小切片。KV：偏移量和这一行的内容)</span></li><li>TextInputFormat的功能逻辑是：一次读一行文本，然后将该行的起始偏移量作为key，行内容作为value返回。</li><li>KeyValueTextInputFormat每一行均为一条记录，被分隔符分割为key，value。默认分隔符是tab（\t）。<span class="p red">(KV：第一个分隔符之前的为k，之后的数据为v)</span></li><li>NlineInputFormat按照指定的行数N来划分切片</li><li>CombineTextInputFormat可以把多个小文件合并成一个切片处理，提高处理效率<span class="p red">(切片：设置一个最大值，小于最大值的合并在一起)</span>。</li><li>用户还可以自定义InputFormat。</li></ol><h2 id="逻辑处理接口：Mapper"><a href="#逻辑处理接口：Mapper" class="headerlink" title="逻辑处理接口：Mapper"></a>逻辑处理接口：Mapper</h2><p>用户根据业务需求实现其中三个方法：</p><ol><li><strong>setup()</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *  启动 maptask 会先执行setup加载配置信息</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">setup</span><span class="params">(Mapper&lt;LongWritable, Text, Text, TableBean&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 因为我们有两个文件，默认情况下会分两个切片，也是两个maptask，</span></span><br><span class="line">    <span class="comment">// 可以通过切片获取到文件的传入路径，进而得到文件名（即订单名）</span></span><br><span class="line">    <span class="type">FileSplit</span> <span class="variable">inputSplit</span> <span class="operator">=</span> (FileSplit) context.getInputSplit();</span><br><span class="line">    name = inputSplit.getPath().getName();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><strong>map()</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 具体的业务逻辑</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取一行</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 分割</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 封装</span></span><br><span class="line">    context.write(k,v);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><strong>cleanup ()</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Called once at the end of the task.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">cleanup</span><span class="params">(Context context</span></span><br><span class="line"><span class="params">                        )</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"><span class="comment">// NOTHING</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Partitioner分区"><a href="#Partitioner分区" class="headerlink" title="Partitioner分区"></a>Partitioner分区</h2></li><li>有默认实现 HashPartitioner，逻辑是根据key的哈希值和numReduces来返回一个分区号；key.hashCode()&amp;Integer.MAXVALUE % numReduces</li><li>如果业务上有特别的需求，可以自定义分区<span class="p red">分区数从0开始往上排，不可跳过</span>。</li></ol><h2 id="Comparable排序"><a href="#Comparable排序" class="headerlink" title="Comparable排序"></a>Comparable排序</h2><ol><li>当我们用自定义的对象作为key来输出时，就必须要实现WritableComparable接口，重写其中的compareTo()方法。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataInput;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Bean</span> <span class="keyword">implements</span> <span class="title class_">WritableComparable</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 具体的比较方式</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> o the object to be compared.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(Object o)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *  序列化</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> out &lt;code&gt;DataOuput&lt;/code&gt; to serialize this object into.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        out.write(a);</span><br><span class="line">        out.write(b);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 反序列化，与序列化顺序一致</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> in &lt;code&gt;DataInput&lt;/code&gt; to deseriablize this object from.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">        a = in.readInt();</span><br><span class="line">        b = in.readInt();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>部分排序：对最终输出的每一个文件进行内部排序。</li><li>全排序：对所有数据进行排序，通常只有一个Reduce。</li><li>二次排序：排序的条件有两个。</li></ol><h2 id="Combiner合并"><a href="#Combiner合并" class="headerlink" title="Combiner合并"></a>Combiner合并</h2><p>Combiner合并可以提高程序执行效率，减少IO传输。但是使用时必须不能影响原有的业务处理结果。<br>自定义Combiner实现步骤:<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>自定义一个Combiner继承Reducer，重写Reduce方法 </span><br><span class="line"><span class="number">2.</span>在Job驱动类中设置</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordcountCombiner</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;&gt;&#123;</span><br><span class="line"></span><br><span class="line">	<span class="meta">@Override</span></span><br><span class="line">	<span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1 汇总操作</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2 写出</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setCombinerClass(WordcountCombiner.class);</span><br></pre></td></tr></table></figure><p></p><h2 id="Reduce端分组：GroupingComparator"><a href="#Reduce端分组：GroupingComparator" class="headerlink" title="Reduce端分组：GroupingComparator"></a>Reduce端分组：GroupingComparator</h2><p>在Reduce端对key进行分组。应用于：在接收的key为bean对象时，想让一个或几个字段相同（全部字段比较不相同）的key进入到同一个reduce方法时，可以采用分组排序。<br>分组排序步骤：<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>自定义类继承WritableComparator</span><br><span class="line"><span class="number">2.</span>重写compare()方法</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparator;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">OrderGroupingComparator</span> <span class="keyword">extends</span> <span class="title class_">WritableComparator</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">protected</span> <span class="title function_">OrderGroupingComparator</span><span class="params">()</span> &#123;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compare</span><span class="params">(WritableComparable a, WritableComparable b)</span> &#123;</span><br><span class="line">            <span class="comment">// 比较的业务逻辑</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h2 id="逻辑处理接口：Reducer"><a href="#逻辑处理接口：Reducer" class="headerlink" title="逻辑处理接口：Reducer"></a>逻辑处理接口：Reducer</h2><p>用户根据业务需求实现其中三个方法：</p><ol><li><strong>reduce()</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">IntWritable</span> <span class="variable">value</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Reducer&lt;Text, IntWritable, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// 1.累加求和</span></span><br><span class="line">    <span class="keyword">for</span> (IntWritable value : values) &#123;</span><br><span class="line">        sum += value.get();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    value.set(sum);</span><br><span class="line">    <span class="comment">// 2.写出</span></span><br><span class="line">    context.write(key, value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><strong>setup()</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">setup</span><span class="params">(Reducer&lt;Text, IntWritable, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">    <span class="built_in">super</span>.setup(context);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><strong>cleanup ()</strong><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">cleanup</span><span class="params">(Reducer&lt;Text, IntWritable, Text, IntWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">    <span class="built_in">super</span>.cleanup(context);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="输出数据接口：OutputFormat"><a href="#输出数据接口：OutputFormat" class="headerlink" title="输出数据接口：OutputFormat"></a>输出数据接口：OutputFormat</h2><ol><li>默认实现类是TextOutputFormat，功能逻辑是：将每一个KV对，向目标文本文件输出一行。</li><li>将SequenceFileOutputFormat输出作为后续 MapReduce任务的输入，这便是一种好的输出格式，因为它的格式紧凑，很容易被压缩。</li><li>用户还可以自定义OutputFormat。</li></ol><h2 id="Driver驱动类"><a href="#Driver驱动类" class="headerlink" title="Driver驱动类"></a>Driver驱动类</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordcountDriver</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 1 获取配置信息以及封装任务</span></span><br><span class="line">		<span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">		<span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(configuration);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 2 设置jar加载路径</span></span><br><span class="line">		job.setJarByClass(WordcountDriver.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 3 设置map和reduce类</span></span><br><span class="line">		job.setMapperClass(WordcountMapper.class);</span><br><span class="line">		job.setReducerClass(WordcountReducer.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 4 设置map输出</span></span><br><span class="line">		job.setMapOutputKeyClass(Text.class);</span><br><span class="line">		job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 5 设置最终输出kv类型</span></span><br><span class="line">		job.setOutputKeyClass(Text.class);</span><br><span class="line">		job.setOutputValueClass(IntWritable.class);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 6 设置输入和输出路径</span></span><br><span class="line">		FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">0</span>]));</span><br><span class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 7 提交</span></span><br><span class="line">		<span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">		System.exit(result ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="第十五章-Hadoop数据压缩"><a href="#第十五章-Hadoop数据压缩" class="headerlink" title="第十五章 Hadoop数据压缩"></a>第十五章 Hadoop数据压缩</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><ul><li>压缩技术能够有效减少底层存储系统（HDFS）读写字节数。压缩提高了网络带宽和磁盘空间的效率。在运行MR程序时，I/O操作、网络数据传输、 Shuffle和Merge要花大量的时间，尤其是数据规模很大和工作负载密集的情况下，因此，使用数据压缩显得非常重要。</li><li>鉴于磁盘I/O和网络带宽是Hadoop的宝贵资源，数据压缩对于节省资源、最小化磁盘I/O和网络传输非常有帮助。可以在任意MapReduce阶段启用压缩。不过，尽管压缩与解压操作的CPU开销不高，其性能的提升和资源的节省并非没有代价。<span class="p center logo large">压缩策略和原则</span> 压缩是提高Hadoop运行效率的一种优化策略。<br>通过对Mapper、Reducer运行过程的数据进行压缩，以减少磁盘IO，提高MR程序运行速度。<br>注意：采用压缩技术减少了磁盘IO，但同时增加了CPU运算负担。所以，压缩特性运用得当能提高性能，但运用不当也可能降低性能。<br>压缩基本原则：<ol><li>运算密集型的job，少用压缩</li><li>IO密集型的job，多用压缩</li></ol></li></ul><h2 id="MR支持的压缩编码"><a href="#MR支持的压缩编码" class="headerlink" title="MR支持的压缩编码"></a>MR支持的压缩编码</h2><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230606093725.png" alt=""><br>为了支持多种压缩/解压缩算法，Hadoop引入了编码/解码器，如下表所示:<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230606093801.png" alt=""></p><h2 id="压缩方式选择"><a href="#压缩方式选择" class="headerlink" title="压缩方式选择"></a>压缩方式选择</h2><h3 id="Gzip压缩"><a href="#Gzip压缩" class="headerlink" title="Gzip压缩"></a>Gzip压缩</h3><ol><li>优点：压缩率比较高，而且压缩/解压速度也比较快；Hadoop本身支持，在应用中处理Gzip格式的文件就和直接处理文本一样；大部分Linux系统都自带Gzip命令，使用方便。</li><li>缺点：不支持Split。</li><li>应用场景：当每个文件压缩之后在130M以内的（1个块大小内），都可以考虑用Gzip压缩格式。例如说一天或者一个小时的日志压缩成一个Gzip文件。</li></ol><h3 id="Bzip2压缩"><a href="#Bzip2压缩" class="headerlink" title="Bzip2压缩"></a>Bzip2压缩</h3><ol><li>优点：支持Split；具有很高的压缩率，比Gzip压缩率都高；Hadoop本身自带，使用方便。</li><li>缺点：压缩/解压速度慢。</li><li>应用场景：适合对速度要求不高，但需要较高的压缩率的时候；或者输出之后的数据比较大，处理之后的数据需要压缩存档减少磁盘空间并且以后数据用得比较少的情况；或者对单个很大的文本文件想压缩减少存储空间，同时又需要支持Split，而且兼容之前的应用程序的情况。</li></ol><h3 id="Lzo压缩"><a href="#Lzo压缩" class="headerlink" title="Lzo压缩"></a>Lzo压缩</h3><ol><li>优点：压缩/解压速度也比较快，合理的压缩率；支持Split，是Hadoop中最流行的压缩格式；可以在Linux系统下安装lzop命令，使用方便。</li><li>缺点：压缩率比Gzip要低一些；Hadoop本身不支持，需要安装；在应用中对Lzo格式的文件需要做一些特殊处理（为了支持Split需要建索引，还需要指定InputFormat为Lzo格式）。</li><li>应用场景：一个很大的文本文件，压缩之后还大于200M以上的可以考虑，而且单个文件越大，Lzo优点越越明显。</li></ol><h3 id="Snappy压缩"><a href="#Snappy压缩" class="headerlink" title="Snappy压缩"></a>Snappy压缩</h3><ol><li>优点：高速压缩速度和合理的压缩率。</li><li>缺点：不支持Split；压缩率比Gzip要低；Hadoop本身不支持，需要安装。</li><li>应用场景：当MapReduce作业的Map输出的数据比较大的时候，作为Map到Reduce的中间数据的压缩格式；或者作为一个MapReduce作业的输出和另外一个MapReduce作业的输入。</li></ol><h2 id="压缩位置选择"><a href="#压缩位置选择" class="headerlink" title="压缩位置选择"></a>压缩位置选择</h2><p>压缩可以在MapReduce作用的任意阶段启用:<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230606094627.png" alt=""></p><h2 id="压缩参数配置"><a href="#压缩参数配置" class="headerlink" title="压缩参数配置"></a>压缩参数配置</h2><p>要在Hadoop中启用压缩，可以配置如下参数：</p><table><tr><td>参数</td><td>默认值</td><td>阶段</td><td>建议</td></tr><tr><td>io.compression.codecs（在core-site.xml中配置）</td><td>org.apache.hadoop.io.compress.DefaultCodec, org.apache.hadoop.io.compress.GzipCodec, org.apache.hadoop.io.compress.BZip2Codec</td><td>输入压缩</td><td>Hadoop使用文件扩展名判断是否支持某种编解码器</td></tr><tr><td>mapreduce.map.output.compress（在mapred-site.xml中配置）</td><td>false</td><td>mapper输出</td><td>这个参数设为true启用压缩</td></tr><tr><td>mapreduce.map.output.compress.codec（在mapred-site.xml中配置）</td><td>org.apache.hadoop.io.compress.DefaultCodec</td><td>mapper输出</td><td>企业多使用LZO或Snappy编解码器在此阶段压缩数据</td></tr><tr><td>mapreduce.output.fileoutputformat.compress（在mapred-site.xml中配置）</td><td>false</td><td>reducer输出</td><td>这个参数设为true启用压缩</td></tr><tr><td>mapreduce.output.fileoutputformat.compress.codec（在mapred-site.xml中配置）</td><td>org.apache.hadoop.io.compress. DefaultCodec</td><td>reducer输出</td><td>使用标准工具或者编解码器，如gzip和bzip2</td></tr><tr><td>mapreduce.output.fileoutputformat.compress.type（在mapred-site.xml中配置）</td><td>RECORD</td><td>reducer输出</td><td>SequenceFile输出使用的压缩类型：NONE和BLOCK</td></tr></table><h2 id="压缩实操案例"><a href="#压缩实操案例" class="headerlink" title="压缩实操案例"></a>压缩实操案例</h2><h3 id="数据流的压缩和解压缩"><a href="#数据流的压缩和解压缩" class="headerlink" title="数据流的压缩和解压缩"></a>数据流的压缩和解压缩</h3><p>CompressionCodec有两个方法可以用于轻松地压缩或解压缩数据。<br>要想对正在被写入一个输出流的数据进行压缩，我们可以使用<strong style="color:red">createOutputStream(OutputStreamout)方法创建一个CompressionOutputStream</strong>，将其以压缩格式写入底层的流。<br>相反，要想对从输入流读取而来的数据进行解压缩，则调用<strong style="color:#c00000">createInputStream(InputStreamin)函数，从而获得一个CompressionInputStream，</strong>从而从底层的流读取未压缩的数据。<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.jermyn.mr.compress;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionCodec;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionCodecFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionInputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionOutputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.ReflectionUtils;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CompressTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// bzip2方式</span></span><br><span class="line">        compress(<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\input\\web.txt&quot;</span>,</span><br><span class="line">                <span class="string">&quot;org.apache.hadoop.io.compress.BZip2Codec&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// gzip方式</span></span><br><span class="line">        compress(<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\input\\web.txt&quot;</span>,</span><br><span class="line">                <span class="string">&quot;org.apache.hadoop.io.compress.GzipCodec&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// default</span></span><br><span class="line">        compress(<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\input\\web.txt&quot;</span>,</span><br><span class="line">                <span class="string">&quot;org.apache.hadoop.io.compress.DefaultCodec&quot;</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 解压缩</span></span><br><span class="line">        decompress(<span class="string">&quot;C:\\Users\\Administrator\\Desktop\\input\\web.txt.gz&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 压缩</span></span><br><span class="line"><span class="comment">     * TODO 1. 获取输入流</span></span><br><span class="line"><span class="comment">     * TODO 2.通过反射的工具类获取哪种的编码方式</span></span><br><span class="line"><span class="comment">     * TODO 3.获取输出流</span></span><br><span class="line"><span class="comment">     * TODO 4.流的对拷</span></span><br><span class="line"><span class="comment">     * TODO 5.关闭资源</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> method</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> ClassNotFoundException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">compress</span><span class="params">(String fileName, String method)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 获取输入流</span></span><br><span class="line">        <span class="type">FileInputStream</span> <span class="variable">fis</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileInputStream</span>(<span class="keyword">new</span> <span class="title class_">File</span>(fileName));</span><br><span class="line"></span><br><span class="line">        <span class="type">Class</span> <span class="variable">classCodec</span> <span class="operator">=</span> Class.forName(method);</span><br><span class="line">        <span class="comment">// 2.通过反射的工具类获取哪种的编码方式</span></span><br><span class="line">        <span class="type">CompressionCodec</span> <span class="variable">codec</span> <span class="operator">=</span> (CompressionCodec) ReflectionUtils.newInstance(classCodec, <span class="keyword">new</span> <span class="title class_">Configuration</span>());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3.获取输出流</span></span><br><span class="line">        <span class="type">FileOutputStream</span> <span class="variable">fos</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileOutputStream</span>(<span class="keyword">new</span> <span class="title class_">File</span>(fileName + codec.getDefaultExtension()));</span><br><span class="line">        <span class="type">CompressionOutputStream</span> <span class="variable">cos</span> <span class="operator">=</span> codec.createOutputStream(fos);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4.流的对拷</span></span><br><span class="line">        IOUtils.copyBytes(fis, cos, <span class="number">1024</span> * <span class="number">1024</span>, <span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5.关闭资源</span></span><br><span class="line">        IOUtils.closeStream(cos);</span><br><span class="line">        IOUtils.closeStream(fos);</span><br><span class="line">        IOUtils.closeStream(fis);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 解压缩</span></span><br><span class="line"><span class="comment">     * TODO 1.压缩方式的检查</span></span><br><span class="line"><span class="comment">     * TODO 2. 获得输入流</span></span><br><span class="line"><span class="comment">     * TODO 3. 获得输出流</span></span><br><span class="line"><span class="comment">     * TODO 4. 流的对拷</span></span><br><span class="line"><span class="comment">     * TODO 5.关闭资源</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fileName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">decompress</span><span class="params">(String fileName)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1.压缩方式的检查</span></span><br><span class="line">        <span class="type">CompressionCodecFactory</span> <span class="variable">factory</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CompressionCodecFactory</span>(<span class="keyword">new</span> <span class="title class_">Configuration</span>());</span><br><span class="line">        <span class="type">CompressionCodec</span> <span class="variable">codec</span> <span class="operator">=</span> factory.getCodec(<span class="keyword">new</span> <span class="title class_">Path</span>(fileName));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (codec == <span class="literal">null</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;can not process&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 获得输入流</span></span><br><span class="line">        <span class="type">FileInputStream</span> <span class="variable">fis</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileInputStream</span>(<span class="keyword">new</span> <span class="title class_">File</span>(fileName));</span><br><span class="line">        <span class="type">CompressionInputStream</span> <span class="variable">cis</span> <span class="operator">=</span> codec.createInputStream(fis);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 获得输出流</span></span><br><span class="line">        <span class="type">FileOutputStream</span> <span class="variable">fos</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FileOutputStream</span>(<span class="keyword">new</span> <span class="title class_">File</span>(fileName + <span class="string">&quot;.decode&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4. 流的对拷</span></span><br><span class="line">        IOUtils.copyBytes(cis, fos, <span class="number">1024</span> * <span class="number">1024</span>, <span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5.关闭资源</span></span><br><span class="line">        IOUtils.closeStream(fos);</span><br><span class="line">        IOUtils.closeStream(cis);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230606104649.png" alt=""><p></p><h3 id="Map输出端采用压缩"><a href="#Map输出端采用压缩" class="headerlink" title="Map输出端采用压缩"></a>Map输出端采用压缩</h3><p>即使你的MapReduce的输入输出文件都是未压缩的文件，你仍然可以对Map任务的中间结果输出做压缩，因为它要写在硬盘并且通过网络传输到Reduce节点，对其压缩可以提高很多性能，这些工作只要设置两个属性即可.<br></p><div class="tip fa-gamepad faa-horizontal animated"><p>提供的Hadoop源码支持的压缩格式有：BZip2Codec 、DefaultCodec<br>使用wordcount案例，map和reduce均不改变，只在driver驱动类中加入：</p></div><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 开启map端输出压缩</span></span><br><span class="line">configuration.setBoolean(<span class="string">&quot;mapreduce.map.output.compress&quot;</span>, <span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置map端输出压缩方式</span></span><br><span class="line">configuration.setClass(<span class="string">&quot;mapreduce.map.output.compress.codec&quot;</span>, BZip2Codec.class, CompressionCodec.class);</span><br></pre></td></tr></table></figure><p></p><blockquote><p>注意：可以看到最终的输出结果是没有变化的，只是在传输过程中提高了io传输的效率</p></blockquote><h3 id="Reduce输出端采用压缩"><a href="#Reduce输出端采用压缩" class="headerlink" title="Reduce输出端采用压缩"></a>Reduce输出端采用压缩</h3><div class="tip fa-gamepad faa-horizontal animated"><p>使用wordcount案例，map和reduce均不改变，只在driver驱动类中加入：</p></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置reduce端输出压缩开启</span></span><br><span class="line">FileOutputFormat.setCompressOutput(job, <span class="literal">true</span>);</span><br><span class="line">		</span><br><span class="line"><span class="comment">// 设置压缩的方式</span></span><br><span class="line">FileOutputFormat.setOutputCompressorClass(job, BZip2Codec.class); </span><br></pre></td></tr></table></figure><h1 id="第十六章-Yarn资源调度器"><a href="#第十六章-Yarn资源调度器" class="headerlink" title="第十六章 Yarn资源调度器"></a>第十六章 Yarn资源调度器</h1><p>Yarn是一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式的操作系统平台，而MapReduce等运算程序则相当于运行于操作系统之上的应用程序。</p><h2 id="Yarn基本架构"><a href="#Yarn基本架构" class="headerlink" title="Yarn基本架构"></a>Yarn基本架构</h2><p>YARN主要由<strong style="color:red">ResourceManager、NodeManager、ApplicationMaster和Container</strong>等组件构成<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230606110634.png" alt=""></p><h2 id="Yarn工作机制"><a href="#Yarn工作机制" class="headerlink" title="Yarn工作机制"></a>Yarn工作机制</h2><h3 id="Yarn运行机制"><a href="#Yarn运行机制" class="headerlink" title="Yarn运行机制"></a>Yarn运行机制</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230606125149.png" alt=""></p><h3 id="工作机制详解"><a href="#工作机制详解" class="headerlink" title="工作机制详解"></a>工作机制详解</h3><ol><li>MR程序提交到客户端所在的节点。</li><li>YarnRunner向ResourceManager申请一个Application。</li><li>RM将该应用程序的资源路径返回给YarnRunner。</li><li>该程序将运行所需资源提交到HDFS上。</li><li>程序资源提交完毕后，申请运行mrAppMaster。</li><li>RM将用户的请求初始化成一个Task。</li><li>其中一个NodeManager领取到Task任务。</li><li>该NodeManager创建容器Container，并产生MRAppmaster。</li><li>Container从HDFS上拷贝资源到本地。</li><li>MRAppmaster向RM 申请运行MapTask资源。</li><li>RM将运行MapTask任务分配给另外两个NodeManager，另两个NodeManager分别领取任务并创建容器。</li><li>MR向两个接收到任务的NodeManager发送程序启动脚本，这两个NodeManager分别启动MapTask，MapTask对数据分区排序。</li><li>MrAppMaster等待所有MapTask运行完毕后，向RM申请容器，运行ReduceTask。</li><li>ReduceTask向MapTask获取相应分区的数据。</li><li>程序运行完毕后，MR会向RM申请注销自己。</li></ol><h2 id="作业提交全过程"><a href="#作业提交全过程" class="headerlink" title="作业提交全过程"></a>作业提交全过程</h2><h3 id="作业提交过程之YARN"><a href="#作业提交过程之YARN" class="headerlink" title="作业提交过程之YARN"></a>作业提交过程之YARN</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230606125558.png" alt=""><br><span class="p center logo large">作业提交全过程详解</span><br></p><div class="timeline green"><div class="timeline-item headline"><div class="timeline-item-title"><div class="item-circle"><p>作业提交全过程详解</p></div></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第一步 作业提交</p></div></div><div class="timeline-item-content"><p>1.Client调用job.waitForCompletion方法，向整个集群提交MapReduce作业。<br>2.Client向RM申请一个作业id。<br>3.RM给Client返回该job资源的提交路径和作业id。<br>4.Client提交jar包、切片信息和配置文件到指定的资源提交路径。<br>5.Client提交完资源后，向RM申请运行MrAppMaster。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第二步 作业初始化</p></div></div><div class="timeline-item-content"><p>6.当RM收到Client的请求后，将该job添加到容量调度器中。<br>7.某一个空闲的NM领取到该Job。<br>8.该NM创建Container，并产生MRAppmaster。<br>9.下载Client提交的资源到本地。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第三步 任务分配</p></div></div><div class="timeline-item-content"><p>10.MrAppMaster向RM申请运行多个MapTask任务资源。<br>11.RM将运行MapTask任务分配给另外两个NodeManager，另两个NodeManager分别领取任务并创建容器。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第四步 任务运行</p></div></div><div class="timeline-item-content"><p>12.MR向两个接收到任务的NodeManager发送程序启动脚本，这两个NodeManager分别启动MapTask，MapTask对数据分区排序。<br>13.MrAppMaster等待所有MapTask运行完毕后，向RM申请容器，运行ReduceTask。<br>14.ReduceTask向MapTask获取相应分区的数据。<br>15.程序运行完毕后，MR会向RM申请注销自己。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第五步 进度和状态更新</p></div></div><div class="timeline-item-content"><p>YARN中的任务将其进度和状态(包括counter)返回给应用管理器, 客户端每秒(通过mapreduce.client.progressmonitor.pollinterval设置)向应用管理器请求进度更新, 展示给用户。</p></div></div><div class="timeline-item"><div class="timeline-item-title"><div class="item-circle"><p>第六步 作业完成</p></div></div><div class="timeline-item-content"><p>除了向应用管理器请求作业进度外, 客户端每5秒都会通过调用waitForCompletion()来检查作业是否完成。时间间隔可以通过mapreduce.client.completion.pollinterval来设置。作业完成之后, 应用管理器和Container会清理工作状态。作业的信息会被作业历史服务器存储以备之后用户核查。</p></div></div></div><p></p><h3 id="作业提交过程之MapReduce"><a href="#作业提交过程之MapReduce" class="headerlink" title="作业提交过程之MapReduce"></a>作业提交过程之MapReduce</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230606130455.png" alt=""></p><h2 id="资源调度器"><a href="#资源调度器" class="headerlink" title="资源调度器"></a>资源调度器</h2><p>目前，Hadoop作业调度器主要有三种：FIFO、Capacity Scheduler和Fair Scheduler。Hadoop2.7.2默认的资源调度器是Capacity Scheduler。<br>具体设置详见：yarn-default.xml文件<br></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>The class to use as the resource scheduler.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p></p><h3 id="先进先出调度器（FIFO）"><a href="#先进先出调度器（FIFO）" class="headerlink" title="先进先出调度器（FIFO）"></a>先进先出调度器（FIFO）</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230606130802.png" alt=""></p><h3 id="容量调度器（Capacity-Scheduler）"><a href="#容量调度器（Capacity-Scheduler）" class="headerlink" title="容量调度器（Capacity Scheduler）"></a>容量调度器（Capacity Scheduler）</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230606130921.png" alt=""></p><h3 id="公平调度器（Fair-Scheduler）"><a href="#公平调度器（Fair-Scheduler）" class="headerlink" title="公平调度器（Fair Scheduler）"></a>公平调度器（Fair Scheduler）</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230606131003.png" alt=""></p><h2 id="任务的推测执行"><a href="#任务的推测执行" class="headerlink" title="任务的推测执行"></a>任务的推测执行</h2><ol><li>作业完成时间取决于最慢的任务完成时间<br>一个作业由若干个Map任务和Reduce任务构成。因硬件老化、软件Bug等，某些任务可能运行非常慢。<br>思考：系统中有99%的Map任务都完成了，只有少数几个Map老是进度很慢，完不成，怎么办？</li><li>推测执行机制<br>发现拖后腿的任务，比如某个任务运行速度远慢于任务平均速度。为拖后腿任务启动一个备份任务，同时运行。谁先运行完，则采用谁的结果。</li><li>执行推测任务的前提条件<ol><li>每个Task只能有一个备份任务</li><li>当前Job已完成的Task必须不小于0.05（5%）</li><li>开启推测执行参数设置。mapred-site.xml文件中默认是打开的。<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.speculative<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  	<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  	<span class="tag">&lt;<span class="name">description</span>&gt;</span>If true, then multiple instances of some map tasks may be executed in parallel.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  	<span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.speculative<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  	<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  	<span class="tag">&lt;<span class="name">description</span>&gt;</span>If true, then multiple instances of some reduce tasks may be executed in parallel.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ol></li><li>不能启用推测执行机制情况<ul><li>任务间存在严重的负载倾斜；</li><li>特殊任务，比如任务向数据库中写数据。</li></ul></li><li>算法原理<br><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/20230606131856.png" alt=""></li></ol><h1 id="第十七章-Hadoop企业优化"><a href="#第十七章-Hadoop企业优化" class="headerlink" title="第十七章 Hadoop企业优化"></a>第十七章 Hadoop企业优化</h1><h2 id="MapReduce优化方法"><a href="#MapReduce优化方法" class="headerlink" title="MapReduce优化方法"></a>MapReduce优化方法</h2><p>MapReduce优化方法主要从六个方面考虑：<strong style="color:red">数据输入、Map阶段、Reduce阶段、IO传输、数据倾斜问题和常用的调优参数。</strong></p><h3 id="数据输入"><a href="#数据输入" class="headerlink" title="数据输入"></a>数据输入</h3><ol><li>合并小文件：在执行MR任务前将小文件进行合并，大量的小文件会产生大量的Map任务，增大Map任务装载次数，而任务的装载比较耗时，从而导致MR运行较慢。</li><li>采用CombineTextInputFormat来作为输入，解决输入端大量小文件场景。</li></ol><h3 id="Map阶段"><a href="#Map阶段" class="headerlink" title="Map阶段"></a>Map阶段</h3><ol><li>减少溢写（Spill）次数：通过调整io.sort.mb及sort.spill.percent参数值，增大触发Spill的内存上限，减少Spill次数，从而减少磁盘IO。</li><li>减少合并（Merge）次数：通过调整io.sort.factor参数，增大Merge的文件数目，减少Merge的次数，从而缩短MR处理时间。</li><li>在Map之后，不影响业务逻辑前提下，先进行Combine处理，减少 I/O。</li></ol><h3 id="Reduce阶段"><a href="#Reduce阶段" class="headerlink" title="Reduce阶段"></a>Reduce阶段</h3><ol><li>合理设置Map和Reduce数：两个都不能设置太少，也不能设置太多。太少，会导致Task等待，延长处理时间；太多，会导致Map、Reduce任务间竞争资源，造成处理超时等错误。</li><li>设置Map、Reduce共存：调整slowstart.completedmaps参数，使Map运行到一定程度后，Reduce也开始运行，减少Reduce的等待时间。</li><li>规避使用Reduce：因为Reduce在用于连接数据集的时候将会产生大量的网络消耗。</li><li>合理设置Reduce端的Buffer：默认情况下，数据达到一个阈值的时候，Buffer中的数据就会写入磁盘，然后Reduce会从磁盘中获得所有的数据。也就是说，Buffer和Reduce是没有直接关联的，中间多次写磁盘-&gt;读磁盘的过程，既然有这个弊端，那么就可以通过参数来配置，使得Buffer中的一部分数据可以直接输送到Reduce，从而减少IO开销：mapreduce.reduce.input.buffer.percent，默认为0.0。当值大于0的时候，会保留指定比例的内存读Buffer中的数据直接拿给Reduce使用。这样一来，设置Buffer需要内存，读取数据需要内存，Reduce计算也要内存，所以要根据作业的运行情况进行调整。</li></ol><h3 id="I-O传输"><a href="#I-O传输" class="headerlink" title="I/O传输"></a>I/O传输</h3><ol><li>采用数据压缩的方式，减少网络IO的的时间。安装Snappy和LZO压缩编码器。</li><li>使用SequenceFile二进制文件。</li></ol><h3 id="数据倾斜问题"><a href="#数据倾斜问题" class="headerlink" title="数据倾斜问题"></a>数据倾斜问题</h3><ol><li>数据倾斜现象<ul><li>数据频率倾斜——某一个区域的数据量要远远大于其他区域。</li><li>数据大小倾斜——部分记录的大小远远大于平均值。</li></ul></li><li>减少数据倾斜的方法<br><strong style="color:red">方法1：</strong>抽样和范围分区:可以通过对原始数据进行抽样得到的结果集来预设分区边界值。<br><strong style="color:red">方法2：</strong>自定义分区:基于输出键的背景知识进行自定义分区。例如，如果Map输出键的单词来源于一本书。且其中某几个专业词汇较多。那么就可以自定义分区将这这些专业词汇发送给固定的一部分Reduce实例。而将其他的都发送给剩余的Reduce实例。<br><strong style="color:red">方法3：</strong>Combine:使用Combine可以大量地减小数据倾斜。在可能的情况下，Combine的目的就是聚合并精简数据。<br><strong style="color:red">方法4：</strong>采用Map Join，尽量避免Reduce Join。</li></ol><h2 id="常用的调优参数"><a href="#常用的调优参数" class="headerlink" title="常用的调优参数"></a>常用的调优参数</h2><h3 id="资源相关参数"><a href="#资源相关参数" class="headerlink" title="资源相关参数"></a>资源相关参数</h3><ol><li>以下参数是在用户自己的MR应用程序中配置就可以生效（mapred-default.xml）<table><tr><td>配置参数</td><td>参数说明</td></tr><tr><td>mapreduce.map.memory.mb</td><td>一个MapTask可使用的资源上限（单位:MB），默认为1024。如果MapTask实际使用的资源量超过该值，则会被强制杀死。</td></tr><tr><td>mapreduce.reduce.memory.mb</td><td>一个ReduceTask可使用的资源上限（单位:MB），默认为1024。如果ReduceTask实际使用的资源量超过该值，则会被强制杀死。</td></tr><tr><td>mapreduce.map.cpu.vcores</td><td>每个MapTask可使用的最多cpu core数目，默认值: 1</td></tr><tr><td>mapreduce.reduce.cpu.vcores</td><td>每个ReduceTask可使用的最多cpu core数目，默认值: 1</td></tr><tr><td>mapreduce.reduce.shuffle.parallelcopies</td><td>每个Reduce去Map中取数据的并行数。默认值是5</td></tr><tr><td>mapreduce.reduce.shuffle.merge.percent</td><td>Buffer中的数据达到多少比例开始写入磁盘。默认值0.66</td></tr><tr><td>mapreduce.reduce.shuffle.input.buffer.percent</td><td>Buffer大小占Reduce可用内存的比例。默认值0.7</td></tr><tr><td>mapreduce.reduce.input.buffer.percent</td><td>指定多少比例的内存用来存放Buffer中的数据，默认值是0.0</td></tr></table></li><li>应该在YARN启动之前就配置在服务器的配置文件中才能生效（yarn-default.xml）<table><tr><td>配置参数</td><td>参数说明</td></tr><tr><td>yarn.scheduler.minimum-allocation-mb</td><td>给应用程序Container分配的最小内存，默认值：1024</td></tr><tr><td>yarn.scheduler.maximum-allocation-mb</td><td>给应用程序Container分配的最大内存，默认值：8192</td></tr><tr><td>yarn.scheduler.minimum-allocation-vcores</td><td>每个Container申请的最小CPU核数，默认值：1</td></tr><tr><td>yarn.scheduler.maximum-allocation-vcores</td><td>每个Container申请的最大CPU核数，默认值：32</td></tr><tr><td>yarn.nodemanager.resource.memory-mb</td><td>给Containers分配的最大物理内存，默认值：8192</td></tr></table></li><li>Shuffle性能优化的关键参数，应在YARN启动之前就配置好（mapred-default.xml）<table><tr><td>配置参数</td><td>参数说明</td></tr><tr><td>mapreduce.task.io.sort.mb</td><td>Shuffle的环形缓冲区大小，默认100m</td></tr><tr><td>mapreduce.map.sort.spill.percent</td><td>环形缓冲区溢出的阈值，默认80%</td></tr></table></li></ol><h3 id="容错相关参数-MapReduce性能优化"><a href="#容错相关参数-MapReduce性能优化" class="headerlink" title="容错相关参数(MapReduce性能优化)"></a>容错相关参数(MapReduce性能优化)</h3><table><tr><td>配置参数</td><td>参数说明</td></tr><tr><td>mapreduce.map.maxattempts</td><td>每个Map Task最大重试次数，一旦重试参数超过该值，则认为Map Task运行失败，默认值：4。</td></tr><tr><td>mapreduce.reduce.maxattempts</td><td>每个Reduce Task最大重试次数，一旦重试参数超过该值，则认为Map Task运行失败，默认值：4。</td></tr><tr><td>mapreduce.task.timeout</td><td>Task超时时间，经常需要设置的一个参数，该参数表达的意思为：如果一个Task在一定时间内没有任何进入，即不会读取新的数据，也没有输出数据，则认为该Task处于Block状态，可能是卡住了，也许永远会卡住，为了防止因为用户程序永远Block住不退出，则强制设置了一个该超时时间（单位毫秒），默认是600000。如果你的程序对每条输入数据的处理时间过长（比如会访问数据库，通过网络拉取数据等），建议将该参数调大，该参数过小常出现的错误提示是“AttemptID:attempt_14267829456721_123456_m_000224_0 Timed out after 300 secsContainer killed by the ApplicationMaster.”。</td></tr></table><h2 id="HDFS小文件优化方法"><a href="#HDFS小文件优化方法" class="headerlink" title="HDFS小文件优化方法"></a>HDFS小文件优化方法</h2><h3 id="HDFS小文件弊端"><a href="#HDFS小文件弊端" class="headerlink" title="HDFS小文件弊端"></a>HDFS小文件弊端</h3><p>HDFS上每个文件都要在NameNode上建立一个索引，这个索引的大小约为150byte，这样当小文件比较多的时候，就会产生很多的索引文件，一方面会大量占用NameNode的内存空间，另一方面就是索引文件过大使得索引速度变慢。</p><h3 id="HDFS小文件解决方案"><a href="#HDFS小文件解决方案" class="headerlink" title="HDFS小文件解决方案"></a>HDFS小文件解决方案</h3><p>小文件的优化无非以下几种方式：</p><ul><li>在数据采集的时候，就将小文件或小批数据合成大文件再上传HDFS。</li><li>在业务处理之前，在HDFS上使用MapReduce程序对小文件进行合并。</li><li>在MapReduce处理时，可采用CombineTextInputFormat提高效率。<ol><li><strong>Hadoop Archive</strong><br>是一个高效地将小文件放入HDFS块中的文件存档工具，它能够将多个小文件打包成一个HAR文件，这样就减少了NameNode的内存使用。</li><li><strong>Sequence File</strong><br>Sequence File由一系列的二进制key/value组成，如果key为文件名，value为文件内容，则可以将大批小文件合并成一个大文件。</li><li><strong>CombineFileInputFormat</strong><br>CombineFileInputFormat是一种新的InputFormat，用于将多个文件合并成一个单独的Split，另外，它会考虑数据的存储位置。</li><li><strong>开启JVM重用</strong></li></ol></li><li>对于大量小文件Job，可以开启JVM重用会减少45%运行时间。</li><li>JVM重用原理：一个Map运行在一个JVM上，开启重用的话，该Map在JVM上运行完毕后，JVM继续运行其他Map。</li><li>具体设置：mapreduce.job.jvm.numtasks值在10-20之间。</li></ul></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者:</span> <span class="post-copyright-info"><a href="https://www.jermyn.cn">Jermyn</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接:</span> <span class="post-copyright-info"><a href="https://www.jermyn.cn/posts/facf.html">https://www.jermyn.cn/posts/facf.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明:</span> <span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.jermyn.cn" target="_blank">Jermyn's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/hadoop/">hadoop</a><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></div><div class="post_share"><div class="social-share" data-image="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/006bf826d4ef7fff55821708a9726a2.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/77ed.html"><img class="prev-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/7c668fc4863f9534bfc36f9b42fd723.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Hadoop2.x源码编译</div></div></a></div><div class="next-post pull-right"><a href="/posts/eb1d.html"><img class="next-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/a2515c0b70892176ece5818b442caf1.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Linux基础命令</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/77ed.html" title="Hadoop2.x源码编译"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/7c668fc4863f9534bfc36f9b42fd723.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-25</div><div class="title">Hadoop2.x源码编译</div></div></a></div><div><a href="/posts/abe0.html" title="HadoopHA高可用"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/abe0/95f15711d8886628b17eb042029a7f9.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-07-12</div><div class="title">HadoopHA高可用</div></div></a></div><div><a href="/posts/3a9e.html" title="Hadoop3.x"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/3a9e/c5a81243b295e460476d240cd09e442.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-06</div><div class="title">Hadoop3.x</div></div></a></div><div><a href="/posts/f69d.html" title="Hive技术"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-07-12</div><div class="title">Hive技术</div></div></a></div><div><a href="/posts/9b06.html" title="zookeeper技术"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/9b06/a1c4c5ed718d3dcfacaa90f881266cd.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-07-10</div><div class="title">zookeeper技术</div></div></a></div><div><a href="/posts/e6c9.html" title="Jave基础编程"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/2.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-02</div><div class="title">Jave基础编程</div></div></a></div></div></div><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i> <span>评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/9a8a/auther.jpg" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">Jermyn</div><div class="author-info__description">个人学习笔记</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">19</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">23</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Jermyn-code"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/Jermyn-code" target="_blank" title="Github"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-github-fill"></use></svg></a><a class="social-icon faa-parent animated-hover" href="https://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=1773046949@qq.com" target="_blank" title="Email"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-mail"></use></svg></a><a class="social-icon faa-parent animated-hover" href="tencent://Message/?Uin=1773046949&amp;amp;websiteName=local.edu.com:8888=&amp;amp;Menu=yes" target="_blank" title="QQ"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-QQ1"></use></svg></a><a class="social-icon faa-parent animated-hover" href="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/qrcode.jpg" target="_blank" title="WeChat"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-weixin"></use></svg></a><a class="social-icon faa-parent animated-hover" href="https://www.instagram.com/born_in2084/" target="_blank" title="Instagram"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-instagram-fill"></use></svg></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">在读学习，联系我请+VX：AYOBRUH</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E7%AB%A0-Hadoop%E6%A1%86%E6%9E%B6"><span class="toc-number">1.</span> <span class="toc-text">第一章 Hadoop框架</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop1-x-%E5%92%8C-Hadoop2-x-%E5%8C%BA%E5%88%AB"><span class="toc-number">1.1.</span> <span class="toc-text">Hadoop1.x 和 Hadoop2.x 区别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0"><span class="toc-number">1.2.</span> <span class="toc-text">HDFS架构概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Yarn%E6%9E%B6%E6%9E%84"><span class="toc-number">1.3.</span> <span class="toc-text">Yarn架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0"><span class="toc-number">1.4.</span> <span class="toc-text">MapReduce架构概述</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E7%AB%A0-Hadoop%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA"><span class="toc-number">2.</span> <span class="toc-text">第二章 Hadoop运行环境搭建</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E7%AB%A0-Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="toc-number">3.</span> <span class="toc-text">第三章 Hadoop运行模式</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%AC%E5%9C%B0%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="toc-number">3.1.</span> <span class="toc-text">本地运行模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%98%E6%96%B9WordCount%E6%A1%88%E4%BE%8B"><span class="toc-number">3.1.1.</span> <span class="toc-text">官方WordCount案例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="toc-number">3.2.</span> <span class="toc-text">伪分布式运行模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4"><span class="toc-number">3.2.1.</span> <span class="toc-text">启动集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E6%93%8D%E4%BD%9C"><span class="toc-number">3.2.2.</span> <span class="toc-text">集群操作</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="toc-number">3.3.</span> <span class="toc-text">完全分布式运行模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#scp%EF%BC%88secure-copy%EF%BC%89%E5%AE%89%E5%85%A8%E6%8B%B7%E8%B4%9D"><span class="toc-number">3.3.1.</span> <span class="toc-text">scp（secure copy）安全拷贝</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rsync-%E8%BF%9C%E7%A8%8B%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7"><span class="toc-number">3.3.2.</span> <span class="toc-text">rsync 远程同步工具</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E5%86%99%E8%84%9A%E6%9C%AC%EF%BC%8C%E4%BD%BF%E7%94%A8xsync%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E5%9C%A8%E9%9B%86%E7%BE%A4%E4%B8%AD%E4%BC%A0%E8%BE%93"><span class="toc-number">3.3.3.</span> <span class="toc-text">编写脚本，使用xsync实现文件在集群中传输</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E8%A7%84%E5%88%92"><span class="toc-number">3.3.4.</span> <span class="toc-text">集群部署规划</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E5%8D%95%E7%82%B9%E5%90%AF%E5%8A%A8"><span class="toc-number">3.3.5.</span> <span class="toc-text">集群单点启动</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SSH%E6%97%A0%E5%AF%86%E7%99%BB%E5%BD%95%E9%85%8D%E7%BD%AE"><span class="toc-number">3.3.6.</span> <span class="toc-text">SSH无密登录配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E6%B5%8B%E8%AF%95%EF%BC%9A%E4%B8%8A%E4%BC%A0%E5%B0%8F%E6%96%87%E4%BB%B6%E5%92%8C%E5%A4%A7%E6%96%87%E4%BB%B6"><span class="toc-number">3.3.7.</span> <span class="toc-text">集群基本测试：上传小文件和大文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hadoop%E7%9B%B8%E5%85%B3%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4"><span class="toc-number">3.3.8.</span> <span class="toc-text">hadoop相关执行命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5"><span class="toc-number">3.3.9.</span> <span class="toc-text">集群时间同步</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E7%AB%A0-HDFS-%E6%A6%82%E8%BF%B0"><span class="toc-number">4.</span> <span class="toc-text">第四章 HDFS 概述</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">4.1.</span> <span class="toc-text">HDFS优缺点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E7%BB%84%E6%88%90%E6%9E%B6%E6%9E%84"><span class="toc-number">4.2.</span> <span class="toc-text">HDFS组成架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E5%9D%97%E5%A4%A7%E5%B0%8F"><span class="toc-number">4.3.</span> <span class="toc-text">HDFS文件块大小</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%94%E7%AB%A0-HDFS%E7%9A%84Shell%E6%93%8D%E4%BD%9C"><span class="toc-number">5.</span> <span class="toc-text">第五章 HDFS的Shell操作</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%AE%9E%E6%93%8D"><span class="toc-number">5.1.</span> <span class="toc-text">常用命令实操</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%85%AD%E7%AB%A0-HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C"><span class="toc-number">6.</span> <span class="toc-text">第六章 HDFS客户端操作</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="toc-number">6.1.</span> <span class="toc-text">HDFS客户端环境准备</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E7%9A%84API%E6%93%8D%E4%BD%9C"><span class="toc-number">6.2.</span> <span class="toc-text">HDFS的API操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%EF%BC%88%E6%B5%8B%E8%AF%95%E5%8F%82%E6%95%B0%E4%BC%98%E5%85%88%E7%BA%A7%EF%BC%89"><span class="toc-number">6.2.1.</span> <span class="toc-text">HDFS文件上传（测试参数优先级）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD"><span class="toc-number">6.2.2.</span> <span class="toc-text">HDFS文件下载</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E7%9A%84%E5%88%A0%E9%99%A4"><span class="toc-number">6.2.3.</span> <span class="toc-text">HDFS文件的删除</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E5%90%8D%E6%9B%B4%E6%94%B9"><span class="toc-number">6.2.4.</span> <span class="toc-text">HDFS文件名更改</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E8%AF%A6%E6%83%85%E6%9F%A5%E7%9C%8B"><span class="toc-number">6.2.5.</span> <span class="toc-text">HDFS文件详情查看</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E5%92%8C%E6%96%87%E4%BB%B6%E5%A4%B9%E5%88%A4%E6%96%AD"><span class="toc-number">6.2.6.</span> <span class="toc-text">HDFS文件和文件夹判断</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E7%9A%84I-O%E6%B5%81%E6%93%8D%E4%BD%9C"><span class="toc-number">6.3.</span> <span class="toc-text">HDFS的I&#x2F;O流操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0"><span class="toc-number">6.3.1.</span> <span class="toc-text">HDFS文件上传</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD-1"><span class="toc-number">6.3.2.</span> <span class="toc-text">HDFS文件下载</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%BD%8D%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96"><span class="toc-number">6.3.3.</span> <span class="toc-text">定位文件读取</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%83%E7%AB%A0-HDFS%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81"><span class="toc-number">7.</span> <span class="toc-text">第七章 HDFS的数据流</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B"><span class="toc-number">7.1.</span> <span class="toc-text">HDFS写数据流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%96%E6%9E%90%E6%96%87%E4%BB%B6%E5%86%99%E5%85%A5"><span class="toc-number">7.1.1.</span> <span class="toc-text">剖析文件写入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E6%8B%93%E6%89%91-%E8%8A%82%E7%82%B9%E8%B7%9D%E7%A6%BB%E8%AE%A1%E7%AE%97"><span class="toc-number">7.1.2.</span> <span class="toc-text">网络拓扑-节点距离计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%BA%E6%9E%B6%E6%84%9F%E7%9F%A5%EF%BC%88%E5%89%AF%E6%9C%AC%E5%AD%98%E5%82%A8%E8%8A%82%E7%82%B9%E9%80%89%E6%8B%A9%EF%BC%89"><span class="toc-number">7.1.3.</span> <span class="toc-text">机架感知（副本存储节点选择）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E8%AF%BB%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B"><span class="toc-number">7.2.</span> <span class="toc-text">HDFS读数据流程</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%85%AB%E7%AB%A0-NameNode%E5%92%8CSecondaryNameNode"><span class="toc-number">8.</span> <span class="toc-text">第八章 NameNode和SecondaryNameNode</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#NN%E5%92%8C2NN%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="toc-number">8.1.</span> <span class="toc-text">NN和2NN工作机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NN%E5%92%8C2NN%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3%EF%BC%9A"><span class="toc-number">8.2.</span> <span class="toc-text">NN和2NN工作机制详解：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Fsimage%E5%92%8CEdits%E8%A7%A3%E6%9E%90"><span class="toc-number">8.3.</span> <span class="toc-text">Fsimage和Edits解析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#oiv%E6%9F%A5%E7%9C%8BFsimage%E6%96%87%E4%BB%B6"><span class="toc-number">8.3.1.</span> <span class="toc-text">oiv查看Fsimage文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#oev%E6%9F%A5%E7%9C%8BEdits%E6%96%87%E4%BB%B6"><span class="toc-number">8.3.2.</span> <span class="toc-text">oev查看Edits文件</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CheckPoint%E6%97%B6%E9%97%B4%E8%AE%BE%E7%BD%AE"><span class="toc-number">8.4.</span> <span class="toc-text">CheckPoint时间设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NameNode%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86"><span class="toc-number">8.5.</span> <span class="toc-text">NameNode故障处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E5%AE%89%E5%85%A8%E6%A8%A1%E5%BC%8F"><span class="toc-number">8.6.</span> <span class="toc-text">集群安全模式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NameNode%E5%A4%9A%E7%9B%AE%E5%BD%95%E9%85%8D%E7%BD%AE"><span class="toc-number">8.7.</span> <span class="toc-text">NameNode多目录配置</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B9%9D%E7%AB%A0-DataNode"><span class="toc-number">9.</span> <span class="toc-text">第九章 DataNode</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#DataNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="toc-number">9.1.</span> <span class="toc-text">DataNode工作机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7"><span class="toc-number">9.2.</span> <span class="toc-text">数据完整性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%89%E7%BA%BF%E6%97%B6%E9%99%90%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE"><span class="toc-number">9.3.</span> <span class="toc-text">掉线时限参数设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%8D%E5%BD%B9%E6%96%B0%E6%95%B0%E6%8D%AE%E8%8A%82%E7%82%B9-%E6%B7%BB%E5%8A%A0%E6%96%B0%E5%B7%A5%E4%BD%9C%E8%8A%82%E7%82%B9"><span class="toc-number">9.4.</span> <span class="toc-text">服役新数据节点(添加新工作节点)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%80%E5%BD%B9%E6%97%A7%E6%95%B0%E6%8D%AE%E8%8A%82%E7%82%B9"><span class="toc-number">9.5.</span> <span class="toc-text">退役旧数据节点</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0%E7%99%BD%E5%90%8D%E5%8D%95"><span class="toc-number">9.5.1.</span> <span class="toc-text">添加白名单</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%BB%91%E5%90%8D%E5%8D%95%E9%80%80%E5%BD%B9"><span class="toc-number">9.5.2.</span> <span class="toc-text">黑名单退役</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Datanode%E5%A4%9A%E7%9B%AE%E5%BD%95%E9%85%8D%E7%BD%AE"><span class="toc-number">9.6.</span> <span class="toc-text">Datanode多目录配置</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%8D%81%E7%AB%A0-HDFS-2-X%E6%96%B0%E7%89%B9%E6%80%A7"><span class="toc-number">10.</span> <span class="toc-text">第十章 HDFS 2.X新特性</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E9%97%B4%E6%95%B0%E6%8D%AE%E6%8B%B7%E8%B4%9D"><span class="toc-number">10.1.</span> <span class="toc-text">集群间数据拷贝</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E6%96%87%E4%BB%B6%E5%AD%98%E6%A1%A3"><span class="toc-number">10.2.</span> <span class="toc-text">小文件存档</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9E%E6%94%B6%E7%AB%99"><span class="toc-number">10.3.</span> <span class="toc-text">回收站</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BF%AB%E7%85%A7%E7%AE%A1%E7%90%86"><span class="toc-number">10.4.</span> <span class="toc-text">快照管理</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0-MapReduce%E6%A6%82%E8%BF%B0"><span class="toc-number">11.</span> <span class="toc-text">第十一章 MapReduce概述</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">11.1.</span> <span class="toc-text">MapReduce优缺点</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E7%82%B9"><span class="toc-number">11.1.1.</span> <span class="toc-text">优点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9"><span class="toc-number">11.1.2.</span> <span class="toc-text">缺点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="toc-number">11.2.</span> <span class="toc-text">MapReduce核心思想</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce%E8%BF%9B%E7%A8%8B"><span class="toc-number">11.3.</span> <span class="toc-text">MapReduce进程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E5%BA%8F%E5%88%97%E5%8C%96%E7%B1%BB%E5%9E%8B"><span class="toc-number">11.4.</span> <span class="toc-text">常用数据序列化类型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce%E7%BC%96%E7%A8%8B%E8%A7%84%E8%8C%83"><span class="toc-number">11.5.</span> <span class="toc-text">MapReduce编程规范</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#WordCount%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="toc-number">11.6.</span> <span class="toc-text">WordCount案例实操</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0-Hadoop%E5%BA%8F%E5%88%97%E5%8C%96"><span class="toc-number">12.</span> <span class="toc-text">第十二章 Hadoop序列化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89bean%E5%AF%B9%E8%B1%A1%E5%AE%9E%E7%8E%B0%E5%BA%8F%E5%88%97%E5%8C%96%E6%8E%A5%E5%8F%A3%EF%BC%88Writable%EF%BC%89"><span class="toc-number">12.1.</span> <span class="toc-text">自定义bean对象实现序列化接口（Writable）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%8F%E5%88%97%E5%8C%96%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="toc-number">12.2.</span> <span class="toc-text">序列化案例实操</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%8D%81%E4%B8%89%E7%AB%A0-MapReduce%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86"><span class="toc-number">13.</span> <span class="toc-text">第十三章 MapReduce框架原理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#InputFormat%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5"><span class="toc-number">13.1.</span> <span class="toc-text">InputFormat数据输入</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%87%E7%89%87%E4%B8%8EMapTask%E5%B9%B6%E8%A1%8C%E5%BA%A6%E5%86%B3%E5%AE%9A%E6%9C%BA%E5%88%B6"><span class="toc-number">13.1.1.</span> <span class="toc-text">切片与MapTask并行度决定机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Job%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B%E6%BA%90%E7%A0%81%E5%92%8C%E5%88%87%E7%89%87%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3"><span class="toc-number">13.1.2.</span> <span class="toc-text">Job提交流程源码和切片源码详解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FileInputFormat%E5%88%87%E7%89%87%E6%9C%BA%E5%88%B6"><span class="toc-number">13.1.3.</span> <span class="toc-text">FileInputFormat切片机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CombineTextInputFormat%E5%88%87%E7%89%87%E6%9C%BA%E5%88%B6-%E5%B0%8F%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86"><span class="toc-number">13.1.4.</span> <span class="toc-text">CombineTextInputFormat切片机制(小文件处理)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CombineTextInputFormat%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="toc-number">13.1.5.</span> <span class="toc-text">CombineTextInputFormat案例实操</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FileInputFormat%E5%AE%9E%E7%8E%B0%E7%B1%BB"><span class="toc-number">13.1.6.</span> <span class="toc-text">FileInputFormat实现类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KeyValueTextInputFormat%E4%BD%BF%E7%94%A8%E6%A1%88%E4%BE%8B"><span class="toc-number">13.1.7.</span> <span class="toc-text">KeyValueTextInputFormat使用案例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NLineInputFormat%E4%BD%BF%E7%94%A8%E6%A1%88%E4%BE%8B"><span class="toc-number">13.1.8.</span> <span class="toc-text">NLineInputFormat使用案例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89InputFormat%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D-%E5%B0%8F%E6%96%87%E4%BB%B6"><span class="toc-number">13.1.9.</span> <span class="toc-text">自定义InputFormat案例实操(小文件)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">13.2.</span> <span class="toc-text">MapReduce工作流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce%E8%AF%A6%E7%BB%86%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E4%B8%80%EF%BC%88Map%EF%BC%89"><span class="toc-number">13.2.1.</span> <span class="toc-text">MapReduce详细工作流程一（Map）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce%E8%AF%A6%E7%BB%86%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E4%B8%80%EF%BC%88Reduce%EF%BC%89"><span class="toc-number">13.2.2.</span> <span class="toc-text">MapReduce详细工作流程一（Reduce）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B5%81%E7%A8%8B%E8%AF%A6%E8%A7%A3"><span class="toc-number">13.2.3.</span> <span class="toc-text">流程详解</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Shuffle%E6%9C%BA%E5%88%B6"><span class="toc-number">13.3.</span> <span class="toc-text">Shuffle机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Shuffle%E6%9C%BA%E5%88%B6-1"><span class="toc-number">13.3.1.</span> <span class="toc-text">Shuffle机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Partition%E5%88%86%E5%8C%BA"><span class="toc-number">13.3.2.</span> <span class="toc-text">Partition分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Partition%E5%88%86%E5%8C%BA%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="toc-number">13.3.3.</span> <span class="toc-text">Partition分区案例实操</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#WritableComparable%E6%8E%92%E5%BA%8F"><span class="toc-number">13.3.4.</span> <span class="toc-text">WritableComparable排序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#WritableComparable%E6%8E%92%E5%BA%8F%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D%EF%BC%88%E5%85%A8%E6%8E%92%E5%BA%8F%EF%BC%89"><span class="toc-number">13.3.5.</span> <span class="toc-text">WritableComparable排序案例实操（全排序）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#WritableComparable%E6%8E%92%E5%BA%8F%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D%EF%BC%88%E5%8C%BA%E5%86%85%E6%8E%92%E5%BA%8F%EF%BC%89"><span class="toc-number">13.3.6.</span> <span class="toc-text">WritableComparable排序案例实操（区内排序）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Combiner%E5%90%88%E5%B9%B6-%E4%BC%98%E5%8C%96"><span class="toc-number">13.3.7.</span> <span class="toc-text">Combiner合并(优化)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Combiner%E5%90%88%E5%B9%B6%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="toc-number">13.3.8.</span> <span class="toc-text">Combiner合并案例实操</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GroupingComparator%E5%88%86%E7%BB%84%EF%BC%88%E8%BE%85%E5%8A%A9%E6%8E%92%E5%BA%8F%EF%BC%89"><span class="toc-number">13.3.9.</span> <span class="toc-text">GroupingComparator分组（辅助排序）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GroupingComparator%E5%88%86%E7%BB%84%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="toc-number">13.3.10.</span> <span class="toc-text">GroupingComparator分组案例实操</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapTask%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="toc-number">13.4.</span> <span class="toc-text">MapTask工作机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ReduceTask%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="toc-number">13.5.</span> <span class="toc-text">ReduceTask工作机制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#OutputFormat%E6%95%B0%E6%8D%AE%E8%BE%93%E5%87%BA"><span class="toc-number">13.6.</span> <span class="toc-text">OutputFormat数据输出</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#OutputFormat%E6%8E%A5%E5%8F%A3%E5%AE%9E%E7%8E%B0%E7%B1%BB"><span class="toc-number">13.6.1.</span> <span class="toc-text">OutputFormat接口实现类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89OutputFormat"><span class="toc-number">13.6.2.</span> <span class="toc-text">自定义OutputFormat</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89OutputFormat%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="toc-number">13.6.3.</span> <span class="toc-text">自定义OutputFormat案例实操</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Join%E5%A4%9A%E7%A7%8D%E5%BA%94%E7%94%A8"><span class="toc-number">13.7.</span> <span class="toc-text">Join多种应用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Reduce-Join"><span class="toc-number">13.7.1.</span> <span class="toc-text">Reduce Join</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reduce-Join%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="toc-number">13.7.2.</span> <span class="toc-text">Reduce Join案例实操</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Map-Join"><span class="toc-number">13.7.3.</span> <span class="toc-text">Map Join</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Map-Join%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="toc-number">13.7.4.</span> <span class="toc-text">Map Join案例实操</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A1%E6%95%B0%E5%99%A8%E5%BA%94%E7%94%A8"><span class="toc-number">13.8.</span> <span class="toc-text">计数器应用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%EF%BC%88ETL%EF%BC%89"><span class="toc-number">13.9.</span> <span class="toc-text">数据清洗（ETL）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D-%E7%AE%80%E5%8D%95%E8%A7%A3%E6%9E%90%E7%89%88"><span class="toc-number">13.9.1.</span> <span class="toc-text">数据清洗案例实操-简单解析版</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D-%E5%A4%8D%E6%9D%82%E8%A7%A3%E6%9E%90%E7%89%88"><span class="toc-number">13.9.2.</span> <span class="toc-text">数据清洗案例实操-复杂解析版</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0-MapReduce%E5%BC%80%E5%8F%91%E6%80%BB%E7%BB%93"><span class="toc-number">14.</span> <span class="toc-text">第十四章 MapReduce开发总结</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%E6%8E%A5%E5%8F%A3%EF%BC%9AInputFormat"><span class="toc-number">14.1.</span> <span class="toc-text">输入数据接口：InputFormat</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E5%A4%84%E7%90%86%E6%8E%A5%E5%8F%A3%EF%BC%9AMapper"><span class="toc-number">14.2.</span> <span class="toc-text">逻辑处理接口：Mapper</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Partitioner%E5%88%86%E5%8C%BA"><span class="toc-number">14.3.</span> <span class="toc-text">Partitioner分区</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Comparable%E6%8E%92%E5%BA%8F"><span class="toc-number">14.4.</span> <span class="toc-text">Comparable排序</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Combiner%E5%90%88%E5%B9%B6"><span class="toc-number">14.5.</span> <span class="toc-text">Combiner合并</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reduce%E7%AB%AF%E5%88%86%E7%BB%84%EF%BC%9AGroupingComparator"><span class="toc-number">14.6.</span> <span class="toc-text">Reduce端分组：GroupingComparator</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E5%A4%84%E7%90%86%E6%8E%A5%E5%8F%A3%EF%BC%9AReducer"><span class="toc-number">14.7.</span> <span class="toc-text">逻辑处理接口：Reducer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BE%93%E5%87%BA%E6%95%B0%E6%8D%AE%E6%8E%A5%E5%8F%A3%EF%BC%9AOutputFormat"><span class="toc-number">14.8.</span> <span class="toc-text">输出数据接口：OutputFormat</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Driver%E9%A9%B1%E5%8A%A8%E7%B1%BB"><span class="toc-number">14.9.</span> <span class="toc-text">Driver驱动类</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%8D%81%E4%BA%94%E7%AB%A0-Hadoop%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9"><span class="toc-number">15.</span> <span class="toc-text">第十五章 Hadoop数据压缩</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0"><span class="toc-number">15.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MR%E6%94%AF%E6%8C%81%E7%9A%84%E5%8E%8B%E7%BC%A9%E7%BC%96%E7%A0%81"><span class="toc-number">15.2.</span> <span class="toc-text">MR支持的压缩编码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8E%8B%E7%BC%A9%E6%96%B9%E5%BC%8F%E9%80%89%E6%8B%A9"><span class="toc-number">15.3.</span> <span class="toc-text">压缩方式选择</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Gzip%E5%8E%8B%E7%BC%A9"><span class="toc-number">15.3.1.</span> <span class="toc-text">Gzip压缩</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Bzip2%E5%8E%8B%E7%BC%A9"><span class="toc-number">15.3.2.</span> <span class="toc-text">Bzip2压缩</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Lzo%E5%8E%8B%E7%BC%A9"><span class="toc-number">15.3.3.</span> <span class="toc-text">Lzo压缩</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Snappy%E5%8E%8B%E7%BC%A9"><span class="toc-number">15.3.4.</span> <span class="toc-text">Snappy压缩</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8E%8B%E7%BC%A9%E4%BD%8D%E7%BD%AE%E9%80%89%E6%8B%A9"><span class="toc-number">15.4.</span> <span class="toc-text">压缩位置选择</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8E%8B%E7%BC%A9%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE"><span class="toc-number">15.5.</span> <span class="toc-text">压缩参数配置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8E%8B%E7%BC%A9%E5%AE%9E%E6%93%8D%E6%A1%88%E4%BE%8B"><span class="toc-number">15.6.</span> <span class="toc-text">压缩实操案例</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%B5%81%E7%9A%84%E5%8E%8B%E7%BC%A9%E5%92%8C%E8%A7%A3%E5%8E%8B%E7%BC%A9"><span class="toc-number">15.6.1.</span> <span class="toc-text">数据流的压缩和解压缩</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Map%E8%BE%93%E5%87%BA%E7%AB%AF%E9%87%87%E7%94%A8%E5%8E%8B%E7%BC%A9"><span class="toc-number">15.6.2.</span> <span class="toc-text">Map输出端采用压缩</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reduce%E8%BE%93%E5%87%BA%E7%AB%AF%E9%87%87%E7%94%A8%E5%8E%8B%E7%BC%A9"><span class="toc-number">15.6.3.</span> <span class="toc-text">Reduce输出端采用压缩</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%8D%81%E5%85%AD%E7%AB%A0-Yarn%E8%B5%84%E6%BA%90%E8%B0%83%E5%BA%A6%E5%99%A8"><span class="toc-number">16.</span> <span class="toc-text">第十六章 Yarn资源调度器</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Yarn%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84"><span class="toc-number">16.1.</span> <span class="toc-text">Yarn基本架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Yarn%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6"><span class="toc-number">16.2.</span> <span class="toc-text">Yarn工作机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Yarn%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6"><span class="toc-number">16.2.1.</span> <span class="toc-text">Yarn运行机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3"><span class="toc-number">16.2.2.</span> <span class="toc-text">工作机制详解</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A%E6%8F%90%E4%BA%A4%E5%85%A8%E8%BF%87%E7%A8%8B"><span class="toc-number">16.3.</span> <span class="toc-text">作业提交全过程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A%E6%8F%90%E4%BA%A4%E8%BF%87%E7%A8%8B%E4%B9%8BYARN"><span class="toc-number">16.3.1.</span> <span class="toc-text">作业提交过程之YARN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A%E6%8F%90%E4%BA%A4%E8%BF%87%E7%A8%8B%E4%B9%8BMapReduce"><span class="toc-number">16.3.2.</span> <span class="toc-text">作业提交过程之MapReduce</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B5%84%E6%BA%90%E8%B0%83%E5%BA%A6%E5%99%A8"><span class="toc-number">16.4.</span> <span class="toc-text">资源调度器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%88%E8%BF%9B%E5%85%88%E5%87%BA%E8%B0%83%E5%BA%A6%E5%99%A8%EF%BC%88FIFO%EF%BC%89"><span class="toc-number">16.4.1.</span> <span class="toc-text">先进先出调度器（FIFO）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%B9%E9%87%8F%E8%B0%83%E5%BA%A6%E5%99%A8%EF%BC%88Capacity-Scheduler%EF%BC%89"><span class="toc-number">16.4.2.</span> <span class="toc-text">容量调度器（Capacity Scheduler）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AC%E5%B9%B3%E8%B0%83%E5%BA%A6%E5%99%A8%EF%BC%88Fair-Scheduler%EF%BC%89"><span class="toc-number">16.4.3.</span> <span class="toc-text">公平调度器（Fair Scheduler）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%8E%A8%E6%B5%8B%E6%89%A7%E8%A1%8C"><span class="toc-number">16.5.</span> <span class="toc-text">任务的推测执行</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%8D%81%E4%B8%83%E7%AB%A0-Hadoop%E4%BC%81%E4%B8%9A%E4%BC%98%E5%8C%96"><span class="toc-number">17.</span> <span class="toc-text">第十七章 Hadoop企业优化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95"><span class="toc-number">17.1.</span> <span class="toc-text">MapReduce优化方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5"><span class="toc-number">17.1.1.</span> <span class="toc-text">数据输入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Map%E9%98%B6%E6%AE%B5"><span class="toc-number">17.1.2.</span> <span class="toc-text">Map阶段</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reduce%E9%98%B6%E6%AE%B5"><span class="toc-number">17.1.3.</span> <span class="toc-text">Reduce阶段</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#I-O%E4%BC%A0%E8%BE%93"><span class="toc-number">17.1.4.</span> <span class="toc-text">I&#x2F;O传输</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E9%97%AE%E9%A2%98"><span class="toc-number">17.1.5.</span> <span class="toc-text">数据倾斜问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E7%9A%84%E8%B0%83%E4%BC%98%E5%8F%82%E6%95%B0"><span class="toc-number">17.2.</span> <span class="toc-text">常用的调优参数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B5%84%E6%BA%90%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0"><span class="toc-number">17.2.1.</span> <span class="toc-text">资源相关参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%B9%E9%94%99%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0-MapReduce%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96"><span class="toc-number">17.2.2.</span> <span class="toc-text">容错相关参数(MapReduce性能优化)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E5%B0%8F%E6%96%87%E4%BB%B6%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95"><span class="toc-number">17.3.</span> <span class="toc-text">HDFS小文件优化方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E5%B0%8F%E6%96%87%E4%BB%B6%E5%BC%8A%E7%AB%AF"><span class="toc-number">17.3.1.</span> <span class="toc-text">HDFS小文件弊端</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E5%B0%8F%E6%96%87%E4%BB%B6%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-number">17.3.2.</span> <span class="toc-text">HDFS小文件解决方案</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/f69d.html" title="Hive技术"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Hive技术"></a><div class="content"><a class="title" href="/posts/f69d.html" title="Hive技术">Hive技术</a><time datetime="2023-07-12T22:02:21.000Z" title="发表于 2023-07-12 22:02:21">2023-07-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/abe0.html" title="HadoopHA高可用"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/abe0/95f15711d8886628b17eb042029a7f9.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="HadoopHA高可用"></a><div class="content"><a class="title" href="/posts/abe0.html" title="HadoopHA高可用">HadoopHA高可用</a><time datetime="2023-07-12T00:35:13.000Z" title="发表于 2023-07-12 00:35:13">2023-07-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/9b06.html" title="zookeeper技术"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/9b06/a1c4c5ed718d3dcfacaa90f881266cd.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="zookeeper技术"></a><div class="content"><a class="title" href="/posts/9b06.html" title="zookeeper技术">zookeeper技术</a><time datetime="2023-07-10T11:35:16.000Z" title="发表于 2023-07-10 11:35:16">2023-07-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/3a9e.html" title="Hadoop3.x"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/3a9e/c5a81243b295e460476d240cd09e442.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Hadoop3.x"></a><div class="content"><a class="title" href="/posts/3a9e.html" title="Hadoop3.x">Hadoop3.x</a><time datetime="2023-06-06T21:12:09.000Z" title="发表于 2023-06-06 21:12:09">2023-06-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/77ed.html" title="Hadoop2.x源码编译"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/facf/7c668fc4863f9534bfc36f9b42fd723.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Hadoop2.x源码编译"></a><div class="content"><a class="title" href="/posts/77ed.html" title="Hadoop2.x源码编译">Hadoop2.x源码编译</a><time datetime="2023-05-25T18:12:54.000Z" title="发表于 2023-05-25 18:12:54">2023-05-25</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2023 By Jermyn</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i> <span>数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo.jermyn.cn/',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo.jermyn.cn/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><div class="aplayer no-destroy" data-id="8670693070" data-server="tencent" data-type="playlist" data-order="list" data-fixed="true" data-preload="auto" data-autoplay="false" data-mutex="true"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><div class="app-refresh" id="app-refresh" style="position:fixed;top:-2.2rem;left:0;right:0;z-index:99999;padding:0 1rem;font-size:15px;height:2.2rem;transition:all .3s ease"><div class="app-refresh-wrap" style="display:flex;color:#fff;height:100%;align-items:center;justify-content:center"><label>✨ 有新文章啦！ 👉</label><a href="javascript:void(0)" onclick="location.reload()"><span style="color:#fff;text-decoration:underline;cursor:pointer">🍗点击食用🍔</span></a></div></div><script>if ('serviceWorker' in navigator) {
if (navigator.serviceWorker.controller) {
navigator.serviceWorker.addEventListener('controllerchange', function() {
showNotification()
})
}
window.addEventListener('load', function() {
navigator.serviceWorker.register('/sw.js')
})
}
function showNotification() {
if (GLOBAL_CONFIG.Snackbar) {
var snackbarBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
GLOBAL_CONFIG.Snackbar.bgLight :
GLOBAL_CONFIG.Snackbar.bgDark
var snackbarPos = GLOBAL_CONFIG.Snackbar.position
Snackbar.show({
text: '✨ 有新文章啦！ 👉',
backgroundColor: snackbarBg,
duration: 500000,
pos: snackbarPos,
actionText: '🍗点击食用🍔',
actionTextColor: '#fff',
onActionClick: function(e) {
location.reload()
},
})
} else {
var showBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
'#49b1f5' :
'#1f1f1f'
var cssText = `top: 0; background: ${showBg};`
document.getElementById('app-refresh').style.cssText = cssText
}
}</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script data-pjax>function butterfly_clock_anzhiyu_injector_config(){var e=document.getElementsByClassName("sticky_layout")[0];console.log("已挂载butterfly_clock_anzhiyu"),e&&e.insertAdjacentHTML("afterbegin",'<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>')}for(var elist="null".split(","),cpage=location.pathname,epage="all",qweather_key="0f5e430e0ec2485a8e175000f1ca33eb",gaud_map_key="163f0b807c26d68365ae5f029f76cf19",baidu_ak_key="undefined",flag=0,clock_rectangle="111.62,33.79",clock_default_rectangle_enable="false",i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;"all"===epage&&0==flag?butterfly_clock_anzhiyu_injector_config():epage===cpage&&butterfly_clock_anzhiyu_injector_config()</script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.js"></script><script data-pjax>function butterfly_footer_beautify_injector_config(){var A=document.getElementById("footer-wrap");console.log("已挂载butterfly_footer_beautify"),A.insertAdjacentHTML("beforeend",'<div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v5.4.0" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" data-title="主题版本Butterfly_v4.2.2" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://cloud.tencent.com/" style="margin-inline:5px" data-title="本站使用JsDelivr为静态资源提供CDN加速" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/CDN-Tencent-blue?style=flat&amp;logo=iCloud" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/Jermyn-code" style="margin-inline:5px" data-title="本站项目由Github托管" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></p>')}for(var elist="null".split(","),cpage=location.pathname,epage="all",flag=0,i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;"all"===epage&&0==flag?butterfly_footer_beautify_injector_config():epage===cpage&&butterfly_footer_beautify_injector_config()</script><script async src="/js/runtime/runtime.min.js"></script><script data-pjax>function butterfly_swiper_injector_config(){var a=document.getElementById("recent-posts");console.log("已挂载butterfly_swiper"),a.insertAdjacentHTML("afterbegin",'<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/9a8a.html" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/1.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-10-02</span><a class="blog-slider__title" href="posts/9a8a.html" alt="">Java高级编程</a><div class="blog-slider__text">Java学习笔记，Java基础阶段的高级编程，包含多线程，Java常用类，枚举类&amp;注解，Java集合，泛型，IO流，网络编程，Java反射机制，Java8的其他新特性，Java9&amp;10&amp;11新特性，文档资源来自尚硅谷，整理为博主，在此感谢尚硅谷无私分享大量的学习资源。</div><a class="blog-slider__button" href="posts/9a8a.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/ba42.html" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/3.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-08-26</span><a class="blog-slider__title" href="posts/ba42.html" alt="">Hadoop集群脚本部署</a><div class="blog-slider__text">Hadoop脚本部署，包含7个shell脚本，以及一个ip.txt文件，建议运行顺序为00-06</div><a class="blog-slider__button" href="posts/ba42.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/ef13.html" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/6.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-08-27</span><a class="blog-slider__title" href="posts/ef13.html" alt="">大数据集群服务部署</a><div class="blog-slider__text">本文为大数据集群服务的部署文档,包括zookeeper服务部署,Hadoop服务部署,Spark服务部署,Kafka服务部署,Hbase服务部署,Hive服务部署</div><a class="blog-slider__button" href="posts/ef13.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/d746.html" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/9a8a/8.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-08-26</span><a class="blog-slider__title" href="posts/d746.html" alt="">shell 学习笔记</a><div class="blog-slider__text">shell脚本学习笔记，学完可自行编写shell脚本</div><a class="blog-slider__button" href="posts/d746.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/e6c9.html" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/2.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-09-02</span><a class="blog-slider__title" href="posts/e6c9.html" alt="">Jave基础编程</a><div class="blog-slider__text">Java学习笔记，Java基础阶段的基础编程，包含Java语言概述，基本语法，数组，面向对象编程，异常处理。文档资源来自尚硅谷，整理为博主，在此感谢尚硅谷无私分享大量的学习资源。</div><a class="blog-slider__button" href="posts/e6c9.html" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>')}for(var elist="undefined".split(","),cpage=location.pathname,epage="all",flag=0,i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;"all"===epage&&0==flag?butterfly_swiper_injector_config():epage===cpage&&butterfly_swiper_injector_config()</script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><div class="js-pjax"><script async>for(var arr=document.getElementsByClassName("recent-post-item"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__zoomIn"),arr[i].setAttribute("data-wow-duration","1.5s"),arr[i].setAttribute("data-wow-delay","200ms"),arr[i].setAttribute("data-wow-offset","30"),arr[i].setAttribute("data-wow-iteration","1")</script><script async>for(var arr=document.getElementsByClassName("card-widget"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__zoomIn"),arr[i].setAttribute("data-wow-duration",""),arr[i].setAttribute("data-wow-delay","200ms"),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("flink-list-card"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__flipInY"),arr[i].setAttribute("data-wow-duration","3s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("flink-list-card"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__animated"),arr[i].setAttribute("data-wow-duration","3s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("article-sort-item"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__slideInRight"),arr[i].setAttribute("data-wow-duration","1.5s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("site-card"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__flipInY"),arr[i].setAttribute("data-wow-duration","3s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("site-card"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__animated"),arr[i].setAttribute("data-wow-duration","3s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script></div><script defer src="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/wow_init.js"></script><script async src="//at.alicdn.com/t/c/font_3617685_a7gpo3nfht.js"></script></body></html>