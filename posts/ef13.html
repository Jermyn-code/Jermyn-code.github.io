<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>大数据集群服务部署 | Jermyn's blog</title><meta name="keywords" content="大数据集群服务"><meta name="author" content="Jermyn,born_in2084@yeah.net"><meta name="copyright" content="Jermyn"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本文为大数据集群服务的部署文档,包括zookeeper服务部署,Hadoop服务部署,Spark服务部署,Kafka服务部署,Hbase服务部署,Hive服务部署"><meta property="og:type" content="article"><meta property="og:title" content="大数据集群服务部署"><meta property="og:url" content="https://www.jermyn.cn/posts/ef13.html"><meta property="og:site_name" content="Jermyn&#39;s blog"><meta property="og:description" content="本文为大数据集群服务的部署文档,包括zookeeper服务部署,Hadoop服务部署,Spark服务部署,Kafka服务部署,Hbase服务部署,Hive服务部署"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/6.png"><meta property="article:published_time" content="2022-08-27T13:53:29.000Z"><meta property="article:modified_time" content="2023-05-25T09:09:57.978Z"><meta property="article:author" content="Jermyn"><meta property="article:tag" content="zookeeper"><meta property="article:tag" content="linux"><meta property="article:tag" content="大数据服务部署"><meta property="article:tag" content="Hadoop"><meta property="article:tag" content="Spark"><meta property="article:tag" content="Kafka"><meta property="article:tag" content="Hbase"><meta property="article:tag" content="Hive"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/6.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://www.jermyn.cn/posts/ef13"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="manifest" href="/manifest.json"><meta name="msapplication-TileColor" content="#49b1f5"><link rel="apple-touch-icon" sizes="180x180" href="/img/siteicon/128.png"><link rel="icon" type="image/png" sizes="32x32" href="/img/siteicon/32.png"><link rel="icon" type="image/png" sizes="16x16" href="/img/siteicon/16.png"><link rel="mask-icon" href="/img/siteicon/128.png" color="#5bbad5"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"大数据集群服务部署",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2023-05-25 09:09:57"}</script><noscript><style>#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.css"><link rel="stylesheet" href="/js/runtime/runtime.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload='this.media="screen"'><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload='this.media="all"'><script src="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="Jermyn's blog" type="application/atom+xml"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/9a8a/auther.jpg" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">21</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><span>留言</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><span>档案</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><span>音乐</span></a></div><div class="menus_item"><a class="site-page" href="/bangumis/index.html"><span>番剧</span></a></div><div class="menus_item"><a class="site-page" href="/books"><span>书籍</span></a></div><div class="menus_item"><a class="site-page" href="/movies/"><span>影视</span></a></div><div class="menus_item"><a class="site-page" href="/games/"><span>游戏</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/6.png)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Jermyn's blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i> <span>搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/comments/"><span>留言</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><span>档案</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><span>友链</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><span>音乐</span></a></div><div class="menus_item"><a class="site-page" href="/bangumis/index.html"><span>番剧</span></a></div><div class="menus_item"><a class="site-page" href="/books"><span>书籍</span></a></div><div class="menus_item"><a class="site-page" href="/movies/"><span>影视</span></a></div><div class="menus_item"><a class="site-page" href="/games/"><span>游戏</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">大数据集群服务部署</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-08-27T13:53:29.000Z" title="发表于 2022-08-27 13:53:29">2022-08-27</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-05-25T09:09:57.978Z" title="更新于 2023-05-25 09:09:57">2023-05-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">12.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>57分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="大数据集群服务部署"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><div class="note blue icon-padding simple"><i class="note-icon fas fa-bullhorn"></i><p>本文为大数据集群服务的部署文档<br>包括zookeeper服务部署,Hadoop服务部署,Spark服务部署,Kafka服务部署,Hbase服务部署,Hive服务部署<br>文档写于2022年初作为学习笔记使用。</p></div><div class="tip fa-atom"><p>系统版本：CentOS Linux release 7.9.2009 (Core)<br>内核版本：3.10.0-1160.el7.x86_64<br>内存：4GB<br>处理器数量（p）：2<br>每个处理器的内核数量（c）：2<br>硬盘：30GB</p></div><div class="tip fa-gamepad faa-horizontal animated"><p>前置：主机相关配置</p></div><div class="table-container"><table><thead><tr><th>Hostname</th><th>IPADDR</th><th>NETMASK</th><th>GATWAY</th><th>DNS1</th><th>ROLE</th><th>USR</th><th>PASSWORD</th></tr></thead><tbody><tr><td>master</td><td>192.168.88.135</td><td>255.255.255.0</td><td>192.168.88.2</td><td>8.8.8.8</td><td>NN DN RM NM</td><td>root</td><td>Ccu2021@</td></tr><tr><td>slave1</td><td>192.168.88.136</td><td>255.255.255.0</td><td>192.168.88.2</td><td>8.8.8.8</td><td>SNN DN NM</td><td>root</td><td>Ccu2021@</td></tr><tr><td>slave2</td><td>192.168.88.137</td><td>255.255.255.0</td><td>192.168.88.2</td><td>8.8.8.8</td><td>DN NM</td><td>root</td><td>Ccu2021@</td></tr></tbody></table></div><div class="tip fa-gamepad faa-horizontal animated"><p>规划：所有组件包均在 /export/server 文件目录下</p></div><div class="table-container"><table><thead><tr><th style="text-align:left">组件</th><th style="text-align:left">版本</th><th style="text-align:left">启动命令</th><th style="text-align:left">WebUI</th></tr></thead><tbody><tr><td style="text-align:left">zookeeper</td><td style="text-align:left">zookeeper-3.4.10 后期改为zookeeper-3.7.0</td><td style="text-align:left">zkServer-all.sh start</td><td style="text-align:left">暂无</td></tr><tr><td style="text-align:left">hadoop</td><td style="text-align:left">hadoop-3.3.0</td><td style="text-align:left">start-all.sh</td><td style="text-align:left"><a target="_blank" rel="noopener" href="http://master:9870/">http://master:9870/</a> <a target="_blank" rel="noopener" href="http://master:8088/">http://master:8088/</a></td></tr><tr><td style="text-align:left">spark</td><td style="text-align:left">spark-3.2.0</td><td style="text-align:left">cd /export/server/spark/bin ./pyspark</td><td style="text-align:left"><a target="_blank" rel="noopener" href="http://master:4040/">http://master:4040/</a></td></tr><tr><td style="text-align:left">spark-history</td><td style="text-align:left">同spark版本</td><td style="text-align:left">cd /export/server/spark/sbin ./start-history-server.sh</td><td style="text-align:left"><a target="_blank" rel="noopener" href="http://master:18080/">http://master:18080/</a></td></tr><tr><td style="text-align:left">hbase</td><td style="text-align:left">hbase-1.2.4</td><td style="text-align:left">cd /export/server/hbase/bin ./start-hbase.sh</td><td style="text-align:left"><a target="_blank" rel="noopener" href="http://master:16010/master-status">http://master:16010/master-status</a></td></tr><tr><td style="text-align:left">Mysql</td><td style="text-align:left">MySQL5.7</td><td style="text-align:left">启动：/etc/init.d/mysqld start 登录：mysql -u root -p</td><td style="text-align:left">暂无</td></tr><tr><td style="text-align:left">jdk</td><td style="text-align:left">jdk_1.8.0_241</td><td style="text-align:left">暂无</td><td style="text-align:left">暂无</td></tr><tr><td style="text-align:left">kafka</td><td style="text-align:left">kafka_2.11-2.0.0</td><td style="text-align:left">kafka-all.sh start</td><td style="text-align:left">暂无</td></tr><tr><td style="text-align:left">hadoop-history</td><td style="text-align:left">同hadoop版本</td><td style="text-align:left">cd /export/server/hadoop-3.3.0/sbin ./mr-jobhistory-daemon.sh start historyserver</td><td style="text-align:left"><a target="_blank" rel="noopener" href="http://master:19888/">http://master:19888/</a></td></tr><tr><td style="text-align:left">python</td><td style="text-align:left">python-3.8.8</td><td style="text-align:left">python</td><td style="text-align:left">暂无</td></tr><tr><td style="text-align:left">hive</td><td style="text-align:left">hive-3.0.0</td><td style="text-align:left">hive</td><td style="text-align:left">暂无</td></tr></tbody></table></div><h1 id="网络环境配置"><a href="#网络环境配置" class="headerlink" title="网络环境配置"></a>网络环境配置</h1><ul><li><p>更改三台主机的主机名</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># master</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;master&quot;</span> &gt;/etc/hostname</span><br><span class="line"></span><br><span class="line"><span class="comment"># slave1</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;slave1&quot;</span> &gt;/etc/hostname</span><br><span class="line"></span><br><span class="line"><span class="comment"># slave2</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;slave2&quot;</span> &gt;/etc/hostname</span><br></pre></td></tr></table></figure></li><li><p>更改网络配置（注：三台主机都需要做）</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入路径 /etc/sysconfig/network-scripts 编辑ifcfg-ens33文件</span></span><br><span class="line">vim /etc/sysconfig/network<span class="literal">-scripts</span>/ifcfg<span class="literal">-ens33</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置ONBOOT=yes:表示启动这块网卡</span></span><br><span class="line"><span class="comment"># 配置BOOTPROTO=static：表示静态路由协议，可以保持IP固定</span></span><br><span class="line"><span class="comment"># 配置IPADDR:表示虚拟机的IP地址，这里设置的IP地址要与前面IP映射配置时的IP地址一致，否则无法通过主机名找到对应IP;</span></span><br><span class="line"><span class="comment"># 配置GATEWAY:表示虚拟机网关,通常都是将IP地址最后一个位数变为2;</span></span><br><span class="line"><span class="comment"># 配置NETMASK:表示虚拟机子网掩码,通常都是255.255.255.0;</span></span><br><span class="line"><span class="comment"># 配置DNS1:表示域名解析器，此处采用Google提供的免费DNS服务器88.8.8(也可以设置为PC端电脑对应的DNS)。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># master</span></span><br><span class="line">IPADDR=<span class="number">192.168</span>.<span class="number">88.135</span></span><br><span class="line">NETMASK=<span class="number">255.255</span>.<span class="number">255.0</span></span><br><span class="line">GATEWAY=<span class="number">192.168</span>.<span class="number">88.2</span></span><br><span class="line">DNS1=<span class="number">8.8</span>.<span class="number">8.8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># slave1</span></span><br><span class="line">IPADDR=<span class="number">192.168</span>.<span class="number">88.135</span></span><br><span class="line">NETMASK=<span class="number">255.255</span>.<span class="number">255.0</span></span><br><span class="line">GATEWAY=<span class="number">192.168</span>.<span class="number">88.2</span></span><br><span class="line">DNS1=<span class="number">8.8</span>.<span class="number">8.8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># slave2</span></span><br><span class="line">IPADDR=<span class="number">192.168</span>.<span class="number">88.135</span></span><br><span class="line">NETMASK=<span class="number">255.255</span>.<span class="number">255.0</span></span><br><span class="line">GATEWAY=<span class="number">192.168</span>.<span class="number">88.2</span></span><br><span class="line">DNS1=<span class="number">8.8</span>.<span class="number">8.8</span></span><br></pre></td></tr></table></figure></li><li><p>前两步骤做完后三台主机进行重启</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shutdown <span class="literal">-r</span> <span class="number">0</span></span><br></pre></td></tr></table></figure></li><li><p>测试（注：三台主机都做ping，看是否ping通外网）</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping www.baidu.com <span class="literal">-c5</span></span><br></pre></td></tr></table></figure></li></ul><h1 id="hosts映射"><a href="#hosts映射" class="headerlink" title="hosts映射"></a>hosts映射</h1><p>打开一个hosts映射文件,为了保证后续相互关联的虚拟机能够通过主机名进行访问，根据实际需求配置对应的IP和主机名映射，分别将主机名master、slave1、slave2 与IP地址 192.168.88.134、192.168.88.135 和192.168.88.136进行了匹配映射(这里通常要根据实际需要，将要搭建的集群主机都配置主机名和IP映射)。</p><ul><li><p>编辑 /etc/hosts 文件</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/hosts</span><br></pre></td></tr></table></figure></li><li><p>内容修改为（注：三台主机内容一样）</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">127.0</span>.<span class="number">0.1</span>   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::<span class="number">1</span>         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"></span><br><span class="line"><span class="number">192.168</span>.<span class="number">88.135</span>  master</span><br><span class="line"><span class="number">192.168</span>.<span class="number">88.136</span>  slave1</span><br><span class="line"><span class="number">192.168</span>.<span class="number">88.137</span>  slave2</span><br></pre></td></tr></table></figure></li></ul><h1 id="集群配置时间同步"><a href="#集群配置时间同步" class="headerlink" title="集群配置时间同步"></a>集群配置时间同步</h1><p>定义：网络时间服务协议（Network Time Protocol, NTP），是用来使计算机时间同步化的一种协议，它可以使计算机对其服务器做时间同步化。</p><p>原因：时间同步服务器，顾名思义就是来同步时间的。在集群中同步时间有着十分重要的作用，负载均衡集群或高可用集群如果时间不一致，在服务器之间的数据误差就会很大，寻找数据便会成为一件棘手的事情。若是时间无法同步，那么就算是备份了数据，你也可能无法在正确的时间将正确的数据备份。那损失可就大了。</p><ul><li><p>yum 安装 ntp （注：三台主机做同样操作）</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install ntp <span class="literal">-y</span></span><br></pre></td></tr></table></figure></li><li><p>开机自启动ntp</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable ntpd  &amp;&amp; systemctl start ntpd</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">结果显示：</span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># systemctl enable ntpd  &amp;&amp; systemctl start ntpd</span></span><br><span class="line">Created symlink from /etc/systemd/system/multi<span class="literal">-user</span>.target.wants/ntpd.service to /usr/lib/systemd/system/ntpd.service.</span><br></pre></td></tr></table></figure></li><li><p>授权 192.168.88.0-192.168.10.255 网段上的所有机器可以从这台机器上查询和同步时间</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看ntp配置文件</span></span><br><span class="line"> <span class="built_in">ls</span> <span class="literal">-al</span> /etc | grep <span class="string">&#x27;ntp&#x27;</span></span><br><span class="line"><span class="comment"># 显示内容</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">etc</span>]<span class="comment"># ls -al /etc | grep &#x27;ntp&#x27;</span></span><br><span class="line">drwxr<span class="literal">-xr-x</span>   <span class="number">3</span> root root       <span class="number">52</span> <span class="number">3</span>月  <span class="number">10</span> <span class="number">18</span>:<span class="number">25</span> ntp</span><br><span class="line"><span class="literal">-rw-r--r--</span>   <span class="number">1</span> root root     <span class="number">2041</span> <span class="number">3</span>月  <span class="number">10</span> <span class="number">20</span>:<span class="number">03</span> ntp.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑内容添加 restrict 192.168.88.0 mask 255.255.255.0 （注：在17行左右）</span></span><br><span class="line">vim /etc/ntp.conf </span><br><span class="line"></span><br><span class="line"><span class="number">16</span> <span class="comment"># Hosts on local network are less restricted.</span></span><br><span class="line"><span class="number">17</span> restrict <span class="number">192.168</span>.<span class="number">88.0</span> mask <span class="number">255.255</span>.<span class="number">255.0</span></span><br></pre></td></tr></table></figure></li><li><p>集群在局域网中，不使用其他互联网上的时间</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改 /etc/ntpd.conf 内容</span></span><br><span class="line">vim /etc/ntp.conf </span><br><span class="line"></span><br><span class="line"><span class="comment"># 将21-24行内容注释掉（注：原来未注释）</span></span><br><span class="line"> <span class="number">21</span> <span class="comment">#server 0.centos.pool.ntp.org iburst</span></span><br><span class="line"> <span class="number">22</span> <span class="comment">#server 1.centos.pool.ntp.org iburst</span></span><br><span class="line"> <span class="number">23</span> <span class="comment">#server 2.centos.pool.ntp.org iburst</span></span><br><span class="line"> <span class="number">24</span> <span class="comment">#server 3.centos.pool.ntp.org iburst</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在25行添加 server masterIP 即为：</span></span><br><span class="line">server <span class="number">192.168</span>.<span class="number">88.135</span></span><br><span class="line">server <span class="number">127.127</span>.<span class="number">1.0</span> iburst</span><br></pre></td></tr></table></figure></li><li><p>slave1 和 slave2 相同操作</p></li><li><p>三台主机同时执行</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable ntpd  &amp;&amp; systemctl <span class="built_in">start</span> ntpd</span><br></pre></td></tr></table></figure></li><li><p>查看ntp端口</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">etc</span>]<span class="comment"># ss -tupln | grep &#x27;123&#x27;</span></span><br><span class="line">udp    UNCONN     <span class="number">0</span>      <span class="number">0</span>      <span class="number">192.168</span>.<span class="number">88.135</span>:<span class="number">123</span>                   *:*                   users:((<span class="string">&quot;ntpd&quot;</span>,pid=<span class="number">54823</span>,fd=<span class="number">19</span>))</span><br><span class="line">udp    UNCONN     <span class="number">0</span>      <span class="number">0</span>      <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">123</span>                   *:*                   users:((<span class="string">&quot;ntpd&quot;</span>,pid=<span class="number">54823</span>,fd=<span class="number">18</span>))</span><br><span class="line">udp    UNCONN     <span class="number">0</span>      <span class="number">0</span>         *:<span class="number">123</span>                   *:*                   users:((<span class="string">&quot;ntpd&quot;</span>,pid=<span class="number">54823</span>,fd=<span class="number">16</span>))</span><br><span class="line">udp    UNCONN     <span class="number">0</span>      <span class="number">0</span>      [<span class="type">fe80</span>::<span class="number">2832</span>:<span class="number">5</span><span class="type">f98</span>:<span class="number">5</span><span class="type">bc0</span>:<span class="type">e621</span>]%ens33:<span class="number">123</span>                [::]:*                   users:((<span class="string">&quot;ntpd&quot;</span>,pid=<span class="number">54823</span>,fd=<span class="number">23</span>))</span><br><span class="line">udp    UNCONN     <span class="number">0</span>      <span class="number">0</span>         [::<span class="number">1</span>]:<span class="number">123</span>                [::]:*                   users:((<span class="string">&quot;ntpd&quot;</span>,pid=<span class="number">54823</span>,fd=<span class="number">20</span>))</span><br><span class="line">udp    UNCONN     <span class="number">0</span>      <span class="number">0</span>      [::]:<span class="number">123</span>                [::]:*                   users:((<span class="string">&quot;ntpd&quot;</span>,pid=<span class="number">54823</span>,fd=<span class="number">17</span>))</span><br></pre></td></tr></table></figure></li><li><p>配置完成后三台主机都需要重启</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shutdown <span class="literal">-r</span> <span class="number">0</span></span><br></pre></td></tr></table></figure></li><li><p>三台主机同时执行（注：此过程需要5分钟左右）</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ntpstat</span><br></pre></td></tr></table></figure></li></ul><h1 id="ssh免密钥登陆"><a href="#ssh免密钥登陆" class="headerlink" title="ssh免密钥登陆"></a>ssh免密钥登陆</h1><p>​ SSH免密钥登陆<strong>可以更加方便的实现不同计算机之间的连接和切换</strong></p><ul><li><p>master 生成公钥私钥 (一路回车)</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh<span class="literal">-keygen</span>  </span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#结果显示：</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">.ssh</span>]<span class="comment"># ssh-keygen </span></span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file <span class="keyword">in</span> which to save the key (/root/.ssh/id_rsa): </span><br><span class="line">Enter passphrase (empty <span class="keyword">for</span> no passphrase): </span><br><span class="line">Enter same passphrase again: </span><br><span class="line">Your identification has been saved <span class="keyword">in</span> /root/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved <span class="keyword">in</span> /root/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">SHA256:QUAgFH5KBc/Erlf1JWSBbKeEepPJqMBqpWbc02/uFj8 root@master</span><br><span class="line">The key<span class="string">&#x27;s randomart image is:</span></span><br><span class="line"><span class="string">+---[RSA 2048]----+</span></span><br><span class="line"><span class="string">| .=++oo+.o+.     |</span></span><br><span class="line"><span class="string">| . *. ..*.o .    |</span></span><br><span class="line"><span class="string">|. o.++ *.+ o     |</span></span><br><span class="line"><span class="string">|.o ++ B ...      |</span></span><br><span class="line"><span class="string">|o.=o.o .S        |</span></span><br><span class="line"><span class="string">|.*oo.. .         |</span></span><br><span class="line"><span class="string">|+  .. . o        |</span></span><br><span class="line"><span class="string">|       + E       |</span></span><br><span class="line"><span class="string">|      =o  .      |</span></span><br><span class="line"><span class="string">+----[SHA256]-----+</span></span><br></pre></td></tr></table></figure></li><li><p>查看隐藏的 .ssh 文件</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">la <span class="literal">-al</span> .ssh</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 结果显示</span></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># ls -al .ssh/</span></span><br><span class="line">总用量 <span class="number">16</span></span><br><span class="line">drwx<span class="literal">------</span>  <span class="number">2</span> root root   <span class="number">80</span> <span class="number">3</span>月  <span class="number">10</span> <span class="number">21</span>:<span class="number">52</span> .</span><br><span class="line">dr<span class="literal">-xr-x---</span>. <span class="number">4</span> root root  <span class="number">175</span> <span class="number">3</span>月  <span class="number">10</span> <span class="number">21</span>:<span class="number">45</span> ..</span><br><span class="line"><span class="literal">-rw-------</span>  <span class="number">1</span> root root  <span class="number">393</span> <span class="number">3</span>月  <span class="number">10</span> <span class="number">21</span>:<span class="number">52</span> authorized_keys</span><br><span class="line"><span class="literal">-rw-------</span>  <span class="number">1</span> root root <span class="number">1675</span> <span class="number">3</span>月  <span class="number">10</span> <span class="number">21</span>:<span class="number">48</span> id_rsa</span><br><span class="line"><span class="literal">-rw-r--r--</span>  <span class="number">1</span> root root  <span class="number">393</span> <span class="number">3</span>月  <span class="number">10</span> <span class="number">21</span>:<span class="number">48</span> id_rsa.pub</span><br><span class="line"><span class="literal">-rw-r--r--</span>  <span class="number">1</span> root root  <span class="number">366</span> <span class="number">3</span>月  <span class="number">10</span> <span class="number">21</span>:<span class="number">54</span> known_hosts</span><br></pre></td></tr></table></figure></li><li><p>master 配置免密登录到master slave1 slave2</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh<span class="literal">-copy-id</span> master</span><br><span class="line">ssh<span class="literal">-copy-id</span> slave1</span><br><span class="line">ssh<span class="literal">-copy-id</span> slave2</span><br></pre></td></tr></table></figure></li></ul><h1 id="安装配置-jdk"><a href="#安装配置-jdk" class="headerlink" title="安装配置 jdk"></a>安装配置 jdk</h1><ul><li><p>编译环境软件安装目录</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir <span class="literal">-p</span> /export/server</span><br></pre></td></tr></table></figure></li><li><p>JDK 1.8安装 上传 jdk-8u241-linux-x64.tar.gz到/export/server/目录下 并解压文件</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar <span class="literal">-zxvf</span> jdk<span class="literal">-8u241-linux-x64</span>.tar.gz</span><br></pre></td></tr></table></figure></li><li><p>配置环境变量</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">export JAVA_HOME=/export/server/jdk1.<span class="number">8.0</span>_241</span><br><span class="line">export PATH=<span class="variable">$PATH:</span><span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line">export CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/lib/tools.jar</span><br></pre></td></tr></table></figure></li><li><p>重新加载环境变量文件</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></li><li><p>查看 java 版本号</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">结果显示：</span><br><span class="line">[root@master jdk1.8.0_241]# java -version</span><br><span class="line">java version &quot;1.8.0_241&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_241-b07)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.241-b07, mixed mode)</span><br></pre></td></tr></table></figure></li><li><p>master 节点将 java 传输到 slave1 和 slave2</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r /export/server/jdk1.8.0_241/ root@slave1:/export/server/</span><br><span class="line">scp -r /export/server/jdk1.8.0_241/ root@slave2:/export/server/</span><br></pre></td></tr></table></figure></li><li><p>配置 slave1 和 slave2 的 jdk 环境变量（注：和上方 master 的配置方法一样）</p></li><li><p>在 master slave1 和slave2 创建软连接</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server</span><br><span class="line"></span><br><span class="line">ln <span class="literal">-s</span> jdk1.<span class="number">8.0</span>_241/ jdk</span><br></pre></td></tr></table></figure></li><li><p>重新加载环境变量文件</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></li></ul><h1 id="zookeeper安装配置"><a href="#zookeeper安装配置" class="headerlink" title="zookeeper安装配置"></a>zookeeper安装配置</h1><ul><li><p>配置主机名和IP的映射关系，修改 /etc/hosts 文件，添加 master.root slave1.root slave2.root</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/hosts</span><br><span class="line"></span><br><span class="line"><span class="comment">#结果显示</span></span><br><span class="line"><span class="number">127.0</span>.<span class="number">0.1</span>   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::<span class="number">1</span>         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"></span><br><span class="line"><span class="number">192.168</span>.<span class="number">88.135</span>  master  master.root</span><br><span class="line"><span class="number">192.168</span>.<span class="number">88.136</span>  slave1  slave1.root</span><br><span class="line"><span class="number">192.168</span>.<span class="number">88.137</span>  slave2  slave2.root</span><br></pre></td></tr></table></figure></li><li><p>zookeeper安装 上传 zookeeper-3.4.10.tar.gz到/export/server/目录下 并解压文件</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server/</span><br><span class="line"></span><br><span class="line">tar <span class="literal">-zxvf</span> zookeeper<span class="literal">-3</span>.<span class="number">4.10</span>.tar.gz</span><br></pre></td></tr></table></figure></li><li><p>在 /export/server 目录下创建软连接</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server</span><br><span class="line"></span><br><span class="line">ln <span class="literal">-s</span> zookeeper<span class="literal">-3</span>.<span class="number">4.10</span>/ zookeeper</span><br></pre></td></tr></table></figure></li><li><p>进入 /export/server/zookeeper/conf/ 将 zoo_sample.cfg 文件复制为新文件 zoo.cfg</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server/zookeeper/conf/ </span><br><span class="line"></span><br><span class="line"><span class="built_in">cp</span> zoo_sample.cfg zoo.cfg</span><br></pre></td></tr></table></figure></li><li><p>接上步给 zoo.cfg 添加内容</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Zookeeper的数据存放目录</span></span><br><span class="line"></span><br><span class="line">dataDir=/export/server/zookeeper/zkdatas</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保留多少个快照</span></span><br><span class="line">autopurge.snapRetainCount=<span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 日志多少小时清理一次</span></span><br><span class="line">autopurge.purgeInterval=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 集群中服务器地址</span></span><br><span class="line">server.<span class="number">1</span>=master:<span class="number">2888</span>:<span class="number">3888</span></span><br><span class="line">server.<span class="number">2</span>=slave1:<span class="number">2888</span>:<span class="number">3888</span></span><br><span class="line">server.<span class="number">3</span>=slave2:<span class="number">2888</span>:<span class="number">3888</span></span><br></pre></td></tr></table></figure></li><li><p>进入 /export/server/zookeeper/zkdatas 目录在此目录下创建 myid 文件，将 1 写入进去</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server/zookeeper/zkdata</span><br><span class="line"></span><br><span class="line">touch myid</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;1&#x27;</span> &gt; myid</span><br></pre></td></tr></table></figure></li><li><p>将 master 节点中 /export/server/zookeeper-3.4.10 路径下内容推送给slave1 和 slave2</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp <span class="literal">-r</span> /export/server/zookeeper<span class="literal">-3</span>.<span class="number">4.10</span>/ slave1:<span class="variable">$PWD</span></span><br><span class="line"></span><br><span class="line">scp <span class="literal">-r</span> /export/server/zookeeper<span class="literal">-3</span>.<span class="number">4.10</span>/ slave2:<span class="variable">$PWD</span></span><br></pre></td></tr></table></figure></li><li><p>推送成功后，分别在 slave1 和 slave2 上创建软连接</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln <span class="literal">-s</span> zookeeper<span class="literal">-3</span>.<span class="number">4.10</span>/ zookeeper</span><br></pre></td></tr></table></figure></li><li><p>接上步推送完成后将 slave1 和 slave2 的 /export/server/zookeeper/zkdatas/ 文件夹下的 myid 中的内容分别改为 2 和 3</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server/zookeeper/zkdatas/</span><br><span class="line">结果显示：</span><br><span class="line">[<span class="type">root</span>@<span class="type">slave1</span> <span class="type">zkdatas</span>]<span class="comment"># vim myid </span></span><br><span class="line">[<span class="type">root</span>@<span class="type">slave1</span> <span class="type">zkdatas</span>]<span class="comment"># more myid </span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"></span><br><span class="line">[<span class="type">root</span>@<span class="type">slave2</span> <span class="type">zkdatas</span>]<span class="comment"># vim myid </span></span><br><span class="line">[<span class="type">root</span>@<span class="type">slave2</span> <span class="type">zkdatas</span>]<span class="comment"># more myid </span></span><br><span class="line"><span class="number">3</span></span><br></pre></td></tr></table></figure></li><li><p><strong>配置zookeeper的环境变量（注：三台主机都需要配置）</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="comment"># zookeeper 环境变量</span></span><br><span class="line">export ZOOKEEPER_HOME=/export/server/zookeeper</span><br><span class="line">export PATH=<span class="variable">$PATH:</span><span class="variable">$ZOOKEEPER_HOME</span>/bin</span><br></pre></td></tr></table></figure></li><li><p>重新加载环境变量文件</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></li><li><p>进入 /export/server/zookeeper-3.4.10/bin 目录下启动 zkServer.sh 脚本 （注：三台都需要做）</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span>  /export/server/zookeeper<span class="literal">-3</span>.<span class="number">4.10</span>/bin </span><br><span class="line"></span><br><span class="line">zkServer.sh <span class="built_in">start</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">结果显示：</span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">bin</span>]<span class="comment"># ./zkServer.sh start</span></span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line"><span class="keyword">Using</span> config: /export/server/zookeeper-3.4.10/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br></pre></td></tr></table></figure></li><li><p>查看 zookeeper 的状态</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh status</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">结果显示：</span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">server</span>]<span class="comment"># zkServer.sh  status</span></span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line"><span class="keyword">Using</span> config: /export/server/zookeeper-3.4.10/bin/../conf/zoo.cfg</span><br><span class="line">Mode: follower</span><br><span class="line"></span><br><span class="line">[<span class="type">root</span>@<span class="type">slave1</span> <span class="type">server</span>]<span class="comment"># zkServer.sh  status</span></span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line"><span class="keyword">Using</span> config: /export/server/zookeeper-3.4.10/bin/../conf/zoo.cfg</span><br><span class="line">Mode: follower</span><br><span class="line"></span><br><span class="line">[<span class="type">root</span>@<span class="type">slave2</span> <span class="type">conf</span>]<span class="comment"># zkServer.sh  status</span></span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line"><span class="keyword">Using</span> config: /export/server/zookeeper-3.4.10/bin/../conf/zoo.cfg</span><br><span class="line">Mode: leader</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">结果显示：</span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> <span class="type">server</span>]<span class="comment"># jps</span></span><br><span class="line"><span class="number">125348</span> QuorumPeerMain</span><br><span class="line"><span class="number">16311</span> Jps</span><br><span class="line"></span><br><span class="line">[<span class="type">root</span>@<span class="type">slave1</span> <span class="type">server</span>]<span class="comment"># jps</span></span><br><span class="line"><span class="number">126688</span> QuorumPeerMain</span><br><span class="line"><span class="number">17685</span> Jps</span><br><span class="line"></span><br><span class="line">[<span class="type">root</span>@<span class="type">slave2</span> <span class="type">conf</span>]<span class="comment"># jps</span></span><br><span class="line"><span class="number">126733</span> QuorumPeerMain</span><br><span class="line"><span class="number">17727</span> Jps</span><br></pre></td></tr></table></figure></li><li><p>脚本一键启动</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">vim zkServer.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$</span><span class="comment"># -eq 0 ] ;</span></span><br><span class="line"><span class="type">then</span></span><br><span class="line">	<span class="type">echo</span> <span class="string">&quot;please input param:start stop&quot;</span></span><br><span class="line"><span class="type">else</span></span><br><span class="line"><span class="type">if</span> [ <span class="variable">$1</span> = <span class="type">start</span>  ] ;<span class="type">then</span>	</span><br><span class="line">	<span class="type">echo</span> <span class="string">&quot;<span class="variable">$</span>&#123;1&#125;ing master&quot;</span></span><br><span class="line">	<span class="type">ssh</span> <span class="type">master</span> <span class="string">&quot;source /etc/profile;/export/server/zookeeper/bin/zkServer.sh start&quot;</span></span><br><span class="line">	<span class="type">for</span> <span class="type">i</span> <span class="type">in</span> &#123;<span class="number">1</span><span class="type">..2</span>&#125;</span><br><span class="line">	<span class="type">do</span></span><br><span class="line">		<span class="type">echo</span> <span class="string">&quot;<span class="variable">$</span>&#123;1&#125;ping slave<span class="variable">$</span>&#123;i&#125;&quot;</span>	</span><br><span class="line">		<span class="type">ssh</span> <span class="type">slave</span><span class="variable">$</span>&#123;<span class="type">i</span>&#125; <span class="string">&quot;source /etc/profile;/export/server/zookeeper/bin/zkServer.sh start&quot;</span></span><br><span class="line">	<span class="type">done</span></span><br><span class="line"><span class="type">fi</span></span><br><span class="line"><span class="type">if</span> [ <span class="variable">$1</span> = <span class="type">stop</span> ];<span class="type">then</span></span><br><span class="line">	<span class="type">echo</span> <span class="string">&quot;<span class="variable">$</span>&#123;1&#125;ping master &quot;</span></span><br><span class="line">	<span class="type">ssh</span> <span class="type">master</span> <span class="string">&quot;source /etc/profile;/export/server/zookeeper/bin/zkServer.sh stop&quot;</span></span><br><span class="line">	<span class="type">for</span> <span class="type">i</span> <span class="type">in</span> &#123;<span class="number">1</span><span class="type">..2</span>&#125;</span><br><span class="line">	<span class="type">do</span></span><br><span class="line">		<span class="type">echo</span> <span class="string">&quot;<span class="variable">$</span>&#123;1&#125;ping slave<span class="variable">$</span>&#123;i&#125;&quot;</span>	</span><br><span class="line">		<span class="type">ssh</span> <span class="type">slave</span><span class="variable">$</span>&#123;<span class="type">i</span>&#125; <span class="string">&quot;source /etc/profile;/export/server/zookeeper/bin/zkServer.sh stop&quot;</span></span><br><span class="line">	<span class="type">done</span></span><br><span class="line"><span class="type">fi</span></span><br><span class="line"><span class="type">if</span> [ <span class="variable">$1</span> = <span class="type">status</span> ];<span class="type">then</span></span><br><span class="line">	<span class="type">echo</span> <span class="string">&quot;<span class="variable">$</span>&#123;1&#125;ing master&quot;</span></span><br><span class="line">	<span class="type">ssh</span> <span class="type">master</span> <span class="string">&quot;source /etc/profile;/export/server/zookeeper/bin/zkServer.sh status&quot;</span></span><br><span class="line">	<span class="type">for</span> <span class="type">i</span> <span class="type">in</span> &#123;<span class="number">1</span><span class="type">..2</span>&#125;</span><br><span class="line">	<span class="type">do</span></span><br><span class="line">	<span class="type">echo</span> <span class="string">&quot;<span class="variable">$</span>&#123;1&#125;ping slave<span class="variable">$</span>&#123;i&#125;&quot;</span></span><br><span class="line">	<span class="type">ssh</span> <span class="type">slave</span><span class="variable">$</span>&#123;<span class="type">i</span>&#125; <span class="string">&quot;source /etc/profile;/export/server/zookeeper/bin/zkServer.sh status&quot;</span></span><br><span class="line">	<span class="type">done</span></span><br><span class="line"><span class="type">fi</span></span><br><span class="line"><span class="type">fi</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将文件放在 /bin 目录下</span></span><br><span class="line">chmod +x zkServer<span class="literal">-all</span>.sh &amp;&amp; zkServer<span class="literal">-all</span>.sh</span><br></pre></td></tr></table></figure></li></ul><h1 id="Hadoop-安装配置"><a href="#Hadoop-安装配置" class="headerlink" title="Hadoop 安装配置"></a>Hadoop 安装配置</h1><ul><li><p>把 hadoop-3.3.0-Centos7-64-with-snappy.tar.gz 上传到 /export/server 并解压文件</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar <span class="literal">-zxvf</span> hadoop<span class="literal">-3</span>.<span class="number">3.0</span><span class="literal">-Centos7-64-with-snappy</span>.tar.gz</span><br></pre></td></tr></table></figure></li><li><p>修改配置文件(进入路径 /export/server/hadoop-3.3.0/etc/hadoop)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/hadoop-3.3.0/etc/hadoop</span><br></pre></td></tr></table></figure><ul><li><p>hadoop-env.sh</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#文件最后添加</span></span><br><span class="line">export JAVA_HOME=/export/server/jdk1.<span class="number">8.0</span>_241</span><br><span class="line">export HDFS_NAMENODE_USER=root</span><br><span class="line">export HDFS_DATANODE_USER=root</span><br><span class="line">export HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line">export YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">export YARN_NODEMANAGER_USER=root </span><br></pre></td></tr></table></figure></li></ul></li><li><p>core-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置默认使用的文件系统 Hadoop支持file、HDFS、GFS、ali|Amazon云等文件系统 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置Hadoop本地保存数据路径 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/export/data/hadoop-3.3.0<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置HDFS web UI用户身份 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 整合hive 用户代理设置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.root.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 文件系统垃圾桶保存时间 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1440<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>hdfs-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置SNN进程运行机器位置信息 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>slave1:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>mapred-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置MR程序默认运行模式： yarn集群模式 local本地模式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- MR程序历史服务地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">&lt;!-- MR程序历史服务器web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>yarn-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 设置YARN集群主角色运行机器位置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 是否将对容器实施物理内存限制 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 是否将对容器实施虚拟内存限制。 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 开启日志聚集 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 设置yarn历史服务器地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://master:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 历史日志保存的时间 7天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>workers</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure></li><li><p>分发同步hadoop安装包</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server</span><br><span class="line"></span><br><span class="line">scp <span class="literal">-r</span> hadoop<span class="literal">-3</span>.<span class="number">3.0</span> root@slave1:<span class="variable">$PWD</span></span><br><span class="line">scp <span class="literal">-r</span> hadoop<span class="literal">-3</span>.<span class="number">3.0</span> root@slave2:<span class="variable">$PWD</span></span><br></pre></td></tr></table></figure></li><li><p>将hadoop添加到环境变量</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">export HADOOP_HOME=/export/server/hadoop<span class="literal">-3</span>.<span class="number">3.0</span></span><br><span class="line">export PATH=<span class="variable">$PATH:</span><span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure></li><li><p>重新加载环境变量文件</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></li><li><p><strong>Hadoop集群启动</strong></p><ul><li><p>格式化namenode（只有首次启动需要格式化）</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode <span class="literal">-format</span></span><br></pre></td></tr></table></figure></li><li><p>脚本一键启动</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># start-dfs.sh </span></span><br><span class="line">Starting namenodes on [<span class="type">master</span>]</span><br><span class="line">上一次登录：五 <span class="number">3</span>月 <span class="number">11</span> <span class="number">21</span>:<span class="number">27</span>:<span class="number">24</span> CST <span class="number">2022</span>pts/<span class="number">0</span> 上</span><br><span class="line">Starting datanodes</span><br><span class="line">上一次登录：五 <span class="number">3</span>月 <span class="number">11</span> <span class="number">21</span>:<span class="number">27</span>:<span class="number">32</span> CST <span class="number">2022</span>pts/<span class="number">0</span> 上</span><br><span class="line">Starting secondary namenodes [<span class="type">slave1</span>]</span><br><span class="line">上一次登录：五 <span class="number">3</span>月 <span class="number">11</span> <span class="number">21</span>:<span class="number">27</span>:<span class="number">35</span> CST <span class="number">2022</span>pts/<span class="number">0</span> 上</span><br><span class="line"></span><br><span class="line">[<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># start-yarn.sh </span></span><br><span class="line">Starting resourcemanager</span><br><span class="line">上一次登录：五 <span class="number">3</span>月 <span class="number">11</span> <span class="number">21</span>:<span class="number">27</span>:<span class="number">41</span> CST <span class="number">2022</span>pts/<span class="number">0</span> 上</span><br><span class="line">Starting nodemanagers</span><br><span class="line">上一次登录：五 <span class="number">3</span>月 <span class="number">11</span> <span class="number">21</span>:<span class="number">27</span>:<span class="number">51</span> CST <span class="number">2022</span>pts/<span class="number">0</span> 上</span><br></pre></td></tr></table></figure></li><li><p>启动后 输入 jps 查看</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# jps</span><br><span class="line">127729 NameNode</span><br><span class="line">127937 DataNode</span><br><span class="line">14105 Jps</span><br><span class="line">128812 NodeManager</span><br><span class="line">128591 ResourceManager</span><br><span class="line"></span><br><span class="line">[root@slave1 hadoop]# jps</span><br><span class="line">121889 NodeManager</span><br><span class="line">121559 SecondaryNameNode</span><br><span class="line">7014 Jps</span><br><span class="line">121369 DataNode</span><br><span class="line"></span><br><span class="line">[root@slave2 hadoop]# jps</span><br><span class="line">6673 Jps</span><br><span class="line">121543 NodeManager</span><br><span class="line">121098 DataNode</span><br></pre></td></tr></table></figure></li><li><p>WEB页面</p></li><li><p>HDFS集群：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://master:9870/</span><br></pre></td></tr></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.328888.xyz/2022/08/27/G8T5C.png" alt="image-20220405131530881"></p></li></ul></li></ul><ul><li><p>YARN集群：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://master:<span class="number">8088</span>/</span><br></pre></td></tr></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.328888.xyz/2022/08/27/G83vU.png" alt="image-20220405131613474"></p></li></ul><p>​</p><h1 id="Spark安装配置"><a href="#Spark安装配置" class="headerlink" title="Spark安装配置"></a>Spark安装配置</h1><p>Spark是专为大规模数据处理而设计的快速通用的计算引擎，其提供了一个全面、统一的框架用于管理各种不同性质的数据集和数据源的大数据处理的需求，大数据开发需掌握Spark基础、SparkJob、Spark RDD、spark job部署与资源分配、Spark shuffle、Spark内存管理、Spark广播变量、Spark SQL、Spark Streaming以及Spark ML等相关知识。</p><h2 id="Spark-local模式"><a href="#Spark-local模式" class="headerlink" title="Spark-local模式"></a>Spark-local模式</h2><p>本地模式(单机) 本地模式就是以一个独立的进程,通过其内部的多个线程来模拟整个Spark运行时环境</p><ul><li><p>Anaconda On Linux 安装 (单台服务器脚本安装)</p></li><li><p>安装上传安装包: 资料中提供的Anaconda3-2021.05-Linux-x86_64.sh文件到Linux服务器上安装位置在 /export/server:</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行文件</span></span><br><span class="line">sh Anaconda3<span class="literal">-2021</span>.<span class="number">05</span><span class="literal">-Linux-x86_64</span>.sh</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">过程显示：</span><br><span class="line">...</span><br><span class="line"><span class="comment"># 出现内容选 yes</span></span><br><span class="line">Please answer <span class="string">&#x27;yes&#x27;</span> or <span class="string">&#x27;no&#x27;</span>:<span class="string">&#x27;</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; yes</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 出现添加路径：/export/server/anaconda3</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">[/root/anaconda3] &gt;&gt;&gt; /export/server/anaconda3</span></span><br><span class="line"><span class="string">PREFIX=/export/server/anaconda3</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure></li><li><p>安装完成后, 退出终端， 重新进来:</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">exit</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">结果显示：</span><br><span class="line"># 看到这个Base开头表明安装好了.base是默认的虚拟环境.</span><br><span class="line">Last login: Tue Mar 15 15:28:59 2022 from 192.168.88.1</span><br><span class="line">(base) [root@master ~]# </span><br></pre></td></tr></table></figure></li><li><p>创建虚拟环境 pyspark 基于 python3.8</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create <span class="literal">-n</span> pyspark python=<span class="number">3.8</span> </span><br></pre></td></tr></table></figure></li><li><p>切换到虚拟环境内</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate pyspark  </span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">结果显示：</span><br><span class="line">(base) [<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># conda activate pyspark  </span></span><br><span class="line">(pyspark) [<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># </span></span><br></pre></td></tr></table></figure></li><li><p>在虚拟环境内安装包 （有WARNING不用管）</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyhive pyspark jieba <span class="literal">-i</span> https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure></li><li><p>spark 安装</p></li><li><p>将文件上传到 /export/server 里面 ，解压</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压</span></span><br><span class="line">tar <span class="literal">-zxvf</span> spark<span class="literal">-3</span>.<span class="number">2.0</span><span class="literal">-bin-hadoop3</span>.<span class="number">2</span>.tgz <span class="literal">-C</span> /export/server/</span><br></pre></td></tr></table></figure></li><li><p>建立软连接</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln <span class="literal">-s</span> /export/server/spark<span class="literal">-3</span>.<span class="number">2.0</span><span class="literal">-bin-hadoop3</span>.<span class="number">2</span> /export/server/spark</span><br></pre></td></tr></table></figure></li></ul><ul><li>添加环境变量<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SPARK_HOME: 表示Spark安装路径在哪里</span><br><span class="line">PYSPARK_PYTHON: 表示Spark想运行Python程序, 那么去哪里找python执行器</span><br><span class="line">JAVA_HOME: 告知Spark Java在哪里</span><br><span class="line">HADOOP_CONF_DIR: 告知Spark Hadoop的配置文件在哪里</span><br><span class="line">HADOOP_HOME: 告知Spark  Hadoop安装在哪里</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>修改环境变量</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">添加内容：</span><br><span class="line"></span><br><span class="line">.....</span><br><span class="line">注：此部分之前配置过，此部分不需要在配置</span><br><span class="line"><span class="comment">#JAVA_HOME</span></span><br><span class="line">export JAVA_HOME=/export/server/jdk1.<span class="number">8.0</span>_241  </span><br><span class="line">export PATH=<span class="variable">$PATH:</span><span class="variable">$JAVA_HOME</span>/bin  </span><br><span class="line">export CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/lib/tools.jar</span><br><span class="line"></span><br><span class="line"><span class="comment">#HADOOP_HOME</span></span><br><span class="line">export HADOOP_HOME=/export/server/hadoop<span class="literal">-3</span>.<span class="number">3.0</span> </span><br><span class="line">export PATH=<span class="variable">$PATH:</span><span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br><span class="line"></span><br><span class="line"><span class="comment">#ZOOKEEPER_HOME</span></span><br><span class="line">export ZOOKEEPER_HOME=/export/server/zookeeper</span><br><span class="line">export PATH=<span class="variable">$PATH:</span><span class="variable">$ZOOKEEPER_HOME</span>/bin</span><br><span class="line">.....</span><br><span class="line"><span class="comment"># 将以下部分添加进去</span></span><br><span class="line"><span class="comment">#SPARK_HOME</span></span><br><span class="line">export SPARK_HOME=/export/server/spark</span><br><span class="line"></span><br><span class="line"><span class="comment">#HADOOP_CONF_DIR</span></span><br><span class="line">export HADOOP_CONF_DIR=<span class="variable">$HADOOP_HOME</span>/etc/hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment">#PYSPARK_PYTHON</span></span><br><span class="line">export PYSPARK_PYTHON=/export/server/anaconda3/envs/pyspark/bin/python</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim .bashrc</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">内容添加进去：</span><br><span class="line"><span class="comment">#JAVA_HOME</span></span><br><span class="line">export JAVA_HOME=/export/server/jdk1.<span class="number">8.0</span>_241  </span><br><span class="line"><span class="comment">#PYSPARK_PYTHON</span></span><br><span class="line">export PYSPARK_PYTHON=/export/server/anaconda3/envs/pyspark/bin/python</span><br></pre></td></tr></table></figure></li><li><p>重新加载环境变量文件</p></li></ul><ul><li><p>进入 /export/server/anaconda3/envs/pyspark/bin/ 文件夹</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server/anaconda3/envs/pyspark/bin/</span><br></pre></td></tr></table></figure></li><li><p>开启</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./pyspark</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">结果显示：</span><br><span class="line">(base) [<span class="type">root</span>@<span class="type">master</span> <span class="type">bin</span>]<span class="comment"># ./pyspark</span></span><br><span class="line">Python <span class="number">3.8</span>.<span class="number">12</span> (default, Oct <span class="number">12</span> <span class="number">2021</span>, <span class="number">13</span>:<span class="number">49</span>:<span class="number">34</span>) </span><br><span class="line">[<span class="type">GCC</span> <span class="number">7.5</span><span class="type">.0</span>] :: Anaconda, Inc. on linux</span><br><span class="line"><span class="built_in">Type</span> <span class="string">&quot;help&quot;</span>, <span class="string">&quot;copyright&quot;</span>, <span class="string">&quot;credits&quot;</span> or <span class="string">&quot;license&quot;</span> <span class="keyword">for</span> more information.</span><br><span class="line">Setting default log level to <span class="string">&quot;WARN&quot;</span>.</span><br><span class="line">To adjust logging level use sc.setLogLevel(newLevel). <span class="keyword">For</span> SparkR, use setLogLevel(newLevel).</span><br><span class="line"><span class="number">2022</span><span class="literal">-03-15</span> <span class="number">20</span>:<span class="number">37</span>:<span class="number">04</span>,<span class="number">612</span> WARN util.NativeCodeLoader: Unable to load native<span class="literal">-hadoop</span> library <span class="keyword">for</span> your platform... <span class="keyword">using</span> builtin-java classes where applicable</span><br><span class="line">Welcome to</span><br><span class="line">      ____              __</span><br><span class="line">     / __/__  ___ _____/ /__</span><br><span class="line">    _\ \/ _ \/ _ `/ __/  <span class="string">&#x27;_/</span></span><br><span class="line"><span class="string">   /__ / .__/\_,_/_/ /_/\_\   version 3.2.0</span></span><br><span class="line"><span class="string">      /_/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Using Python version 3.8.12 (default, Oct 12 2021 13:49:34)</span></span><br><span class="line"><span class="string">Spark context Web UI available at http://master:4040</span></span><br><span class="line"><span class="string">Spark context available as &#x27;</span><span class="built_in">sc</span><span class="string">&#x27; (master = local[*], app id = local-1647347826262).</span></span><br><span class="line"><span class="string">SparkSession available as &#x27;</span>spark<span class="string">&#x27;.</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; </span></span><br></pre></td></tr></table></figure></li><li><p>查看WebUI界面</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">浏览器访问：</span><br><span class="line"></span><br><span class="line">http://master:4040/</span><br></pre></td></tr></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.328888.xyz/2022/08/27/G8bwB.png" alt="image-20220405131946528"></p></li><li><p>退出</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda deactivate</span><br></pre></td></tr></table></figure></li></ul><h2 id="Spark-Standalone模式"><a href="#Spark-Standalone模式" class="headerlink" title="Spark-Standalone模式"></a>Spark-Standalone模式</h2><p>Standalone模式(集群) Spark中的各个角色以独立进程的形式存在,并组成Spark集群环境</p><ul><li><p>Anaconda On Linux 安装 (单台服务器脚本安装 注：在 slave1 和 slave2 上部署)</p></li><li><p>安装上传安装包: 资料中提供的Anaconda3-2021.05-Linux-x86_64.sh文件到Linux服务器上安装位置在 /export/server:</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行文件</span></span><br><span class="line">sh Anaconda3<span class="literal">-2021</span>.<span class="number">05</span><span class="literal">-Linux-x86_64</span>.sh</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">过程显示：</span><br><span class="line">...</span><br><span class="line"><span class="comment"># 出现内容选 yes</span></span><br><span class="line">Please answer <span class="string">&#x27;yes&#x27;</span> or <span class="string">&#x27;no&#x27;</span>:<span class="string">&#x27;</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; yes</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 出现添加路径：/export/server/anaconda3</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">[/root/anaconda3] &gt;&gt;&gt; /export/server/anaconda3</span></span><br><span class="line"><span class="string">PREFIX=/export/server/anaconda3</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure></li><li><p>安装完成后, 退出终端， 重新进来:</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">exit</span></span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">结果显示：</span><br><span class="line"><span class="comment"># 看到这个Base开头表明安装好了.base是默认的虚拟环境.</span></span><br><span class="line">Last login: Tue Mar <span class="number">15</span> <span class="number">15</span>:<span class="number">28</span>:<span class="number">59</span> <span class="number">2022</span> from <span class="number">192.168</span>.<span class="number">88.1</span></span><br><span class="line">(base) [<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># </span></span><br></pre></td></tr></table></figure></li><li><p>在 master 节点上把 ./bashrc 和 profile 分发给 slave1 和 slave2</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#分发 .bashrc :</span></span><br><span class="line">scp ~/.bashrc root@slave1:~/</span><br><span class="line">scp ~/.bashrc root@slave2:~/</span><br><span class="line"></span><br><span class="line"><span class="comment">#分发 profile :</span></span><br><span class="line">scp /etc/profile/ root@slave1:/etc/</span><br><span class="line">scp /etc/profile/ root@slave2:/etc/</span><br></pre></td></tr></table></figure></li><li><p>创建虚拟环境 pyspark 基于 python3.8</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create <span class="literal">-n</span> pyspark python=<span class="number">3.8</span> </span><br></pre></td></tr></table></figure></li><li><p>切换到虚拟环境内</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate pyspark  </span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">结果显示：</span><br><span class="line">(base) [<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># conda activate pyspark  </span></span><br><span class="line">(pyspark) [<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># </span></span><br></pre></td></tr></table></figure></li><li><p>在虚拟环境内安装包 （有WARNING不用管）</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyhive pyspark jieba <span class="literal">-i</span> https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure></li><li><p>master 节点节点进入 /export/server/spark/conf 修改以下配置文件</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server/spark/conf</span><br></pre></td></tr></table></figure></li><li><p>将文件 workers.template 改名为 workers，并配置文件内容</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mv</span> workers.template workers</span><br><span class="line"></span><br><span class="line">vim workers</span><br><span class="line"></span><br><span class="line"><span class="comment"># localhost删除，内容追加文末：</span></span><br><span class="line">master</span><br><span class="line">slave1</span><br><span class="line">slave2</span><br><span class="line"><span class="comment"># 功能: 这个文件就是指示了  当前SparkStandAlone环境下, 有哪些worker</span></span><br></pre></td></tr></table></figure></li><li><p>将文件 spark-env.sh.template 改名为 spark-env.sh，并配置相关内容</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mv</span> spark<span class="literal">-env</span>.sh.template spark<span class="literal">-env</span>.sh</span><br><span class="line"></span><br><span class="line">vim spark<span class="literal">-env</span>.sh</span><br><span class="line"></span><br><span class="line">文末追加内容：</span><br><span class="line"></span><br><span class="line"><span class="comment">## 设置JAVA安装目录</span></span><br><span class="line">JAVA_HOME=/export/server/jdk</span><br><span class="line"></span><br><span class="line"><span class="comment">## HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群</span></span><br><span class="line">HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class="line">YARN_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment">## 指定spark老大Master的IP和提交任务的通信端口</span></span><br><span class="line"><span class="comment"># 告知Spark的master运行在哪个机器上</span></span><br><span class="line">export SPARK_MASTER_HOST=master</span><br><span class="line"><span class="comment"># 告知sparkmaster的通讯端口</span></span><br><span class="line">export SPARK_MASTER_PORT=<span class="number">7077</span></span><br><span class="line"><span class="comment"># 告知spark master的 webui端口</span></span><br><span class="line">SPARK_MASTER_WEBUI_PORT=<span class="number">8080</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># worker cpu可用核数</span></span><br><span class="line">SPARK_WORKER_CORES=<span class="number">1</span></span><br><span class="line"><span class="comment"># worker可用内存</span></span><br><span class="line">SPARK_WORKER_MEMORY=<span class="number">1</span>g</span><br><span class="line"><span class="comment"># worker的工作通讯地址</span></span><br><span class="line">SPARK_WORKER_PORT=<span class="number">7078</span></span><br><span class="line"><span class="comment"># worker的 webui地址</span></span><br><span class="line">SPARK_WORKER_WEBUI_PORT=<span class="number">8081</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 设置历史服务器</span></span><br><span class="line"><span class="comment"># 配置的意思是  将spark程序运行的历史日志 存到hdfs的/sparklog文件夹中</span></span><br><span class="line">SPARK_HISTORY_OPTS=<span class="string">&quot;-Dspark.history.fs.logDirectory=hdfs://master:8020/sparklog/ -Dspark.history.fs.cleaner.enabled=true&quot;</span></span><br></pre></td></tr></table></figure></li><li><p>开启 hadoop 的 hdfs 和 yarn 集群</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">start-dfs</span>.sh</span><br><span class="line"></span><br><span class="line"><span class="built_in">start-yarn</span>.sh </span><br></pre></td></tr></table></figure></li><li><p>在HDFS上创建程序运行历史记录存放的文件夹，同样 conf 文件目录下:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /sparklog</span><br><span class="line"></span><br><span class="line">hadoop fs -chmod 777 /sparklog</span><br></pre></td></tr></table></figure></li><li><p>将 spark-defaults.conf.template 改为 spark-defaults.conf 并做相关配置</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mv</span> spark<span class="literal">-defaults</span>.conf.template spark<span class="literal">-defaults</span>.conf</span><br><span class="line"></span><br><span class="line">vim spark<span class="literal">-defaults</span>.conf</span><br><span class="line"></span><br><span class="line">文末追加内容为：</span><br><span class="line"><span class="comment"># 开启spark的日期记录功能</span></span><br><span class="line">spark.eventLog.enabled 	true</span><br><span class="line"><span class="comment"># 设置spark日志记录的路径</span></span><br><span class="line">spark.eventLog.dir	 hdfs://master:<span class="number">8020</span>/sparklog/ </span><br><span class="line"><span class="comment"># 设置spark日志是否启动压缩</span></span><br><span class="line">spark.eventLog.compress 	true</span><br></pre></td></tr></table></figure></li><li><p>配置 log4j.properties 文件 将文件第 19 行的 log4j.rootCategory=INFO, console 改为 log4j.rootCategory=WARN, console （即将INFO 改为 WARN 目的：输出日志, 设置级别为WARN 只输出警告和错误日志，INFO 则为输出所有信息，多数为无用信息）</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mv</span> log4j.properties.template log4j.properties</span><br><span class="line"></span><br><span class="line">vim log4j.properties</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">结果显示：</span><br><span class="line">...</span><br><span class="line"><span class="number">18</span> <span class="comment"># Set everything to be logged to the console</span></span><br><span class="line"><span class="number">19</span> log4j.rootCategory=WARN, console</span><br><span class="line">....</span><br></pre></td></tr></table></figure></li><li><p>master 节点分发 spark 安装文件夹 到 slave1 和 slave2 上</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server/</span><br><span class="line"></span><br><span class="line">scp <span class="literal">-r</span> /export/server/spark<span class="literal">-3</span>.<span class="number">2.0</span><span class="literal">-bin-hadoop3</span>.<span class="number">2</span>/ slave1:<span class="variable">$PWD</span></span><br><span class="line"></span><br><span class="line">scp <span class="literal">-r</span> /export/server/spark<span class="literal">-3</span>.<span class="number">2.0</span><span class="literal">-bin-hadoop3</span>.<span class="number">2</span>/ slave2:<span class="variable">$PWD</span></span><br></pre></td></tr></table></figure></li><li><p>在slave1 和 slave2 上做软连接</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln <span class="literal">-s</span> /export/server/spark<span class="literal">-3</span>.<span class="number">2.0</span><span class="literal">-bin-hadoop3</span>.<span class="number">2</span> /export/server/spark</span><br></pre></td></tr></table></figure></li><li><p>重新加载环境变量</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></li><li><p>进入 /export/server/spark/sbin 文件目录下 启动 start-history-server.sh</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server/spark/sbin </span><br><span class="line"></span><br><span class="line">./<span class="built_in">start-history</span><span class="literal">-server</span>.sh</span><br></pre></td></tr></table></figure></li><li><p>访问 WebUI 界面</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">浏览器访问：</span><br><span class="line"></span><br><span class="line">http://master:<span class="number">18080</span>/</span><br></pre></td></tr></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.328888.xyz/2022/08/27/G8wgR.png" alt="image-20220405132216135"></p></li><li><p>启动Spark的Master和Worker进程</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动全部master和worker</span></span><br><span class="line">sbin/<span class="built_in">start-all</span>.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者可以一个个启动:</span></span><br><span class="line"><span class="comment"># 启动当前机器的master</span></span><br><span class="line">sbin/<span class="built_in">start-master</span>.sh</span><br><span class="line"><span class="comment"># 启动当前机器的worker</span></span><br><span class="line">sbin/<span class="built_in">start-worker</span>.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止全部</span></span><br><span class="line">sbin/<span class="built_in">stop-all</span>.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止当前机器的master</span></span><br><span class="line">sbin/<span class="built_in">stop-master</span>.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止当前机器的worker</span></span><br><span class="line">sbin/<span class="built_in">stop-worker</span>.sh</span><br></pre></td></tr></table></figure></li><li><p>访问 WebUI界面</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">浏览器访问：</span><br><span class="line"></span><br><span class="line">http://master:<span class="number">8080</span>/</span><br></pre></td></tr></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.328888.xyz/2022/08/27/G8a66.png" alt="image-20220405132434960"></p></li></ul><h2 id="Spark-Standalone-HA模式"><a href="#Spark-Standalone-HA模式" class="headerlink" title="Spark-Standalone-HA模式"></a>Spark-Standalone-HA模式</h2><p>Spark Standalone集群是Master-Slaves架构的集群模式,和大部分的Master-Slaves结构集群一样,存在着Master 单点故障(SPOF)的问题。简单理解为，spark-Standalone 模式下为 master 节点控制其他节点，当 master 节点出现故障时，集群就不可用了。 spark-Standalone-HA 模式下 master 节点不固定，当一个宕机时，立即换另一台为 master 保障不出现故障。</p><ul><li><p>此处因为先前配置时的 zookeeper 版本和 spark 版本不太兼容，导致此模式有故障，需要重新下载配置新的版本的 zookeeper</p></li><li><p>配置之前需要删除三台主机的 旧版 zookeeper 以及 对应的软连接</p></li><li><p>在 master 节点上重新进行前面配置的 zookeeper 操作</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>.上传apache<span class="literal">-zookeeper-3</span>.<span class="number">7.0</span><span class="literal">-bin</span>.tar.gz 到/export/server/目录下 并解压文件</span><br><span class="line"><span class="number">2</span>.在 /export/server 目录下创建软连接</span><br><span class="line"><span class="number">3</span>.进入   /export/server/zookeeper/conf/  将 zoo_sample.cfg 文件复制为新文件 zoo.cfg </span><br><span class="line"><span class="number">4</span>.接上步给 zoo.cfg  添加内容 </span><br><span class="line"><span class="number">5</span>.进入 /export/server/zookeeper/zkdatas 目录在此目录下创建 myid 文件，将 <span class="number">1</span> 写入进去</span><br><span class="line"><span class="number">6</span>.将 master 节点中 /export/server/zookeeper<span class="literal">-3</span>.<span class="number">7.0</span> 路径下内容推送给slave1 和 slave2</span><br><span class="line"><span class="number">7</span>.推送成功后，分别在 slave1 和 slave2 上创建软连接</span><br><span class="line"><span class="number">8</span>.接上步推送完成后将 slave1 和 slave2 的 /export/server/zookeeper/zkdatas/文件夹下的 myid 中的内容分别改为 <span class="number">2</span> 和 <span class="number">3</span></span><br><span class="line">配置环境变量：</span><br><span class="line">因先前配置 zookeeper 时候创建过软连接且以 ’zookeeper‘ 为路径，所以不用配置环境变量，此处也是创建软连接的方便之处. </span><br></pre></td></tr></table></figure></li><li><p>进入 /export/server/spark/conf 文件夹 修改 spark-env.sh 文件内容</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server/spark/conf </span><br><span class="line"></span><br><span class="line">vim spark<span class="literal">-env</span>.sh</span><br></pre></td></tr></table></figure><ul><li><p>为 83 行内容加上注释，此部分原为指定 某台主机 做 master ，加上注释后即为 任何主机都可以做 master</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">结果显示：</span><br><span class="line">......</span><br><span class="line"> <span class="number">82</span> <span class="comment"># 告知Spark的master运行在哪个机器上</span></span><br><span class="line"> <span class="number">83</span> <span class="comment"># export SPARK_MASTER_HOST=master</span></span><br><span class="line">.........</span><br></pre></td></tr></table></figure></li><li><p>文末添加内容</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SPARK_DAEMON_JAVA_OPTS=<span class="string">&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=master:2181,slave1:2181,slave2:2181 -Dspark.deploy.zookeeper.dir=/spark-ha&quot;</span></span><br><span class="line"><span class="comment"># spark.deploy.recoveryMode 指定HA模式 基于Zookeeper实现</span></span><br><span class="line"><span class="comment"># 指定Zookeeper的连接地址</span></span><br><span class="line"><span class="comment"># 指定在Zookeeper中注册临时节点的路径</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>分发 spark-env.sh 到 salve1 和 slave2 上</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp spark<span class="literal">-env</span>.sh slave1:/export/server/spark/conf/</span><br><span class="line"></span><br><span class="line">scp spark<span class="literal">-env</span>.sh slave2:/export/server/spark/conf/</span><br></pre></td></tr></table></figure></li><li><p>启动之前确保 Zookeeper 和 HDFS 均已经启动</p></li><li><p>启动集群:</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在 master 上 启动一个master 和全部worker</span></span><br><span class="line">/export/server/spark/sbin/<span class="built_in">start-all</span>.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意, 下面命令在 slave1 上执行 启动 slave1 上的 master 做备用 master</span></span><br><span class="line">/export/server/spark/sbin/<span class="built_in">start-master</span>.sh</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">结果显示：</span><br><span class="line">(base) [<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># jps</span></span><br><span class="line"><span class="number">37328</span> DataNode</span><br><span class="line"><span class="number">41589</span> Master</span><br><span class="line"><span class="number">35798</span> QuorumPeerMain</span><br><span class="line"><span class="number">38521</span> ResourceManager</span><br><span class="line"><span class="number">46281</span> Jps</span><br><span class="line"><span class="number">38907</span> NodeManager</span><br><span class="line"><span class="number">41821</span> Worker</span><br><span class="line"><span class="number">36958</span> NameNode</span><br><span class="line"></span><br><span class="line">(base) [<span class="type">root</span>@<span class="type">slave1</span> <span class="type">sbin</span>]<span class="comment"># jps</span></span><br><span class="line"><span class="number">36631</span> DataNode</span><br><span class="line"><span class="number">48135</span> Master</span><br><span class="line"><span class="number">35385</span> QuorumPeerMain</span><br><span class="line"><span class="number">37961</span> NodeManager</span><br><span class="line"><span class="number">40970</span> Worker</span><br><span class="line"><span class="number">48282</span> Jps</span><br><span class="line"><span class="number">37276</span> SecondaryNameNode</span><br></pre></td></tr></table></figure></li><li><p>访问 WebUI 界面</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://master:8081/</span><br></pre></td></tr></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.328888.xyz/2022/08/27/G81HI.png" alt="image-20220403195207486"></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://slave1:8082/</span><br></pre></td></tr></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.328888.xyz/2022/08/27/G89Fj.png" alt="image-20220403195512439"></p></li><li><p>此时 kill 掉 master 上的 master 假设 master 主机宕机掉</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># master主机 master 的进程号</span></span><br><span class="line"><span class="built_in">kill</span> <span class="literal">-9</span> <span class="number">41589</span></span><br><span class="line"></span><br><span class="line">结果显示：</span><br><span class="line">(base) [<span class="type">root</span>@<span class="type">master</span> ~]<span class="comment"># jps</span></span><br><span class="line"><span class="number">37328</span> DataNode</span><br><span class="line"><span class="number">90336</span> Jps</span><br><span class="line"><span class="number">35798</span> QuorumPeerMain</span><br><span class="line"><span class="number">38521</span> ResourceManager</span><br><span class="line"><span class="number">38907</span> NodeManager</span><br><span class="line"><span class="number">41821</span> Worker</span><br><span class="line"><span class="number">36958</span> NameNode</span><br></pre></td></tr></table></figure></li><li><p>访问 slave1 的 WebUI</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://slave1:8082/</span><br></pre></td></tr></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.328888.xyz/2022/08/27/G8K5r.png" alt="image-20220403203828713"></p></li><li><p>进行主备切换的测试</p></li><li><p>提交一个 spark 任务到当前 活跃的 master上 :</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/export/server/spark/bin/spark<span class="literal">-submit</span> <span class="literal">--master</span> spark://master:<span class="number">7077</span> /export/server/spark/examples/src/main/python/pi.py <span class="number">1000</span></span><br></pre></td></tr></table></figure></li><li><p>复制标签 kill 掉 master 的 进程号</p></li><li><p>再次访问 master 的 WebUI</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://master:8081/</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">网页访问不了！</span><br></pre></td></tr></table></figure></li><li><p>再次访问 slave1 的 WebUI</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://slave1:8082/</span><br></pre></td></tr></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.328888.xyz/2022/08/27/G878p.png" alt="image-20220403204737370"></p></li><li><p>可以看到当前活跃的 master 提示信息</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(base) [root@master ~]# /export/server/spark/bin/spark-submit --master spark://master:7077 /export/server/spark/examples/src/main/python/pi.py 1000</span><br><span class="line">22/03/29 16:11:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">22/03/29 16:12:16 WARN StandaloneAppClient$ClientEndpoint: Connection to master:7077 failed; waiting for master to reconnect...</span><br><span class="line">22/03/29 16:12:16 WARN StandaloneSchedulerBackend: Disconnected from Spark cluster! Waiting for reconnection...</span><br><span class="line">22/03/29 16:12:16 WARN StandaloneAppClient$ClientEndpoint: Connection to master:7077 failed; waiting for master to reconnect...</span><br><span class="line">Pi is roughly 3.140960</span><br><span class="line">(base) [root@master ~]# </span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">同样可以输出结果</span><br></pre></td></tr></table></figure><p>当新的 master 接收集群后, 程序继续运行, 正常得到结果.</p></li></ul><blockquote><p>结论 HA模式下, 主备切换 不会影响到正在运行的程序.</p><p>最大的影响是 会让它中断大约30秒左右.</p></blockquote><h2 id="Spark-On-YARN模式"><a href="#Spark-On-YARN模式" class="headerlink" title="Spark On YARN模式"></a>Spark On YARN模式</h2><p>在已有YARN集群的前提下在单独准备Spark StandAlone集群,对资源的利用就不高.Spark On YARN, 无需部署Spark集群, 只要找一台服务器, 充当Spark的客户端</p><ul><li><p>保证 HADOOP<em>CONF</em>和 DIR_YARN_CONF_DIR 已经配置在 spark-env.sh 和环境变量中 （注: 前面配置spark-Standlone 时已经配置过此项了）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">spark-env.sh 文件部分显示：</span><br><span class="line">....</span><br><span class="line"> 77 ## HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群</span><br><span class="line"> 78 HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class="line"> 79 YARN_CONF_DIR=/export/server/hadoop/etc/hadoop</span><br><span class="line">....</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>链接到 YARN 中（注: 交互式环境 pyspark 和 spark-shell 无法运行 cluster模式）</p></li><li><p>```powershell<br>bin/pyspark —master yarn —deploy-mode client|cluster<br>—deploy-mode 选项是指定部署模式, 默认是 客户端模式<br>client就是客户端模式<br>cluster就是集群模式<br>—deploy-mode 仅可以用在YARN模式下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- ```powershell</span><br><span class="line">  bin/spark-shell --master yarn --deploy-mode client|cluster</span><br></pre></td></tr></table></figure></li><li><p>```powershell<br>bin/spark-submit —master yarn —deploy-mode client|cluster /xxx/xxx/xxx.py 参数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- spark-submit 和 spark-shell 和 pyspark的相关参数</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>bin/pyspark: pyspark解释器spark环境</li><li>bin/spark-shell: scala解释器spark环境</li><li>bin/spark-submit: 提交jar包或Python文件执行的工具</li><li>bin/spark-sql: sparksql客户端工具<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>这4个客户端工具的参数基本通用.以spark-submit 为例:<br>bin/spark-submit —master spark://master:7077 xxx.py`<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">```powershell</span><br><span class="line">Usage: spark-submit [options] &lt;app jar | python file | R file&gt; [app arguments]</span><br><span class="line">Usage: spark-submit --kill [submission ID] --master [spark://...]</span><br><span class="line">Usage: spark-submit --status [submission ID] --master [spark://...]</span><br><span class="line">Usage: spark-submit run-example [options] example-class [example args]</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  --master MASTER_URL         spark://host:port, mesos://host:port, yarn,</span><br><span class="line">                              k8s://https://host:port, or local (Default: local[*]).</span><br><span class="line">  --deploy-mode DEPLOY_MODE   部署模式 client 或者 cluster 默认是client</span><br><span class="line">  --class CLASS_NAME          运行java或者scala class(for Java / Scala apps).</span><br><span class="line">  --name NAME                 程序的名字</span><br><span class="line">  --jars JARS                 Comma-separated list of jars to include on the driver</span><br><span class="line">                              and executor classpaths.</span><br><span class="line">  --packages                  Comma-separated list of maven coordinates of jars to include</span><br><span class="line">                              on the driver and executor classpaths. Will search the local</span><br><span class="line">                              maven repo, then maven central and any additional remote</span><br><span class="line">                              repositories given by --repositories. The format for the</span><br><span class="line">                              coordinates should be groupId:artifactId:version.</span><br><span class="line">  --exclude-packages          Comma-separated list of groupId:artifactId, to exclude while</span><br><span class="line">                              resolving the dependencies provided in --packages to avoid</span><br><span class="line">                              dependency conflicts.</span><br><span class="line">  --repositories              Comma-separated list of additional remote repositories to</span><br><span class="line">                              search for the maven coordinates given with --packages.</span><br><span class="line">  --py-files PY_FILES         指定Python程序依赖的其它python文件</span><br><span class="line">  --files FILES               Comma-separated list of files to be placed in the working</span><br><span class="line">                              directory of each executor. File paths of these files</span><br><span class="line">                              in executors can be accessed via SparkFiles.get(fileName).</span><br><span class="line">  --archives ARCHIVES         Comma-separated list of archives to be extracted into the</span><br><span class="line">                              working directory of each executor.</span><br><span class="line"></span><br><span class="line">  --conf, -c PROP=VALUE       手动指定配置</span><br><span class="line">  --properties-file FILE      Path to a file from which to load extra properties. If not</span><br><span class="line">                              specified, this will look for conf/spark-defaults.conf.</span><br><span class="line"></span><br><span class="line">  --driver-memory MEM         Driver的可用内存(Default: 1024M).</span><br><span class="line">  --driver-java-options       Driver的一些Java选项</span><br><span class="line">  --driver-library-path       Extra library path entries to pass to the driver.</span><br><span class="line">  --driver-class-path         Extra class path entries to pass to the driver. Note that</span><br><span class="line">                              jars added with --jars are automatically included in the</span><br><span class="line">                              classpath.</span><br><span class="line"></span><br><span class="line">  --executor-memory MEM       Executor的内存 (Default: 1G).</span><br><span class="line"></span><br><span class="line">  --proxy-user NAME           User to impersonate when submitting the application.</span><br><span class="line">                              This argument does not work with --principal / --keytab.</span><br><span class="line"></span><br><span class="line">  --help, -h                  显示帮助文件</span><br><span class="line">  --verbose, -v               Print additional debug output.</span><br><span class="line">  --version,                  打印版本</span><br><span class="line"></span><br><span class="line"> Cluster deploy mode only(集群模式专属):</span><br><span class="line">  --driver-cores NUM          Driver可用的的CPU核数(Default: 1).</span><br><span class="line"></span><br><span class="line"> Spark standalone or Mesos with cluster deploy mode only:</span><br><span class="line">  --supervise                 如果给定, 可以尝试重启Driver</span><br><span class="line"></span><br><span class="line"> Spark standalone, Mesos or K8s with cluster deploy mode only:</span><br><span class="line">  --kill SUBMISSION_ID        指定程序ID kill</span><br><span class="line">  --status SUBMISSION_ID      指定程序ID 查看运行状态</span><br><span class="line"></span><br><span class="line"> Spark standalone, Mesos and Kubernetes only:</span><br><span class="line">  --total-executor-cores NUM  整个任务可以给Executor多少个CPU核心用</span><br><span class="line"></span><br><span class="line"> Spark standalone, YARN and Kubernetes only:</span><br><span class="line">  --executor-cores NUM        单个Executor能使用多少CPU核心</span><br><span class="line"></span><br><span class="line"> Spark on YARN and Kubernetes only(YARN模式下):</span><br><span class="line">  --num-executors NUM         Executor应该开启几个</span><br><span class="line">  --principal PRINCIPAL       Principal to be used to login to KDC.</span><br><span class="line">  --keytab KEYTAB             The full path to the file that contains the keytab for the</span><br><span class="line">                              principal specified above.</span><br><span class="line"></span><br><span class="line"> Spark on YARN only:</span><br><span class="line">  --queue QUEUE_NAME          指定运行的YARN队列(Default: &quot;default&quot;).</span><br></pre></td></tr></table></figure></li></ul></li><li><p>启动 YARN 的历史服务器</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/hadoop-3.3.0/sbin</span><br><span class="line"></span><br><span class="line">./mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure></li><li><p>访问WebUI界面</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://master:19888/</span><br></pre></td></tr></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.328888.xyz/2022/08/27/G8czK.png" alt="image-20220403213634530"></p></li></ul><ul><li><p>client 模式测试</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SPARK_HOME=/export/server/spark </span><br><span class="line"></span><br><span class="line"><span class="variable">$</span>&#123;SPARK_HOME&#125;/bin/spark<span class="literal">-submit</span>  <span class="literal">--master</span> yarn  <span class="literal">--deploy-mode</span> client  <span class="literal">--driver-memory</span> <span class="number">512</span>m  <span class="literal">--executor-memory</span> <span class="number">512</span>m  <span class="literal">--num-executors</span> <span class="number">1</span>  <span class="literal">--total-executor-cores</span> <span class="number">2</span> <span class="variable">$</span>&#123;SPARK_HOME&#125;/examples/src/main/python/pi.py <span class="number">3</span></span><br></pre></td></tr></table></figure></li></ul><ul><li><p>cluster 模式测试</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SPARK_HOME=/export/server/spark </span><br><span class="line"></span><br><span class="line"><span class="variable">$</span>&#123;SPARK_HOME&#125;/bin/spark<span class="literal">-submit</span> <span class="literal">--master</span> yarn <span class="literal">--deploy-mode</span> cluster <span class="literal">--driver-memory</span> <span class="number">512</span>m <span class="literal">--executor-memory</span> <span class="number">512</span>m <span class="literal">--num-executors</span> <span class="number">1</span> <span class="literal">--total-executor-cores</span> <span class="number">2</span> <span class="literal">--conf</span> <span class="string">&quot;spark.pyspark.driver.python=/root/anaconda3/bin/python3&quot;</span> <span class="literal">--conf</span> <span class="string">&quot;spark.pyspark.python=/root/anaconda3/bin/python3&quot;</span> <span class="variable">$</span>&#123;SPARK_HOME&#125;/examples/src/main/python/pi.py <span class="number">3</span></span><br></pre></td></tr></table></figure></li></ul><h1 id="kafka-安装配置"><a href="#kafka-安装配置" class="headerlink" title="kafka 安装配置"></a>kafka 安装配置</h1><p>Kafka是一种高吞吐量的分布式发布订阅消息系统，其在大数据开发应用上的目的是通过 Hadoo的并行加载机制来统一线上和离线的消息处理，也是为了通过集群来提供实时的消息。大数据开发需掌握Kafka架构原理及各组件的作用和使用方法及相关功能的实现。</p><ul><li><p>上传文件包 到/export/server/</p></li><li><p>解压文件</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar <span class="literal">-zxvf</span> kafka_2.<span class="number">11</span><span class="literal">-2</span>.<span class="number">0.0</span>.tgz</span><br></pre></td></tr></table></figure></li><li><p>创建软连接</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln <span class="literal">-s</span> kafka_2.<span class="number">11</span><span class="literal">-2</span>.<span class="number">0.0</span>/ kafka</span><br></pre></td></tr></table></figure></li><li><p>进入 /export/server/kafka/config 修改 配置文件 server.properties</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server/kafka/config</span><br><span class="line"></span><br><span class="line">vim server.properties </span><br></pre></td></tr></table></figure><ul><li><p>21 行内容 broker.id=0 为依次增长的:0、1、2、3、4,集群中唯一 id 从0开始，每台不能重复（注：此处不用修改）</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">21</span> broker.id=<span class="number">0</span></span><br></pre></td></tr></table></figure></li><li><p>31 行内容 #listeners=PLAINTEXT://:9092 取消注释，内容改为：listeners=PLAINTEXT://master:9092</p><p>PLAINTEXT为通信使用明文（加密ssl）</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">31</span> listeners=PLAINTEXT://master:<span class="number">9092</span> </span><br></pre></td></tr></table></figure></li><li><p>59 行内容 log.dirs=/tmp/kafka-logs 为默认日志文件存储的位置，改为 log.dirs=/export/server/data/kafka-logs</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">59</span> log.dirs=/export/<span class="keyword">data</span>/kafka<span class="literal">-logs</span></span><br></pre></td></tr></table></figure></li><li><p>63 行内容为 num.partitions=1 是默认分区数</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">63</span> num.partitions=<span class="number">1</span></span><br></pre></td></tr></table></figure></li><li><p>76 行部分</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">############################ **Log Flush Policy** ###############################</span><br><span class="line"> </span><br><span class="line">数据安全性（持久化之前先放到缓存上，从缓存刷到磁盘上）interval.messages   interval.ms</span><br></pre></td></tr></table></figure></li><li><p>93 行部分</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">########################### **Log Retention Policy** ############################</span><br><span class="line"> </span><br><span class="line">数据保留策略 168/24=7，1073741824/1024=1GB，300000ms = 300s = 5min超过了删掉（最后修改时间还是创建时间--&gt;日志段中最晚的一条消息，维护这个最大的时间戳--&gt;用户无法干预</span><br></pre></td></tr></table></figure></li><li><p>121 行内容 zookeeper.connect=localhost:2181 修改为 zookeeper.connect=master:2181,slave1:2181,slave2:2181</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">121</span> zookeeper.connect=master:<span class="number">2181</span>,slave1:<span class="number">2181</span>,slave2:<span class="number">2181</span></span><br></pre></td></tr></table></figure></li><li><p>126 行内容 group.initial.rebalance.delay.ms=0 修改为 group.initial.rebalance.delay.ms=3000</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">133</span> group.initial.rebalance.delay.ms=<span class="number">3000</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>给 slaves1和 slavs2 scp 分发 kafka</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server/</span><br><span class="line"></span><br><span class="line">scp <span class="literal">-r</span> /export/server/kafka_2.<span class="number">11</span><span class="literal">-2</span>.<span class="number">0.0</span>/ slave1:<span class="variable">$PWD</span></span><br><span class="line"></span><br><span class="line">scp <span class="literal">-r</span> /export/server/kafka_2.<span class="number">11</span><span class="literal">-2</span>.<span class="number">0.0</span>/ slave2:<span class="variable">$PWD</span></span><br></pre></td></tr></table></figure></li><li><p>创建软连接</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /export/server/kafka_2.11-2.0.0/ kafka</span><br></pre></td></tr></table></figure></li><li><p>配置 kafka 环境变量（注：可以一台一台配，也可以在 master 完成后发给 slave1 和slave2）</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile </span><br><span class="line"></span><br><span class="line"><span class="comment"># kafka 环境变量</span></span><br><span class="line">export KAFKA_HOME=/export/server/kafka </span><br><span class="line">export PATH=<span class="variable">$PATH:</span><span class="variable">$KAFKA_HOME</span>/bin </span><br></pre></td></tr></table></figure></li><li><p>重新加载环境变量</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></li><li><p>分别在 slave1 和slave2 上修改配置文件 路径：/export/server/kafka/config</p><ul><li><p>将文件 server.properties 的第 21 行的 broker.id=0 修改为 broker.id=1 同理 slave2 同样操作</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">21</span> broker.id=<span class="number">1</span></span><br></pre></td></tr></table></figure></li><li><p>将文件 server.properties 的第 31 行的 listeners=PLAINTEXT://master:9092 修改为 listeners=PLAINTEXT://slave1:9092 同理slave2 同样操作</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">31</span> listeners=PLAINTEXT://slave1:<span class="number">9092</span> </span><br></pre></td></tr></table></figure></li></ul></li><li><p>启停 kafka (注：kafka 启动需要在 zookeeper 启动的情况下才可)</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka<span class="literal">-server-start</span>.sh <span class="literal">-daemon</span> /export/server/kafka/config/server.properties</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">hadoop，zookeeper，kafka启动</span><br><span class="line">结果显示：</span><br><span class="line">(base) [root@master ~]# jps</span><br><span class="line">11793 NodeManager</span><br><span class="line">91699 Kafka</span><br><span class="line">85618 QuorumPeerMain</span><br><span class="line">10697 NameNode</span><br><span class="line">10924 DataNode</span><br><span class="line">11596 ResourceManager</span><br><span class="line">109852 Jps</span><br><span class="line"></span><br><span class="line">[root@slave1 ~]# jps</span><br><span class="line">9301 DataNode</span><br><span class="line">9493 SecondaryNameNode</span><br><span class="line">95959 Kafka</span><br><span class="line">102971 Jps</span><br><span class="line">9855 NodeManager</span><br><span class="line">89534 QuorumPeerMain</span><br><span class="line"></span><br><span class="line">[root@slave2 ~]# jps</span><br><span class="line">88660 QuorumPeerMain</span><br><span class="line">95204 Kafka</span><br><span class="line">9110 NodeManager</span><br><span class="line">8616 DataNode</span><br><span class="line">102104 Jps</span><br></pre></td></tr></table></figure></li><li><p>关闭 kafka</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka<span class="literal">-server-stop</span>.sh stop</span><br></pre></td></tr></table></figure></li><li><p>定制脚本一键启动</p></li><li><p>```sh<br>vim kafka-all.sh</p><p>放入 /bin 路径下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">```powershell</span><br><span class="line">#!/bin/bash</span><br><span class="line">if [ $# -eq 0 ] ;</span><br><span class="line">then</span><br><span class="line">	echo &quot;please input param:start stop&quot;</span><br><span class="line">else</span><br><span class="line">if [ $1 = start  ] ;then	</span><br><span class="line">	echo &quot;$&#123;1&#125;ing master&quot;</span><br><span class="line">	ssh master &quot;source /etc/profile;kafka-server-start.sh -daemon /export/server/kafka/config/server.properties&quot;</span><br><span class="line">	for i in &#123;1..2&#125;</span><br><span class="line">	do</span><br><span class="line">		echo &quot;$&#123;1&#125;ing slave$&#123;i&#125;&quot;	</span><br><span class="line">		ssh slave$&#123;i&#125; &quot;source /etc/profile;kafka-server-start.sh -daemon /export/server/kafka/config/server.properties&quot;</span><br><span class="line">	done</span><br><span class="line">fi</span><br><span class="line">if [ $1 = stop ];then</span><br><span class="line">	echo &quot;$&#123;1&#125;ping master &quot;</span><br><span class="line">	ssh master &quot;source /etc/profile;kafka-server-stop.sh&quot;</span><br><span class="line">	for i in &#123;1..2&#125;</span><br><span class="line">	do</span><br><span class="line">		echo &quot;$&#123;1&#125;ping slave$&#123;i&#125;&quot;	</span><br><span class="line">		ssh slave$&#123;i&#125; &quot;source /etc/profile;kafka-server-stop.sh&quot;</span><br><span class="line">	done</span><br><span class="line">fi</span><br><span class="line">fi</span><br></pre></td></tr></table></figure></li></ul><h1 id="hbase安装配置"><a href="#hbase安装配置" class="headerlink" title="hbase安装配置"></a>hbase安装配置</h1><ul><li><p>进入 /export/server 将文件 hbase-1.2.4-bin.tar 上传 并解压</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server</span><br><span class="line"></span><br><span class="line">tar <span class="literal">-zxvf</span> hbase<span class="literal">-1</span>.<span class="number">2.4</span><span class="literal">-bin</span>.tar.gz </span><br></pre></td></tr></table></figure></li><li><p>创建软连接</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s hbase-1.2.4 hbase</span><br></pre></td></tr></table></figure></li><li><p>进入 /export/server/hbase/conf 修改配置</p><ul><li><p>修改 hbase-env.sh 文件内容 添加</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim hbase-env.sh</span><br><span class="line"></span><br><span class="line">内容添加末尾：</span><br><span class="line">export HBASE_MANAGES_ZK=false</span><br><span class="line">export JAVA_HOME=/export/server/jdk1.8.0_241</span><br><span class="line">export HBASE_CLASSPATH=/export/server/hadoop-3.3.0/etc/hadoop</span><br></pre></td></tr></table></figure></li><li><p>修改 hbase-site.xml 文件内容</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">vim hbase-site.xml</span><br><span class="line"></span><br><span class="line"># 文末删除 <span class="tag">&lt;<span class="name">configuration</span>&gt;</span> <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span> 添加以下内容</span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:8020/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.master<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:6000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>master,slave1,slave2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>/export/server/ zookeeper<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>配置 regionservers 添加内容 删除原来的 localhoast</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure></li></ul></li><li><p>进入 /export/server/hadoop-3.3.0/etc/hadoop 将文件 hdfs-site.xml 和 core-site.xml 拷贝到 hbase的配置文件夹下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/hadoop-3.3.0/etc/hadoop</span><br><span class="line"></span><br><span class="line">cp hdfs-site.xml /export/server/hbase/conf/</span><br><span class="line">cp core-site.xml /export/server/hbase/conf/</span><br></pre></td></tr></table></figure></li><li><p>向 slave1 和 slave2 分发配置的 hbase</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp  -r  /export/server/hbase/  root@slave1:/export/server/</span><br><span class="line">scp  -r  /export/server/hbase/  root@slave2:/export/server/</span><br></pre></td></tr></table></figure></li><li><p>master slave1 和 slave2三台主机同时配置环境变量</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line"># 添加内容</span><br><span class="line">#HBASE_HOME</span><br><span class="line">export  HBASE_HOME=/export/server/hbase</span><br><span class="line">export  PATH=$PATH:$HBASE_HOME/bin</span><br></pre></td></tr></table></figure><p>重新加载环境变量</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></li><li><p>启动 hbase（注:启动 hbase 之前需要启动 zookeeper 和 hadoop ）</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">zkServer<span class="literal">-all</span>.sh <span class="built_in">start</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">start-all</span>.sh</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /export/server/hbase/bin</span><br><span class="line"></span><br><span class="line">./<span class="built_in">start-hbase</span>.sh </span><br></pre></td></tr></table></figure></li><li><p>jps 查看进程</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">结果显示：</span><br><span class="line">(base) [root@master bin]# jps</span><br><span class="line">24977 Jps</span><br><span class="line">24534 HMaster</span><br></pre></td></tr></table></figure></li><li><p>访问 WebUI</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://master:16010/master-status</span><br></pre></td></tr></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.328888.xyz/2022/08/27/G82Em.png" alt="image-20220403171041076"></p></li></ul><h1 id="Hive安装配置"><a href="#Hive安装配置" class="headerlink" title="Hive安装配置"></a>Hive安装配置</h1><div class="tip fa-gamepad faa-horizontal animated"><p>规划</p></div><div class="table-container"><table><thead><tr><th style="text-align:center">序号</th><th style="text-align:center">主机</th><th style="text-align:center">角色</th></tr></thead><tbody><tr><td style="text-align:center">01</td><td style="text-align:center">master</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">02</td><td style="text-align:center">salve1</td><td style="text-align:center">mysql，hive server服务器端</td></tr><tr><td style="text-align:center">03</td><td style="text-align:center">slave2</td><td style="text-align:center">作为Client客户端</td></tr></tbody></table></div><h2 id="Hive-部署之本地模式"><a href="#Hive-部署之本地模式" class="headerlink" title="Hive 部署之本地模式"></a>Hive 部署之本地模式</h2><p>本地模式部署本质上是将Hive默认的元数据存储介质由内嵌的Derby数据库替换为独立数据库，即MySQL数据库。本地模式部署Hive需要在一台虚拟机上同时安装MySQL和Hive，接下来，我们以虚拟机slave1为例，使用本地模式部署Hive。</p><ul><li><p><strong><em>安装 Mysql 安装 Mysql 5.7</em></strong></p></li><li><p>下载并安装wget工具，wget是Linux中的一个下载文件的工具</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install <span class="built_in">wget</span> <span class="literal">-y</span></span><br></pre></td></tr></table></figure></li><li><p>下载MySQL 5.7的yum资源库，资源库文件会下载到当前目录下</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /export/server</span><br><span class="line"></span><br><span class="line"><span class="built_in">wget</span> <span class="literal">-i</span> <span class="literal">-c</span> http://dev.mysql.com/get/mysql57<span class="literal">-community-release-el7-10</span>.noarch.rpm</span><br></pre></td></tr></table></figure></li><li><p>安装MySQL 5.7的yum资源库</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum <span class="literal">-y</span> install mysql57<span class="literal">-community-release-el7-10</span>.noarch.rpm</span><br></pre></td></tr></table></figure></li><li><p>进入 /etc/yum.repos.d 文件查看 是否有 mysql-community.repo 和从 mysql-community-source.repo</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ls</span> /etc/yum.repos.d | grep <span class="string">&#x27;mysql&#x27;</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">结果显示:</span><br><span class="line">(base) [root@slave1~]# ls /etc/yum.repos.d | grep &#x27;mysql&#x27;</span><br><span class="line">mysql-community.repo</span><br><span class="line">mysql-community-source.repo</span><br></pre></td></tr></table></figure></li><li><p>mysql-community-source.repo 文件内容是 需要的下载的 mysql 组件</p></li><li><p>清除缓存</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum clean all &amp;&amp; yum makecache fast</span><br></pre></td></tr></table></figure></li><li><p>安装MySQL 5.7服务</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install mysql<span class="literal">-community-server</span> <span class="literal">--nogpgcheck</span></span><br></pre></td></tr></table></figure></li><li><p>启动 mysql 并查看 服务状态</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="built_in">start</span> mysqld.service</span><br><span class="line"></span><br><span class="line">systemctl status mysqld.service</span><br><span class="line"></span><br><span class="line">结果显示:</span><br><span class="line">(base) [<span class="type">root</span>@<span class="type">slave1</span> <span class="type">log</span>]<span class="comment"># systemctl status mysqld.service</span></span><br><span class="line"></span><br><span class="line">● mysqld.service - MySQL Server</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled)</span><br><span class="line">   Active: active (running) since Sat <span class="number">2022</span><span class="literal">-04-09</span> <span class="number">17</span>:<span class="number">26</span>:<span class="number">23</span> CST; <span class="number">13</span>s ago</span><br><span class="line">     Docs: <span class="built_in">man</span>:mysqld(<span class="number">8</span>)</span><br><span class="line">           http://dev.mysql.com/doc/refman/en/using<span class="literal">-systemd</span>.html</span><br><span class="line">  <span class="keyword">Process</span>: <span class="number">1800</span> ExecStart=/usr/sbin/mysqld <span class="literal">--daemonize</span> <span class="literal">--pid-file</span>=/var/run/mysqld/mysqld.pid <span class="variable">$MYSQLD_OPTS</span> (code=exited, status=<span class="number">0</span>/SUCCESS)</span><br><span class="line">  <span class="keyword">Process</span>: <span class="number">1751</span> ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=<span class="number">0</span>/SUCCESS)</span><br><span class="line"> Main PID: <span class="number">1803</span> (mysqld)</span><br><span class="line">   CGroup: /system.slice/mysqld.service</span><br><span class="line">           └─<span class="number">1803</span> /usr/sbin/mysqld <span class="literal">--daemonize</span> <span class="literal">--pid-file</span>=/var/run/mysqld/mysqld.pid</span><br><span class="line"></span><br><span class="line">Apr <span class="number">09</span> <span class="number">17</span>:<span class="number">26</span>:<span class="number">16</span> slave1 systemd[<span class="number">1</span>]: Starting MySQL Server...</span><br><span class="line">Apr <span class="number">09</span> <span class="number">17</span>:<span class="number">26</span>:<span class="number">23</span> slave1 systemd[<span class="number">1</span>]: Started MySQL Server.</span><br><span class="line">(base) [<span class="type">root</span>@<span class="type">slave1</span> <span class="type">log</span>]<span class="comment"># </span></span><br></pre></td></tr></table></figure></li><li><p>MySQL安装完成后需要通过用户名和密码进行登录，MySQL为本地默认用户root自动生成密码，可以在MySQL的日志文件中查看此密码。</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep <span class="string">&quot;password&quot;</span> /var/log/mysqld.log</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">结果显示:</span><br><span class="line">(base) [root@slave1 log]# grep &quot;password&quot; /var/log/mysqld.log</span><br><span class="line">2022-04-09T09:26:19.571037Z 1 [Note] A temporary password is generated for root@localhost: /Xb6caelDqqk</span><br><span class="line"></span><br><span class="line">注意:/Xb6caelDqqk 为默认密码</span><br></pre></td></tr></table></figure></li><li><p>知识点：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">数字权限使用格式</span><br><span class="line">在这种使用方式中，首先我们需要了解数字如何表示权限。 首先，我们规定 数字 4 、2 和 1表示读、写、执行权限（具体原因可见下节权限详解内容），即 r=4，w=2，x=1 。此时其他的权限组合也可以用其他的八进制数字表示出来，</span><br><span class="line">如：</span><br><span class="line">rwx = 4 + 2 + 1 = 7</span><br><span class="line">rw = 4 + 2 = 6</span><br><span class="line">rx = 4 +1 = 5</span><br><span class="line"></span><br><span class="line">若要同时设置 rwx (可读写运行） 权限则将该权限位 设置 为 4 + 2 + 1 = 7</span><br><span class="line">若要同时设置 rw- （可读写不可运行）权限则将该权限位 设置 为 4 + 2 = 6</span><br><span class="line">若要同时设置 r-x （可读可运行不可写）权限则将该权限位 设置 为 4 +1 = 5</span><br><span class="line">User-Group-Other---&gt;&gt;U-G-O</span><br><span class="line">-rw------- (600)    只有拥有者有读写权限。</span><br><span class="line">-rw-r--r-- (644)    只有拥有者有读写权限；而属组用户和其他用户只有读权限。</span><br><span class="line">-rwx------ (700)    只有拥有者有读、写、执行权限。</span><br><span class="line">-rwxr-xr-x (755)    拥有者有读、写、执行权限；而属组用户和其他用户只有读、执行权限。</span><br><span class="line">-rwx--x--x (711)    拥有者有读、写、执行权限；而属组用户和其他用户只有执行权限。</span><br><span class="line">-rw-rw-rw- (666)    所有用户都有文件读、写权限。</span><br><span class="line">-rwxrwxrwx (777)    所有用户都有读、写、执行权限。</span><br></pre></td></tr></table></figure></li><li><p>登录 mysql 默认密码：/Xb6caelDqqk</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql <span class="literal">-u</span> root <span class="literal">-p</span></span><br></pre></td></tr></table></figure></li><li><p>修改密码为 Ccu2021@ ，密码策略规则要求密码必须包含英文大小写、数字以及特殊符号</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER USER <span class="string">&#x27;root&#x27;</span><span class="string">@&#x27;localhost&#x27; IDENTIFIED BY &#x27;Ccu2021@&#x27;;</span></span><br></pre></td></tr></table></figure></li><li><p>创建数据库</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE DATABASE hive;</span><br></pre></td></tr></table></figure></li><li><p>刷新MySQL配置，使得配置生效</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>注意：</p></li><li><p>此部分如果是需要远程登陆的话，mysql 需要创建远程登录，mysql本地登录的话，这步非必要选择</p></li><li><p>创建 用户：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create  user  &#x27;root&#x27;@&#x27;%&#x27;  identified  by  &#x27;Ccu2022@&#x27;;</span><br></pre></td></tr></table></figure></li><li><p>允许远程连接：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grant  all  privileges  on  *.*  to  &#x27;root&#x27;@&#x27;%&#x27;  with  grant  option;</span><br></pre></td></tr></table></figure></li><li><p>更新权限：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flush privileges;</span><br></pre></td></tr></table></figure></li></ul><ul><li><p><strong><em>安装HIve</em></strong></p></li><li><p>网址（注：hive基于hadoop ，因先前部署hadoop版本3.3.0 所以hive版本必须为3.0以上，否则会有不兼容发生）：<a target="_blank" rel="noopener" href="http://archive.apache.org/dist/hive/">Index of /dist/hive (apache.org)</a></p></li><li><p>上传 Hive 安装包到 /export/server</p></li><li><p>此处如果使用PowerShell 上传的话</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入文件所在的文件夹 打开PowerShell</span></span><br><span class="line">scp <span class="literal">-r</span> .\apache<span class="literal">-hive-3</span>.<span class="number">0.0</span><span class="literal">-bin</span>.tar.gz root@<span class="number">192.168</span>.<span class="number">88.136</span>:/export/server</span><br></pre></td></tr></table></figure></li><li><p>解压文件</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar <span class="literal">-zxvf</span> apache<span class="literal">-hive-3</span>.<span class="number">0.0</span><span class="literal">-bin</span>.tar.gz</span><br></pre></td></tr></table></figure></li><li><p>创建软连接</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln <span class="literal">-s</span> apache<span class="literal">-hive-3</span>.<span class="number">0.0</span><span class="literal">-bin</span> hive</span><br></pre></td></tr></table></figure></li><li><p>配置文件</p><ul><li><p>进入Hive安装目录下的conf目录，复制模板文件hive-env.sh.template并重命名为hive-env.sh，文件hive-env.sh用于配置Hive运行环境。</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> hive<span class="literal">-env</span>.sh.template hive<span class="literal">-env</span>.sh</span><br><span class="line"> </span><br><span class="line">vim hive<span class="literal">-env</span>.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文末添加内容</span></span><br><span class="line"></span><br><span class="line">export HADOOP_HOME=/export/server/hadoop<span class="literal">-3</span>.<span class="number">3.0</span> </span><br><span class="line">export HIVE_CONF_DIR=/export/server/hive/conf</span><br><span class="line">export HIVE_AUX_JARS_PATH=/export/server/hive/lib</span><br><span class="line">export JAVA_HOME=/export/server/jdk</span><br></pre></td></tr></table></figure></li><li><p>进入Hive安装目录下的conf目录，创建文件hive-site.xml用于配置Hive相关参数。或者以模板复制一个</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">cp hive-default.xml.template hive-site.xml</span><br><span class="line"></span><br><span class="line">vim hive-site.xml</span><br><span class="line"></span><br><span class="line"># <span class="tag">&lt;<span class="name">configuration</span>&gt;</span> 添加内容 <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置Hive数据存储在HDFS上的目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>     </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive_local/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置Hive在HDFS上的临时目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp_local/hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Hive开启本地模式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.local<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span>	</span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>	</span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置JDBC连接地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://localhost:3306/hive?</span><br><span class="line">createDatabaseIfNotExist=true<span class="symbol">&amp;amp;</span>usessL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- 如果需要配置mysql的远程，需要在这里改--&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- &lt;value&gt;jdbc:mysql://slave2:3306/hive?</span></span><br><span class="line"><span class="comment">createDatabaseIfNotExist=true&amp;amp;usessL=false&lt;/value&gt; --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置JDBC驱动 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span>	<span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置连接MySQL的用户名 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置连接MySQL的密码  --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span>	</span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>Ccu2021@<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置在命令行界面（CLI）中显示表的列名 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.header&lt;/name        	</span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置在命令行界面（CLI）中显示当前数据库名称  --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.current.db<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    	<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>上传JDBC 连接MySQL的驱动包，传入 /export/server/hive/lib 文件夹下</p></li><li><p>注：此部分如需要远程连接 mysql 需要上传MySQL的驱动包 到</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp <span class="literal">-r</span> .\mysql<span class="literal">-connector-java-5</span>.<span class="number">1.32</span>.jar root@<span class="number">192.168</span>.<span class="number">88.136</span>:/export/server/hive/lib</span><br></pre></td></tr></table></figure></li><li><p>添加环境变量</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="comment"># HIVE_PATH</span></span><br><span class="line">export HIVE_HOME=/export/server/hive</span><br><span class="line">export PATH=<span class="variable">$PATH:</span><span class="variable">$HIVE_HOME</span>/bin</span><br></pre></td></tr></table></figure></li><li><p>重新加载环境变量</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></li><li><p>初始化mysql</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">schematool <span class="literal">-initSchema</span> <span class="literal">-dbType</span> mysql</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">结果显示:</span><br><span class="line">(base) [<span class="type">root</span>@<span class="type">slave1</span> <span class="type">conf</span>]<span class="comment"># schematool -initSchema -dbType mysql</span></span><br><span class="line">Metastore connection URL:        jdbc:mysql://localhost:<span class="number">3306</span>/hive?</span><br><span class="line">createDatabaseIfNotExist=true&amp;usessL=false</span><br><span class="line">Metastore Connection Driver :    com.mysql.jdbc.Driver</span><br><span class="line">Metastore connection User:       root</span><br><span class="line">Starting metastore schema initialization to <span class="number">3.0</span>.<span class="number">0</span></span><br><span class="line">Initialization script hive<span class="literal">-schema-3</span>.<span class="number">0.0</span>.mysql.sql</span><br><span class="line">Initialization script completed</span><br><span class="line">schemaTool completed</span><br></pre></td></tr></table></figure><p>注：如果执行有报错看下方报错解决办法！！！！</p></li><li><p>注：启动 hive 之前必须启动 hadoop 集群</p></li><li><p>启动Hive</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">结果显示：</span><br><span class="line">(base) [<span class="type">root</span>@<span class="type">slave1</span> <span class="type">conf</span>]<span class="comment"># hive</span></span><br><span class="line">SLF4J: <span class="class"><span class="keyword">Class</span> <span class="title">path</span> <span class="title">contains</span> <span class="title">multiple</span> <span class="title">SLF4J</span> <span class="title">bindings</span>.</span></span><br><span class="line"><span class="class"><span class="title">SLF4J</span>: <span class="title">Found</span> <span class="title">binding</span> <span class="title">in</span> [<span class="title">jar</span>:<span class="title">file</span>:/<span class="title">export</span>/<span class="title">server</span>/<span class="title">hbase</span>/<span class="title">lib</span>/<span class="title">slf4j</span>-<span class="title">log4j12</span>-1.7.5.<span class="title">jar</span>!/<span class="title">org</span>/<span class="title">slf4j</span>/<span class="title">impl</span>/<span class="title">StaticLoggerBinder</span>.<span class="title">class</span>]</span></span><br><span class="line"><span class="class"><span class="title">SLF4J</span>: <span class="title">Found</span> <span class="title">binding</span> <span class="title">in</span> [<span class="title">jar</span>:<span class="title">file</span>:/<span class="title">export</span>/<span class="title">server</span>/<span class="title">apache</span>-<span class="title">hive</span>-3.0.0-<span class="title">bin</span>/<span class="title">lib</span>/<span class="title">log4j</span>-<span class="title">slf4j</span>-<span class="title">impl</span>-2.10.0.<span class="title">jar</span>!/<span class="title">org</span>/<span class="title">slf4j</span>/<span class="title">impl</span>/<span class="title">StaticLoggerBinder</span>.<span class="title">class</span>]</span></span><br><span class="line"><span class="class"><span class="title">SLF4J</span>: <span class="title">See</span> <span class="title">http</span>://<span class="title">www</span>.<span class="title">slf4j</span>.<span class="title">org</span>/<span class="title">codes</span>.<span class="title">html</span>#<span class="title">multiple_bindings</span> <span class="title">for</span> <span class="title">an</span> <span class="title">explanation</span>.</span></span><br><span class="line"><span class="class"><span class="title">SLF4J</span>: <span class="title">Actual</span> <span class="title">binding</span> <span class="title">is</span> <span class="title">of</span> <span class="title">type</span> [<span class="title">org</span>.<span class="title">slf4j</span>.<span class="title">impl</span>.<span class="title">Log4jLoggerFactory</span>]</span></span><br><span class="line"><span class="class"><span class="title">Hive</span> <span class="title">Session</span> <span class="title">ID</span> = <span class="title">a898fd11</span>-<span class="title">e58d</span>-4<span class="title">d25</span>-<span class="title">adf8</span>-21<span class="title">c8077f5a4b</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">Logging</span> <span class="title">initialized</span> <span class="title">using</span> <span class="title">configuration</span> <span class="title">in</span> <span class="title">jar</span>:<span class="title">file</span>:/<span class="title">export</span>/<span class="title">server</span>/<span class="title">apache</span>-<span class="title">hive</span>-3.0.0-<span class="title">bin</span>/<span class="title">lib</span>/<span class="title">hive</span>-<span class="title">common</span>-3.0.0.<span class="title">jar</span>!/<span class="title">hive</span>-<span class="title">log4j2</span>.<span class="title">properties</span> <span class="title">Async</span>: <span class="title">true</span></span></span><br><span class="line"><span class="class"><span class="title">Hive</span>-<span class="title">on</span>-<span class="title">MR</span> <span class="title">is</span> <span class="title">deprecated</span> <span class="title">in</span> <span class="title">Hive</span> 2 <span class="title">and</span> <span class="title">may</span> <span class="title">not</span> <span class="title">be</span> <span class="title">available</span> <span class="title">in</span> <span class="title">the</span> <span class="title">future</span> <span class="title">versions</span>. <span class="title">Consider</span> <span class="title">using</span> <span class="title">a</span> <span class="title">different</span> <span class="title">execution</span> <span class="title">engine</span> (<span class="title">i</span>.<span class="title">e</span>. <span class="title">spark</span>, <span class="title">tez</span>) <span class="title">or</span> <span class="title">using</span> <span class="title">Hive</span> 1.<span class="title">X</span> <span class="title">releases</span>.</span></span><br><span class="line"><span class="class"><span class="title">hive</span> (<span class="title">default</span>)&gt; </span></span><br></pre></td></tr></table></figure><p>报错解决办法：</p><ul><li>执行 schematool -initSchema -dbType mysql 出现：</li></ul><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.328888.xyz/2022/08/27/G8Iw7.png" alt="image-20220409224823997"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">【解决办法】：此问题由于 hive 和 hadoop 中的 log4j-slf4j-impl-2.10.0.jar包冲突删除一个即可</span><br><span class="line">hive中的路径： /export/server/hive/lib</span><br><span class="line">hadoop中的路径： /export/server/hadoop-3.3.0/share/hadoop/common/lib/</span><br><span class="line">任意删除一个</span><br></pre></td></tr></table></figure><ul><li>执行 schematool -initSchema -dbType mysql 出现：</li></ul><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.328888.xyz/2022/08/27/G8V8k.png" alt="image-20220409225740771"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">【解决办法】：此问题com.google.common.base.Preconditions.checkArgument 这是因为hive内依赖的guava.jar和hadoop内的版本不一致造成的</span><br><span class="line">hive中的路径： /export/server/hive/lib</span><br><span class="line">hadoop中的路径： /export/server/hadoop-3.3.0/share/hadoop/common/lib/</span><br><span class="line">查看guava.jar的版本 。如果两者不一致，删除版本低的，并拷贝高版本的，保证两者的版本一致。</span><br></pre></td></tr></table></figure></li></ul><h2 id="Hive-部署之远程模式"><a href="#Hive-部署之远程模式" class="headerlink" title="Hive 部署之远程模式"></a>Hive 部署之远程模式</h2><p>远程模式与本地模式一样，同样是使用独立数据库存储元数据。不同的是，远程模式使用的是远端的独立数据库，而本地模式使用的是本地独立数据库。远程模式主要应用于Hive客户端较多的情况。</p><ul><li><p>启动HiveServer2服务</p></li><li><p>在虚拟机Node_02中执行“hiveserver2”命令启动HiveServer2服务，HiveServer2服务会进入监听状态</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hiveserver2</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">结果显示：</span><br><span class="line">(base) [<span class="type">root</span>@<span class="type">slave1</span> ~]<span class="comment"># hiveserver2</span></span><br><span class="line">SLF4J: <span class="class"><span class="keyword">Class</span> <span class="title">path</span> <span class="title">contains</span> <span class="title">multiple</span> <span class="title">SLF4J</span> <span class="title">bindings</span>.</span></span><br><span class="line"><span class="class"><span class="title">SLF4J</span>: <span class="title">Found</span> <span class="title">binding</span> <span class="title">in</span> [<span class="title">jar</span>:<span class="title">file</span>:/<span class="title">export</span>/<span class="title">server</span>/<span class="title">hbase</span>/<span class="title">lib</span>/<span class="title">slf4j</span>-<span class="title">log4j12</span>-1.7.5.<span class="title">jar</span>!/<span class="title">org</span>/<span class="title">slf4j</span>/<span class="title">impl</span>/<span class="title">StaticLoggerBinder</span>.<span class="title">class</span>]</span></span><br><span class="line"><span class="class"><span class="title">SLF4J</span>: <span class="title">Found</span> <span class="title">binding</span> <span class="title">in</span> [<span class="title">jar</span>:<span class="title">file</span>:/<span class="title">export</span>/<span class="title">server</span>/<span class="title">apache</span>-<span class="title">hive</span>-3.0.0-<span class="title">bin</span>/<span class="title">lib</span>/<span class="title">log4j</span>-<span class="title">slf4j</span>-<span class="title">impl</span>-2.10.0.<span class="title">jar</span>!/<span class="title">org</span>/<span class="title">slf4j</span>/<span class="title">impl</span>/<span class="title">StaticLoggerBinder</span>.<span class="title">class</span>]</span></span><br><span class="line"><span class="class"><span class="title">SLF4J</span>: <span class="title">See</span> <span class="title">http</span>://<span class="title">www</span>.<span class="title">slf4j</span>.<span class="title">org</span>/<span class="title">codes</span>.<span class="title">html</span>#<span class="title">multiple_bindings</span> <span class="title">for</span> <span class="title">an</span> <span class="title">explanation</span>.</span></span><br><span class="line"><span class="class"><span class="title">SLF4J</span>: <span class="title">Actual</span> <span class="title">binding</span> <span class="title">is</span> <span class="title">of</span> <span class="title">type</span> [<span class="title">org</span>.<span class="title">slf4j</span>.<span class="title">impl</span>.<span class="title">Log4jLoggerFactory</span>]</span></span><br><span class="line"><span class="class">2022-04-09 23:48:24: <span class="title">Starting</span> <span class="title">HiveServer2</span></span></span><br><span class="line"><span class="class"><span class="title">Hive</span> <span class="title">Session</span> <span class="title">ID</span> = 09<span class="title">ab8af4</span>-5<span class="title">dbf</span>-473<span class="title">f</span>-9<span class="title">e34</span>-<span class="title">d4b929984b5c</span></span></span><br><span class="line"><span class="class"><span class="title">Hive</span> <span class="title">Session</span> <span class="title">ID</span> = 9<span class="title">f0ed0a4</span>-<span class="title">b8f6</span>-43<span class="title">ca</span>-9430-7527<span class="title">b81543aa</span></span></span><br></pre></td></tr></table></figure></li><li><p>使用后台方式启动HiveServer2服务，则执行“hive —service hiveserver2 &amp;”命令。</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive <span class="literal">--service</span> hiveserver2 &amp;</span><br></pre></td></tr></table></figure><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">结果显示：</span><br><span class="line">(base) [<span class="type">root</span>@<span class="type">slave1</span> ~]<span class="comment"># hive --service hiveserver2 &amp;</span></span><br><span class="line">[<span class="number">2</span>] <span class="number">6640</span></span><br><span class="line">(base) [<span class="type">root</span>@<span class="type">slave1</span> ~]<span class="comment"># jps</span></span><br><span class="line"><span class="number">2304</span> DataNode</span><br><span class="line"><span class="number">6800</span> Jps</span><br><span class="line"><span class="number">2531</span> NodeManager</span><br><span class="line"><span class="number">6340</span> RunJar</span><br><span class="line"><span class="number">2421</span> SecondaryNameNode</span><br><span class="line">(base) [<span class="type">root</span>@<span class="type">slave1</span> ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure></li><li><p>上传 Hive 到 /export/server 文件夹下（注：以下部分在slave2上操作）</p></li><li><p>此处如果使用PowerShell 上传的话</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 进入文件所在的文件夹 打开PowerShell</span><br><span class="line">scp -r .\apache-hive-3.0.0-bin.tar.gz root@192.168.88.137:/export/server</span><br></pre></td></tr></table></figure></li><li><p>解压文件</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar <span class="literal">-zxvf</span> apache<span class="literal">-hive-3</span>.<span class="number">0.0</span><span class="literal">-bin</span>.tar.gz</span><br></pre></td></tr></table></figure></li><li><p>创建软连接</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln <span class="literal">-s</span> apache<span class="literal">-hive-3</span>.<span class="number">0.0</span><span class="literal">-bin</span> hive</span><br></pre></td></tr></table></figure></li><li><p><strong><em>配置Hive</em></strong></p></li><li><p>虚拟机 slave2 进入Hive安装目录下的conf目录，创建文件hive-site.xml用于配置Hive相关参数。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">cp hive-default.xml.template hive-site.xml</span><br><span class="line"></span><br><span class="line">vim hive-site.xml</span><br><span class="line"></span><br><span class="line"># <span class="tag">&lt;<span class="name">configuration</span>&gt;</span> 添加内容 <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置Hive数据存储在HDFS上的目录  --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>             					</span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive_local/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置Hive在HDFS上的临时目录  --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>	</span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp_local/hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Hive不开启本地模式  --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.local<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Metastore服务地址   --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://slave1:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br></pre></td></tr></table></figure></li><li><p>编辑环境变量</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line"># HIVE_HOME</span><br><span class="line">export HIVE_HOME=/export/server/hive</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br></pre></td></tr></table></figure></li><li><p>虚拟机 slave2 执行通过Hive客户端工具Beeline远程连接虚拟机 slave1 的HiveServer2服务。</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">beeline <span class="literal">-u</span> jdbc:hive2://slave1:<span class="number">10000</span> <span class="literal">-n</span> root <span class="literal">-p</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">结果显示:</span><br><span class="line">(base) [root@slave2 conf]# beeline -u jdbc:hive2://slave1:10000 -n root -p</span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding in [jar:file:/export/server/apache-hive-3.0.0-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding in [jar:file:/export/server/hadoop-3.3.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</span><br><span class="line">SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]</span><br><span class="line">Connecting to jdbc:hive2://slave1:10000/;user=root</span><br><span class="line">Enter password for jdbc:hive2://slave1:10000/: ********</span><br><span class="line">Connected to: Apache Hive (version 3.0.0)</span><br><span class="line">Driver: Hive JDBC (version 3.0.0)</span><br><span class="line">Transaction isolation: TRANSACTION_REPEATABLE_READ</span><br><span class="line">Beeline version 3.0.0 by Apache Hive</span><br><span class="line">0: jdbc:hive2://slave1:10000/&gt;</span><br></pre></td></tr></table></figure></li><li><p>执行“hive”命令，通过Hive客户端工具HiveCLI操作本地模式下的Hive，在HiveCLI的命令行界面执行“create database test;”命令创建数据库test。然后分别执行“show databases;”命令分别查看 slave1 和 slave2 数据库列表。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">结果显示:</span><br></pre></td></tr></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s1.328888.xyz/2022/08/27/G8P6J.png" alt="image-20220410002727118"></p></li></ul><div class="tip warning faa-horizontal animated-hover"><p>文档内容来自于网络采集和自己编写,不做任何盈利,仅供学习。如有侵权请及时联系博主,博主会在第一时间进行删改。</p></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者:</span> <span class="post-copyright-info"><a href="https://www.jermyn.cn">Jermyn</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接:</span> <span class="post-copyright-info"><a href="https://www.jermyn.cn/posts/ef13.html">https://www.jermyn.cn/posts/ef13.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明:</span> <span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.jermyn.cn" target="_blank">Jermyn's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/zookeeper/">zookeeper</a><a class="post-meta__tags" href="/tags/linux/">linux</a><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/">大数据服务部署</a><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a><a class="post-meta__tags" href="/tags/Spark/">Spark</a><a class="post-meta__tags" href="/tags/Kafka/">Kafka</a><a class="post-meta__tags" href="/tags/Hbase/">Hbase</a><a class="post-meta__tags" href="/tags/Hive/">Hive</a></div><div class="post_share"><div class="social-share" data-image="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/6.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/e6c9.html"><img class="prev-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/2.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Jave基础编程</div></div></a></div><div class="next-post pull-right"><a href="/posts/ba42.html"><img class="next-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/3.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Hadoop集群脚本部署</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/ba42.html" title="Hadoop集群脚本部署"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-08-26</div><div class="title">Hadoop集群脚本部署</div></div></a></div><div><a href="/posts/c9d2.html" title="kafka基本操作"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/8.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-08-26</div><div class="title">kafka基本操作</div></div></a></div></div></div><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i> <span>评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/9a8a/auther.jpg" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">Jermyn</div><div class="author-info__description">个人学习笔记</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">21</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Jermyn-code"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/Jermyn-code" target="_blank" title="Github"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-github-fill"></use></svg></a><a class="social-icon faa-parent animated-hover" href="https://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&amp;email=1773046949@qq.com" target="_blank" title="Email"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-mail"></use></svg></a><a class="social-icon faa-parent animated-hover" href="tencent://Message/?Uin=1773046949&amp;amp;websiteName=local.edu.com:8888=&amp;amp;Menu=yes" target="_blank" title="QQ"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-QQ1"></use></svg></a><a class="social-icon faa-parent animated-hover" href="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/qrcode.jpg" target="_blank" title="WeChat"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-weixin"></use></svg></a><a class="social-icon faa-parent animated-hover" href="https://www.instagram.com/born_in2084/" target="_blank" title="Instagram"><svg class="icon faa-tada" aria-hidden="true"><use xlink:href="#icon-instagram-fill"></use></svg></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">在读学习，联系我请+VX：AYOBRUH</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE"><span class="toc-number">1.</span> <span class="toc-text">网络环境配置</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#hosts%E6%98%A0%E5%B0%84"><span class="toc-number">2.</span> <span class="toc-text">hosts映射</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5"><span class="toc-number">3.</span> <span class="toc-text">集群配置时间同步</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ssh%E5%85%8D%E5%AF%86%E9%92%A5%E7%99%BB%E9%99%86"><span class="toc-number">4.</span> <span class="toc-text">ssh免密钥登陆</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE-jdk"><span class="toc-number">5.</span> <span class="toc-text">安装配置 jdk</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#zookeeper%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE"><span class="toc-number">6.</span> <span class="toc-text">zookeeper安装配置</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hadoop-%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE"><span class="toc-number">7.</span> <span class="toc-text">Hadoop 安装配置</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Spark%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE"><span class="toc-number">8.</span> <span class="toc-text">Spark安装配置</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark-local%E6%A8%A1%E5%BC%8F"><span class="toc-number">8.1.</span> <span class="toc-text">Spark-local模式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark-Standalone%E6%A8%A1%E5%BC%8F"><span class="toc-number">8.2.</span> <span class="toc-text">Spark-Standalone模式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark-Standalone-HA%E6%A8%A1%E5%BC%8F"><span class="toc-number">8.3.</span> <span class="toc-text">Spark-Standalone-HA模式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark-On-YARN%E6%A8%A1%E5%BC%8F"><span class="toc-number">8.4.</span> <span class="toc-text">Spark On YARN模式</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#kafka-%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE"><span class="toc-number">9.</span> <span class="toc-text">kafka 安装配置</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#hbase%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE"><span class="toc-number">10.</span> <span class="toc-text">hbase安装配置</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hive%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE"><span class="toc-number">11.</span> <span class="toc-text">Hive安装配置</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive-%E9%83%A8%E7%BD%B2%E4%B9%8B%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F"><span class="toc-number">11.1.</span> <span class="toc-text">Hive 部署之本地模式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive-%E9%83%A8%E7%BD%B2%E4%B9%8B%E8%BF%9C%E7%A8%8B%E6%A8%A1%E5%BC%8F"><span class="toc-number">11.2.</span> <span class="toc-text">Hive 部署之远程模式</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/facf.html" title="Hadoop2.x"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Hadoop2.x"></a><div class="content"><a class="title" href="/posts/facf.html" title="Hadoop2.x">Hadoop2.x</a><time datetime="2023-05-23T21:12:50.000Z" title="发表于 2023-05-23 21:12:50">2023-05-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/eb1d.html" title="Linux基础命令"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/f495/2.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Linux基础命令"></a><div class="content"><a class="title" href="/posts/eb1d.html" title="Linux基础命令">Linux基础命令</a><time datetime="2023-05-22T22:17:56.000Z" title="发表于 2023-05-22 22:17:56">2023-05-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/f495.html" title="Linux磁盘的挂载和卸载"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/f495/1.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Linux磁盘的挂载和卸载"></a><div class="content"><a class="title" href="/posts/f495.html" title="Linux磁盘的挂载和卸载">Linux磁盘的挂载和卸载</a><time datetime="2023-05-22T14:41:20.000Z" title="发表于 2023-05-22 14:41:20">2023-05-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/2053.html" title="JavaCodeDemo"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed/other/2053head.jpeg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="JavaCodeDemo"></a><div class="content"><a class="title" href="/posts/2053.html" title="JavaCodeDemo">JavaCodeDemo</a><time datetime="2023-05-07T18:21:42.000Z" title="发表于 2023-05-07 18:21:42">2023-05-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/3755.html" title="Maven技术"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/3755/20230221223405.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Maven技术"></a><div class="content"><a class="title" href="/posts/3755.html" title="Maven技术">Maven技术</a><time datetime="2023-02-14T18:56:51.000Z" title="发表于 2023-02-14 18:56:51">2023-02-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2023 By Jermyn</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i> <span>数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo.jermyn.cn/',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo.jermyn.cn/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><div class="aplayer no-destroy" data-id="8670693070" data-server="tencent" data-type="playlist" data-order="list" data-fixed="true" data-preload="auto" data-autoplay="false" data-mutex="true"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><div class="app-refresh" id="app-refresh" style="position:fixed;top:-2.2rem;left:0;right:0;z-index:99999;padding:0 1rem;font-size:15px;height:2.2rem;transition:all .3s ease"><div class="app-refresh-wrap" style="display:flex;color:#fff;height:100%;align-items:center;justify-content:center"><label>✨ 有新文章啦！ 👉</label><a href="javascript:void(0)" onclick="location.reload()"><span style="color:#fff;text-decoration:underline;cursor:pointer">🍗点击食用🍔</span></a></div></div><script>if ('serviceWorker' in navigator) {
if (navigator.serviceWorker.controller) {
navigator.serviceWorker.addEventListener('controllerchange', function() {
showNotification()
})
}
window.addEventListener('load', function() {
navigator.serviceWorker.register('/sw.js')
})
}
function showNotification() {
if (GLOBAL_CONFIG.Snackbar) {
var snackbarBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
GLOBAL_CONFIG.Snackbar.bgLight :
GLOBAL_CONFIG.Snackbar.bgDark
var snackbarPos = GLOBAL_CONFIG.Snackbar.position
Snackbar.show({
text: '✨ 有新文章啦！ 👉',
backgroundColor: snackbarBg,
duration: 500000,
pos: snackbarPos,
actionText: '🍗点击食用🍔',
actionTextColor: '#fff',
onActionClick: function(e) {
location.reload()
},
})
} else {
var showBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
'#49b1f5' :
'#1f1f1f'
var cssText = `top: 0; background: ${showBg};`
document.getElementById('app-refresh').style.cssText = cssText
}
}</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script data-pjax>function butterfly_clock_anzhiyu_injector_config(){var e=document.getElementsByClassName("sticky_layout")[0];console.log("已挂载butterfly_clock_anzhiyu"),e&&e.insertAdjacentHTML("afterbegin",'<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>')}for(var elist="null".split(","),cpage=location.pathname,epage="all",qweather_key="0f5e430e0ec2485a8e175000f1ca33eb",gaud_map_key="163f0b807c26d68365ae5f029f76cf19",baidu_ak_key="undefined",flag=0,clock_rectangle="111.62,33.79",clock_default_rectangle_enable="false",i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;"all"===epage&&0==flag?butterfly_clock_anzhiyu_injector_config():epage===cpage&&butterfly_clock_anzhiyu_injector_config()</script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.js"></script><script data-pjax>function butterfly_footer_beautify_injector_config(){var A=document.getElementById("footer-wrap");console.log("已挂载butterfly_footer_beautify"),A.insertAdjacentHTML("beforeend",'<div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v5.4.0" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" data-title="主题版本Butterfly_v4.2.2" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://cloud.tencent.com/" style="margin-inline:5px" data-title="本站使用JsDelivr为静态资源提供CDN加速" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/CDN-Tencent-blue?style=flat&amp;logo=iCloud" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/Jermyn-code" style="margin-inline:5px" data-title="本站项目由Github托管" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></p>')}for(var elist="null".split(","),cpage=location.pathname,epage="all",flag=0,i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;"all"===epage&&0==flag?butterfly_footer_beautify_injector_config():epage===cpage&&butterfly_footer_beautify_injector_config()</script><script async src="/js/runtime/runtime.min.js"></script><script data-pjax>function butterfly_swiper_injector_config(){var a=document.getElementById("recent-posts");console.log("已挂载butterfly_swiper"),a.insertAdjacentHTML("afterbegin",'<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/9a8a.html" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/1.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-10-02</span><a class="blog-slider__title" href="posts/9a8a.html" alt="">Java高级编程</a><div class="blog-slider__text">Java学习笔记，Java基础阶段的高级编程，包含多线程，Java常用类，枚举类&amp;注解，Java集合，泛型，IO流，网络编程，Java反射机制，Java8的其他新特性，Java9&amp;10&amp;11新特性，文档资源来自尚硅谷，整理为博主，在此感谢尚硅谷无私分享大量的学习资源。</div><a class="blog-slider__button" href="posts/9a8a.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/ba42.html" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/3.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-08-26</span><a class="blog-slider__title" href="posts/ba42.html" alt="">Hadoop集群脚本部署</a><div class="blog-slider__text">Hadoop脚本部署，包含7个shell脚本，以及一个ip.txt文件，建议运行顺序为00-06</div><a class="blog-slider__button" href="posts/ba42.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/ef13.html" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/6.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-08-27</span><a class="blog-slider__title" href="posts/ef13.html" alt="">大数据集群服务部署</a><div class="blog-slider__text">本文为大数据集群服务的部署文档,包括zookeeper服务部署,Hadoop服务部署,Spark服务部署,Kafka服务部署,Hbase服务部署,Hive服务部署</div><a class="blog-slider__button" href="posts/ef13.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/d746.html" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/9a8a/8.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-08-26</span><a class="blog-slider__title" href="posts/d746.html" alt="">shell 学习笔记</a><div class="blog-slider__text">shell脚本学习笔记，学完可自行编写shell脚本</div><a class="blog-slider__button" href="posts/d746.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/e6c9.html" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn1.tianli0.top/gh/Jermyn-code/FigureBed@main/blogImages/2.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-09-02</span><a class="blog-slider__title" href="posts/e6c9.html" alt="">Jave基础编程</a><div class="blog-slider__text">Java学习笔记，Java基础阶段的基础编程，包含Java语言概述，基本语法，数组，面向对象编程，异常处理。文档资源来自尚硅谷，整理为博主，在此感谢尚硅谷无私分享大量的学习资源。</div><a class="blog-slider__button" href="posts/e6c9.html" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>')}for(var elist="undefined".split(","),cpage=location.pathname,epage="all",flag=0,i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;"all"===epage&&0==flag?butterfly_swiper_injector_config():epage===cpage&&butterfly_swiper_injector_config()</script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><div class="js-pjax"><script async>for(var arr=document.getElementsByClassName("recent-post-item"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__zoomIn"),arr[i].setAttribute("data-wow-duration","1.5s"),arr[i].setAttribute("data-wow-delay","200ms"),arr[i].setAttribute("data-wow-offset","30"),arr[i].setAttribute("data-wow-iteration","1")</script><script async>for(var arr=document.getElementsByClassName("card-widget"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__zoomIn"),arr[i].setAttribute("data-wow-duration",""),arr[i].setAttribute("data-wow-delay","200ms"),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("flink-list-card"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__flipInY"),arr[i].setAttribute("data-wow-duration","3s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("flink-list-card"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__animated"),arr[i].setAttribute("data-wow-duration","3s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("article-sort-item"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__slideInRight"),arr[i].setAttribute("data-wow-duration","1.5s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("site-card"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__flipInY"),arr[i].setAttribute("data-wow-duration","3s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("site-card"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__animated"),arr[i].setAttribute("data-wow-duration","3s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script></div><script defer src="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/wow_init.js"></script><script async src="//at.alicdn.com/t/c/font_3617685_a7gpo3nfht.js"></script></body></html>